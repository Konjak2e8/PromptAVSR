2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12204
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12204
[W117 10:12:40.151995863 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12204
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 1
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12204
[W117 10:12:40.156806916 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 3
[W117 10:12:40.160215983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 2
[W117 10:12:40.167446825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-17 10:12:40 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 0
[2025-01-17 10:12:41,546][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/workspace/av_hubert/avhubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12204', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 45000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/workspace/AV_HuBERT_pretrained/base_vox_iter5.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 22500, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True, 'prompting': True}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/workspace/lrs2/433h_data', 'label_dir': '/workspace/lrs2/433h_data', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'fine_tuning': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video', 'audio'], 'image_aug': True, 'pad_audio': True, 'random_crop': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 15000, 'hold_steps': 0, 'decay_steps': 30000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 45000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2025-01-17 10:12:41,553][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/avhubert/finetune_prompt
[2025-01-17 10:12:41,553][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['wrd'], 'label_dir': '/workspace/lrs2/433h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video', 'audio'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}
2025-01-17 10:12:42 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 4, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
2025-01-17 10:12:42 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 4, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
2025-01-17 10:12:42 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 4, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2025-01-17 10:12:42,516][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/avhubert/finetune_prompt
[2025-01-17 10:12:42,516][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['km'], 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'label_rate': 25, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 2000, 'min_sample_size': 5, 'max_trim_sample_size': 400, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': False}
[2025-01-17 10:12:42,525][avhubert.hubert][INFO] - HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 4, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
all_params: 228.73M learnable_params: 1.97M
[2025-01-17 10:12:46,772][fairseq_cli.train][INFO] - AVHubertSeq2Seq(
  (encoder): HubertEncoderWrapper(
    (w2v_model): AVHubertModel(
      (modal_prompt_learner): MultiModalPromptLearner(
        (compound_prompt_projections_audio): ModuleList(
          (0-3): 4 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_audio): ModuleList(
          (0-3): 4 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (compound_prompt_projections_video): ModuleList(
          (0-3): 4 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_video): ModuleList(
          (0-3): 4 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (common_prompt_projection_video): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
        (common_prompt_projection_audio): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
      )
      (feature_extractor_audio): SubModel(
        (proj): Linear(in_features=104, out_features=768, bias=True)
        (encoder): TransformerEncoder(
          (pos_conv): Sequential(
            (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
            (1): SamePad()
            (2): GELU(approximate='none')
          )
          (layers): ModuleList(
            (0-3): 4 x TransformerSentenceEncoderLayer(
              (self_attn): MultiheadAttention(
                (dropout_module): FairseqDropout()
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.0, inplace=False)
              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (feature_extractor_video): SubModel(
        (resnet): ResEncoder(
          (frontend3D): Sequential(
            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): PReLU(num_parameters=64)
            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
          )
          (trunk): ResNet(
            (layer1): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer2): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer3): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer4): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (avgpool): AdaptiveAvgPool2d(output_size=1)
          )
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
        (encoder): TransformerEncoder(
          (pos_conv): Sequential(
            (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
            (1): SamePad()
            (2): GELU(approximate='none')
          )
          (layers): ModuleList(
            (0-3): 4 x TransformerSentenceEncoderLayer(
              (self_attn): MultiheadAttention(
                (dropout_module): FairseqDropout()
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.0, inplace=False)
              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2025-01-17 10:12:46,777][fairseq_cli.train][INFO] - task: AVHubertPretrainingTask
[2025-01-17 10:12:46,777][fairseq_cli.train][INFO] - model: AVHubertSeq2Seq
[2025-01-17 10:12:46,777][fairseq_cli.train][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2025-01-17 10:12:46,780][fairseq_cli.train][INFO] - num. shared model params: 228,730,184 (num. trained: 1,971,552)
[2025-01-17 10:12:46,783][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2025-01-17 10:12:46,784][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2025-01-17 10:12:46,794][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 1082, skipped 0 short and 0 long and 0 unaligned, longest-loaded=153, shortest-loaded=14
[2025-01-17 10:12:46,794][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/valid.wrd is sequence label. skipped
[2025-01-17 10:12:46,794][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <avhubert.utils.CenterCrop object at 0x7f026089a4c0>
    Normalize(mean=0.421, std=0.165)
)
[2025-01-17 10:12:46,795][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2025-01-17 10:12:46,795][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv2.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv2.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv2.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.downsample.0.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv2.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv2.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.downsample.0.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv1.bias
[2025-01-17 10:12:46,863][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv2.bias
[2025-01-17 10:12:46,864][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv1.bias
[2025-01-17 10:12:46,864][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv2.bias
[2025-01-17 10:12:46,864][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.downsample.0.bias
[2025-01-17 10:12:46,864][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv1.bias
[2025-01-17 10:12:46,864][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv2.bias
[2025-01-17 10:12:48,181][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2025-01-17 10:12:48,182][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-17 10:12:48,182][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-17 10:12:48,182][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-17 10:12:48,182][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-17 10:12:48,182][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2025-01-17 10:12:48,183][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2025-01-17 10:12:48,183][fairseq_cli.train][INFO] - max tokens per device = 1000 and max sentences per device = None
[2025-01-17 10:12:48,184][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2025-01-17 10:13:01,691][fairseq.trainer][INFO] - Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 0 updates)
[2025-01-17 10:13:01,893][fairseq.trainer][INFO] - loading train data for epoch 38
[2025-01-17 10:13:01,895][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2025-01-17 10:13:02,509][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 163822, skipped 0 short and 292 long and 0 unaligned, longest-loaded=500, shortest-loaded=0
[2025-01-17 10:13:02,633][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/train.wrd is sequence label. skipped
[2025-01-17 10:13:02,650][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <avhubert.utils.HorizontalFlip object at 0x7f03522a1f70>
    Normalize(mean=0.421, std=0.165)
)
[2025-01-17 10:13:02,650][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2025-01-17 10:13:02,651][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2025-01-17 10:13:03,826][fairseq.trainer][INFO] - begin training epoch 38
[2025-01-17 10:13:03,826][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
all_params: 228.73M learnable_params: 1.97M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
all_params: 228.73M learnable_params: 1.97M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
all_params: 228.73M learnable_params: 1.97M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
[rank3]:[W117 10:13:48.816630510 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W117 10:13:51.412664609 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W117 10:13:51.690394652 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W117 10:13:57.154570757 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[2025-01-17 10:17:29,889][train_inner][INFO] - {"epoch": 38, "update": 37.078, "loss": "129.302", "nll_loss": "4.6", "total": "673.2", "n_correct": "340.04", "ppl": "24.25", "accuracy": "50.511", "wps": "414.6", "ups": "0.62", "wpb": "673.2", "bsz": "28.2", "num_updates": "200", "lr": "2.32e-05", "gnorm": "1.084", "loss_scale": "128", "train_wall": "237", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:21:00,816][train_inner][INFO] - {"epoch": 38, "update": 37.112, "loss": "128.793", "nll_loss": "4.537", "total": "661.455", "n_correct": "336.845", "ppl": "23.21", "accuracy": "50.925", "wps": "627.2", "ups": "0.95", "wpb": "661.5", "bsz": "27.5", "num_updates": "400", "lr": "3.64e-05", "gnorm": "1.228", "loss_scale": "128", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:24:39,547][train_inner][INFO] - {"epoch": 38, "update": 37.147, "loss": "117.975", "nll_loss": "4.394", "total": "667.925", "n_correct": "351.705", "ppl": "21.02", "accuracy": "52.656", "wps": "610.8", "ups": "0.91", "wpb": "667.9", "bsz": "29.6", "num_updates": "600", "lr": "4.96e-05", "gnorm": "1.027", "loss_scale": "128", "train_wall": "212", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:28:08,314][train_inner][INFO] - {"epoch": 38, "update": 37.181, "loss": "127.329", "nll_loss": "4.468", "total": "665.86", "n_correct": "342.695", "ppl": "22.13", "accuracy": "51.467", "wps": "637.9", "ups": "0.96", "wpb": "665.9", "bsz": "27.7", "num_updates": "800", "lr": "6.28e-05", "gnorm": "1.117", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:31:34,034][train_inner][INFO] - {"epoch": 38, "update": 37.215, "loss": "134.937", "nll_loss": "4.643", "total": "665.815", "n_correct": "334.62", "ppl": "24.99", "accuracy": "50.257", "wps": "647.3", "ups": "0.97", "wpb": "665.8", "bsz": "26.9", "num_updates": "1000", "lr": "7.6e-05", "gnorm": "1.143", "loss_scale": "128", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 10:35:08,981][train_inner][INFO] - {"epoch": 38, "update": 37.249, "loss": "121.762", "nll_loss": "4.429", "total": "670.475", "n_correct": "349.275", "ppl": "21.54", "accuracy": "52.094", "wps": "623.9", "ups": "0.93", "wpb": "670.5", "bsz": "29", "num_updates": "1200", "lr": "8.92e-05", "gnorm": "0.867", "loss_scale": "128", "train_wall": "208", "gb_free": "10.9", "wall": "0"}
[2025-01-17 10:38:33,636][train_inner][INFO] - {"epoch": 38, "update": 37.283, "loss": "126.938", "nll_loss": "4.521", "total": "665.355", "n_correct": "340.89", "ppl": "22.96", "accuracy": "51.234", "wps": "650.3", "ups": "0.98", "wpb": "665.4", "bsz": "28", "num_updates": "1400", "lr": "0.0001024", "gnorm": "1.194", "loss_scale": "128", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:42:02,129][train_inner][INFO] - {"epoch": 38, "update": 37.317, "loss": "129.233", "nll_loss": "4.537", "total": "663.84", "n_correct": "338.695", "ppl": "23.22", "accuracy": "51.021", "wps": "636.9", "ups": "0.96", "wpb": "663.8", "bsz": "27.5", "num_updates": "1600", "lr": "0.0001156", "gnorm": "1.073", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:45:34,407][train_inner][INFO] - {"epoch": 38, "update": 37.351, "loss": "123.011", "nll_loss": "4.444", "total": "668.315", "n_correct": "346.78", "ppl": "21.76", "accuracy": "51.889", "wps": "629.7", "ups": "0.94", "wpb": "668.3", "bsz": "28.6", "num_updates": "1800", "lr": "0.0001288", "gnorm": "0.94", "loss_scale": "128", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:49:03,757][train_inner][INFO] - {"epoch": 38, "update": 37.385, "loss": "129.995", "nll_loss": "4.532", "total": "670.555", "n_correct": "342.17", "ppl": "23.14", "accuracy": "51.028", "wps": "640.7", "ups": "0.96", "wpb": "670.6", "bsz": "27.6", "num_updates": "2000", "lr": "0.000142", "gnorm": "1.072", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 10:52:35,883][train_inner][INFO] - {"epoch": 38, "update": 37.419, "loss": "124.786", "nll_loss": "4.46", "total": "669.615", "n_correct": "345.91", "ppl": "22", "accuracy": "51.658", "wps": "631.6", "ups": "0.94", "wpb": "669.6", "bsz": "28.4", "num_updates": "2200", "lr": "0.0001552", "gnorm": "1.065", "loss_scale": "128", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 10:55:57,760][train_inner][INFO] - {"epoch": 38, "update": 37.454, "loss": "126.543", "nll_loss": "4.455", "total": "655.915", "n_correct": "338.885", "ppl": "21.93", "accuracy": "51.666", "wps": "649.9", "ups": "0.99", "wpb": "655.9", "bsz": "27.4", "num_updates": "2400", "lr": "0.0001684", "gnorm": "1.338", "loss_scale": "128", "train_wall": "195", "gb_free": "10.7", "wall": "0"}
[2025-01-17 10:59:28,016][train_inner][INFO] - {"epoch": 38, "update": 37.488, "loss": "126.573", "nll_loss": "4.505", "total": "665.385", "n_correct": "341.47", "ppl": "22.7", "accuracy": "51.319", "wps": "633", "ups": "0.95", "wpb": "665.4", "bsz": "28", "num_updates": "2600", "lr": "0.0001816", "gnorm": "1.076", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:02:52,423][train_inner][INFO] - {"epoch": 38, "update": 37.522, "loss": "127.743", "nll_loss": "4.425", "total": "661.48", "n_correct": "343.025", "ppl": "21.49", "accuracy": "51.857", "wps": "647.3", "ups": "0.98", "wpb": "661.5", "bsz": "27.2", "num_updates": "2800", "lr": "0.0001948", "gnorm": "1.084", "loss_scale": "128", "train_wall": "197", "gb_free": "10.9", "wall": "0"}
[2025-01-17 11:06:28,443][train_inner][INFO] - {"epoch": 38, "update": 37.556, "loss": "121.528", "nll_loss": "4.412", "total": "673.405", "n_correct": "352.83", "ppl": "21.28", "accuracy": "52.395", "wps": "623.5", "ups": "0.93", "wpb": "673.4", "bsz": "29.1", "num_updates": "3000", "lr": "0.000208", "gnorm": "1.133", "loss_scale": "128", "train_wall": "209", "gb_free": "10.9", "wall": "0"}
[2025-01-17 11:09:55,448][train_inner][INFO] - {"epoch": 38, "update": 37.59, "loss": "126.539", "nll_loss": "4.436", "total": "662.795", "n_correct": "342.985", "ppl": "21.65", "accuracy": "51.748", "wps": "640.5", "ups": "0.97", "wpb": "662.8", "bsz": "27.6", "num_updates": "3200", "lr": "0.0002212", "gnorm": "0.829", "loss_scale": "128", "train_wall": "201", "gb_free": "10.7", "wall": "0"}
[2025-01-17 11:13:20,419][train_inner][INFO] - {"epoch": 38, "update": 37.624, "loss": "127.571", "nll_loss": "4.453", "total": "661.64", "n_correct": "342.14", "ppl": "21.91", "accuracy": "51.711", "wps": "645.6", "ups": "0.98", "wpb": "661.6", "bsz": "27.4", "num_updates": "3400", "lr": "0.0002344", "gnorm": "1.159", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 11:16:52,118][train_inner][INFO] - {"epoch": 38, "update": 37.658, "loss": "126.674", "nll_loss": "4.547", "total": "671.27", "n_correct": "342.115", "ppl": "23.37", "accuracy": "50.965", "wps": "634.2", "ups": "0.94", "wpb": "671.3", "bsz": "28.4", "num_updates": "3600", "lr": "0.0002476", "gnorm": "1.336", "loss_scale": "128", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:20:24,656][train_inner][INFO] - {"epoch": 38, "update": 37.692, "loss": "123.251", "nll_loss": "4.421", "total": "668.335", "n_correct": "348.435", "ppl": "21.42", "accuracy": "52.135", "wps": "629", "ups": "0.94", "wpb": "668.3", "bsz": "28.5", "num_updates": "3800", "lr": "0.0002608", "gnorm": "1.776", "loss_scale": "128", "train_wall": "205", "gb_free": "10.6", "wall": "0"}
[2025-01-17 11:23:51,327][train_inner][INFO] - {"epoch": 38, "update": 37.727, "loss": "126.209", "nll_loss": "4.52", "total": "661.64", "n_correct": "340.8", "ppl": "22.94", "accuracy": "51.508", "wps": "640.4", "ups": "0.97", "wpb": "661.6", "bsz": "28", "num_updates": "4000", "lr": "0.000274", "gnorm": "1.075", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:25:18,207][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2025-01-17 11:27:14,129][train_inner][INFO] - {"epoch": 38, "update": 37.761, "loss": "133.673", "nll_loss": "4.586", "total": "665.805", "n_correct": "335.84", "ppl": "24.02", "accuracy": "50.441", "wps": "656.7", "ups": "0.99", "wpb": "665.8", "bsz": "26.9", "num_updates": "4200", "lr": "0.0002872", "gnorm": "0.976", "loss_scale": "64", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:30:40,573][train_inner][INFO] - {"epoch": 38, "update": 37.795, "loss": "126.809", "nll_loss": "4.519", "total": "662.28", "n_correct": "339.93", "ppl": "22.92", "accuracy": "51.327", "wps": "641.7", "ups": "0.97", "wpb": "662.3", "bsz": "27.9", "num_updates": "4400", "lr": "0.0003004", "gnorm": "0.911", "loss_scale": "64", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 11:34:05,291][train_inner][INFO] - {"epoch": 38, "update": 37.829, "loss": "126.9", "nll_loss": "4.5", "total": "656.44", "n_correct": "337.925", "ppl": "22.63", "accuracy": "51.478", "wps": "641.4", "ups": "0.98", "wpb": "656.4", "bsz": "27.5", "num_updates": "4600", "lr": "0.0003136", "gnorm": "1.077", "loss_scale": "64", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:37:41,243][train_inner][INFO] - {"epoch": 38, "update": 37.863, "loss": "114.703", "nll_loss": "4.324", "total": "659.365", "n_correct": "348.815", "ppl": "20.04", "accuracy": "52.902", "wps": "610.7", "ups": "0.93", "wpb": "659.4", "bsz": "29.7", "num_updates": "4800", "lr": "0.0003268", "gnorm": "1.158", "loss_scale": "64", "train_wall": "209", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:41:10,223][train_inner][INFO] - {"epoch": 38, "update": 37.897, "loss": "126.145", "nll_loss": "4.534", "total": "671.185", "n_correct": "341.14", "ppl": "23.17", "accuracy": "50.827", "wps": "642.5", "ups": "0.96", "wpb": "671.2", "bsz": "28.5", "num_updates": "5000", "lr": "0.00034", "gnorm": "1.107", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:44:30,542][train_inner][INFO] - {"epoch": 38, "update": 37.931, "loss": "135.646", "nll_loss": "4.628", "total": "670.985", "n_correct": "335.77", "ppl": "24.72", "accuracy": "50.041", "wps": "670", "ups": "1", "wpb": "671", "bsz": "26.9", "num_updates": "5200", "lr": "0.0003532", "gnorm": "1.168", "loss_scale": "64", "train_wall": "194", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:47:59,303][train_inner][INFO] - {"epoch": 38, "update": 37.966, "loss": "126.312", "nll_loss": "4.475", "total": "661.59", "n_correct": "340.325", "ppl": "22.23", "accuracy": "51.44", "wps": "633.9", "ups": "0.96", "wpb": "661.6", "bsz": "27.8", "num_updates": "5400", "lr": "0.0003664", "gnorm": "1.28", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:51:05,800][train_inner][INFO] - {"epoch": 38, "update": 38.0, "loss": "131.263", "nll_loss": "4.558", "total": "663.77", "n_correct": "336.92", "ppl": "23.55", "accuracy": "50.759", "wps": "711.9", "ups": "1.07", "wpb": "663.8", "bsz": "27.2", "num_updates": "5600", "lr": "0.0003796", "gnorm": "1.186", "loss_scale": "64", "train_wall": "181", "gb_free": "10.9", "wall": "0"}
[2025-01-17 11:51:06,150][fairseq_cli.train][INFO] - begin validation on "valid" subset
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2025-01-17 11:52:01,925][valid][INFO] - {"epoch": 38, "valid_loss": "39.944", "valid_nll_loss": "2.064", "valid_total": "678.4", "valid_n_correct": "499.9", "valid_ppl": "4.18", "valid_accuracy": "73.688", "valid_wps": "724.1", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "5602"}
[2025-01-17 11:52:01,928][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 5602 updates
[2025-01-17 11:52:01,928][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-17 11:52:04,401][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-17 11:52:07,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 38 @ 5602 updates, score 73.688) (writing took 5.405531514901668 seconds)
[2025-01-17 11:52:07,334][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2025-01-17 11:52:07,341][train][INFO] - {"epoch": 38, "train_loss": "117.227", "train_nll_loss": "4.294", "train_total": "667.686", "train_n_correct": "358.354", "train_ppl": "19.61", "train_accuracy": "53.671", "train_wps": "593.9", "train_ups": "0.89", "train_wpb": "667.7", "train_bsz": "29.3", "train_num_updates": "5602", "train_lr": "0.000379732", "train_gnorm": "1.264", "train_loss_scale": "64", "train_train_wall": "6214", "train_gb_free": "10.8", "train_wall": "0"}
[2025-01-17 11:52:07,940][fairseq.trainer][INFO] - begin training epoch 39
[2025-01-17 11:52:07,941][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 11:56:14,309][train_inner][INFO] - {"epoch": 39, "update": 38.034, "loss": "135.164", "nll_loss": "4.601", "total": "667.68", "n_correct": "336.68", "ppl": "24.26", "accuracy": "50.425", "wps": "432.9", "ups": "0.65", "wpb": "667.7", "bsz": "26.7", "num_updates": "5800", "lr": "0.0003928", "gnorm": "1.225", "loss_scale": "64", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 11:59:45,464][train_inner][INFO] - {"epoch": 39, "update": 38.068, "loss": "128.965", "nll_loss": "4.517", "total": "672.695", "n_correct": "344.43", "ppl": "22.89", "accuracy": "51.202", "wps": "637.2", "ups": "0.95", "wpb": "672.7", "bsz": "27.8", "num_updates": "6000", "lr": "0.000406", "gnorm": "1.095", "loss_scale": "64", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 12:03:13,724][train_inner][INFO] - {"epoch": 39, "update": 38.102, "loss": "129.79", "nll_loss": "4.527", "total": "668.66", "n_correct": "342.335", "ppl": "23.06", "accuracy": "51.197", "wps": "642.2", "ups": "0.96", "wpb": "668.7", "bsz": "27.5", "num_updates": "6200", "lr": "0.0004192", "gnorm": "1.344", "loss_scale": "64", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:06:34,673][train_inner][INFO] - {"epoch": 39, "update": 38.136, "loss": "134.567", "nll_loss": "4.529", "total": "662.155", "n_correct": "338.85", "ppl": "23.09", "accuracy": "51.174", "wps": "659.1", "ups": "1", "wpb": "662.2", "bsz": "26.3", "num_updates": "6400", "lr": "0.0004324", "gnorm": "1.21", "loss_scale": "64", "train_wall": "195", "gb_free": "10.9", "wall": "0"}
[2025-01-17 12:10:06,708][train_inner][INFO] - {"epoch": 39, "update": 38.17, "loss": "121.26", "nll_loss": "4.384", "total": "667.79", "n_correct": "349.25", "ppl": "20.87", "accuracy": "52.299", "wps": "629.9", "ups": "0.94", "wpb": "667.8", "bsz": "28.7", "num_updates": "6600", "lr": "0.0004456", "gnorm": "1.321", "loss_scale": "64", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:13:38,679][train_inner][INFO] - {"epoch": 39, "update": 38.204, "loss": "125.334", "nll_loss": "4.43", "total": "668.775", "n_correct": "347.245", "ppl": "21.55", "accuracy": "51.923", "wps": "631", "ups": "0.94", "wpb": "668.8", "bsz": "28.1", "num_updates": "6800", "lr": "0.0004588", "gnorm": "1.125", "loss_scale": "64", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:17:08,977][train_inner][INFO] - {"epoch": 39, "update": 38.238, "loss": "124.408", "nll_loss": "4.422", "total": "664.89", "n_correct": "345.52", "ppl": "21.43", "accuracy": "51.966", "wps": "632.4", "ups": "0.95", "wpb": "664.9", "bsz": "28.1", "num_updates": "7000", "lr": "0.000472", "gnorm": "1.31", "loss_scale": "64", "train_wall": "204", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:20:34,992][train_inner][INFO] - {"epoch": 39, "update": 38.273, "loss": "133.9", "nll_loss": "4.655", "total": "671.965", "n_correct": "334.66", "ppl": "25.2", "accuracy": "49.803", "wps": "652.4", "ups": "0.97", "wpb": "672", "bsz": "27.4", "num_updates": "7200", "lr": "0.0004852", "gnorm": "1.315", "loss_scale": "64", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 12:24:06,345][train_inner][INFO] - {"epoch": 39, "update": 38.307, "loss": "123.73", "nll_loss": "4.506", "total": "666.9", "n_correct": "341.31", "ppl": "22.72", "accuracy": "51.179", "wps": "631.2", "ups": "0.95", "wpb": "666.9", "bsz": "28.7", "num_updates": "7400", "lr": "0.0004984", "gnorm": "1.186", "loss_scale": "64", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:27:33,756][train_inner][INFO] - {"epoch": 39, "update": 38.341, "loss": "130.54", "nll_loss": "4.59", "total": "657.64", "n_correct": "333.835", "ppl": "24.08", "accuracy": "50.763", "wps": "634.3", "ups": "0.96", "wpb": "657.6", "bsz": "27.2", "num_updates": "7600", "lr": "0.0005116", "gnorm": "1.196", "loss_scale": "64", "train_wall": "201", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:31:03,257][train_inner][INFO] - {"epoch": 39, "update": 38.375, "loss": "124.619", "nll_loss": "4.439", "total": "669.825", "n_correct": "346.87", "ppl": "21.69", "accuracy": "51.785", "wps": "639.5", "ups": "0.95", "wpb": "669.8", "bsz": "28.3", "num_updates": "7800", "lr": "0.0005248", "gnorm": "1.108", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 12:34:28,589][train_inner][INFO] - {"epoch": 39, "update": 38.409, "loss": "127.718", "nll_loss": "4.522", "total": "656.495", "n_correct": "335.73", "ppl": "22.98", "accuracy": "51.14", "wps": "639.6", "ups": "0.97", "wpb": "656.5", "bsz": "27.5", "num_updates": "8000", "lr": "0.000538", "gnorm": "1.157", "loss_scale": "64", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:37:55,076][train_inner][INFO] - {"epoch": 39, "update": 38.443, "loss": "131.162", "nll_loss": "4.56", "total": "663.715", "n_correct": "337.39", "ppl": "23.59", "accuracy": "50.834", "wps": "642.9", "ups": "0.97", "wpb": "663.7", "bsz": "27.2", "num_updates": "8200", "lr": "0.0005512", "gnorm": "1.523", "loss_scale": "128", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:41:22,780][train_inner][INFO] - {"epoch": 39, "update": 38.477, "loss": "122.196", "nll_loss": "4.423", "total": "660.73", "n_correct": "342.875", "ppl": "21.44", "accuracy": "51.893", "wps": "636.3", "ups": "0.96", "wpb": "660.7", "bsz": "28.4", "num_updates": "8400", "lr": "0.0005644", "gnorm": "1.357", "loss_scale": "128", "train_wall": "201", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:44:50,269][train_inner][INFO] - {"epoch": 39, "update": 38.511, "loss": "127.327", "nll_loss": "4.555", "total": "666.335", "n_correct": "338.89", "ppl": "23.51", "accuracy": "50.859", "wps": "642.4", "ups": "0.96", "wpb": "666.3", "bsz": "28.1", "num_updates": "8600", "lr": "0.0005776", "gnorm": "1.8", "loss_scale": "128", "train_wall": "201", "gb_free": "10.9", "wall": "0"}
[2025-01-17 12:48:20,777][train_inner][INFO] - {"epoch": 39, "update": 38.546, "loss": "120.188", "nll_loss": "4.365", "total": "667.075", "n_correct": "350.185", "ppl": "20.6", "accuracy": "52.496", "wps": "633.8", "ups": "0.95", "wpb": "667.1", "bsz": "28.9", "num_updates": "8800", "lr": "0.0005908", "gnorm": "1.783", "loss_scale": "128", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 12:51:56,066][train_inner][INFO] - {"epoch": 39, "update": 38.58, "loss": "124.421", "nll_loss": "4.518", "total": "665.56", "n_correct": "339.87", "ppl": "22.91", "accuracy": "51.065", "wps": "618.3", "ups": "0.93", "wpb": "665.6", "bsz": "28.5", "num_updates": "9000", "lr": "0.000604", "gnorm": "1.893", "loss_scale": "128", "train_wall": "209", "gb_free": "10.8", "wall": "0"}
[2025-01-17 12:55:27,840][train_inner][INFO] - {"epoch": 39, "update": 38.614, "loss": "119.722", "nll_loss": "4.341", "total": "665.985", "n_correct": "349.89", "ppl": "20.26", "accuracy": "52.537", "wps": "629", "ups": "0.94", "wpb": "666", "bsz": "28.8", "num_updates": "9200", "lr": "0.0006172", "gnorm": "1.549", "loss_scale": "128", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 12:58:50,006][train_inner][INFO] - {"epoch": 39, "update": 38.648, "loss": "128.599", "nll_loss": "4.525", "total": "664.07", "n_correct": "338.87", "ppl": "23.02", "accuracy": "51.029", "wps": "657", "ups": "0.99", "wpb": "664.1", "bsz": "27.6", "num_updates": "9400", "lr": "0.0006304", "gnorm": "1.251", "loss_scale": "128", "train_wall": "196", "gb_free": "10.9", "wall": "0"}
[2025-01-17 13:02:20,503][train_inner][INFO] - {"epoch": 39, "update": 38.682, "loss": "126.447", "nll_loss": "4.491", "total": "673.83", "n_correct": "346.665", "ppl": "22.49", "accuracy": "51.447", "wps": "640.3", "ups": "0.95", "wpb": "673.8", "bsz": "28.3", "num_updates": "9600", "lr": "0.0006436", "gnorm": "1.578", "loss_scale": "128", "train_wall": "204", "gb_free": "11", "wall": "0"}
[2025-01-17 13:05:46,082][train_inner][INFO] - {"epoch": 39, "update": 38.716, "loss": "124.582", "nll_loss": "4.43", "total": "662.915", "n_correct": "344.33", "ppl": "21.56", "accuracy": "51.942", "wps": "645", "ups": "0.97", "wpb": "662.9", "bsz": "28", "num_updates": "9800", "lr": "0.0006568", "gnorm": "1.133", "loss_scale": "128", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 13:09:21,247][train_inner][INFO] - {"epoch": 39, "update": 38.75, "loss": "116.276", "nll_loss": "4.398", "total": "667.665", "n_correct": "349.14", "ppl": "21.09", "accuracy": "52.293", "wps": "620.7", "ups": "0.93", "wpb": "667.7", "bsz": "30", "num_updates": "10000", "lr": "0.00067", "gnorm": "1.432", "loss_scale": "128", "train_wall": "209", "gb_free": "10.9", "wall": "0"}
[2025-01-17 13:12:51,016][train_inner][INFO] - {"epoch": 39, "update": 38.784, "loss": "125.486", "nll_loss": "4.446", "total": "672.095", "n_correct": "346.925", "ppl": "21.8", "accuracy": "51.618", "wps": "640.8", "ups": "0.95", "wpb": "672.1", "bsz": "28.2", "num_updates": "10200", "lr": "0.0006832", "gnorm": "1.615", "loss_scale": "128", "train_wall": "203", "gb_free": "10.9", "wall": "0"}
[2025-01-17 13:16:19,048][train_inner][INFO] - {"epoch": 39, "update": 38.818, "loss": "126.627", "nll_loss": "4.459", "total": "666.41", "n_correct": "343.275", "ppl": "22", "accuracy": "51.511", "wps": "640.7", "ups": "0.96", "wpb": "666.4", "bsz": "27.8", "num_updates": "10400", "lr": "0.0006964", "gnorm": "1.641", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:19:35,358][train_inner][INFO] - {"epoch": 39, "update": 38.853, "loss": "134.482", "nll_loss": "4.599", "total": "663.605", "n_correct": "334.865", "ppl": "24.23", "accuracy": "50.461", "wps": "676.1", "ups": "1.02", "wpb": "663.6", "bsz": "26.7", "num_updates": "10600", "lr": "0.0007096", "gnorm": "2.132", "loss_scale": "128", "train_wall": "190", "gb_free": "11", "wall": "0"}
[2025-01-17 13:23:03,134][train_inner][INFO] - {"epoch": 39, "update": 38.887, "loss": "125.719", "nll_loss": "4.523", "total": "665.755", "n_correct": "339.975", "ppl": "22.99", "accuracy": "51.066", "wps": "640.9", "ups": "0.96", "wpb": "665.8", "bsz": "28.3", "num_updates": "10800", "lr": "0.0007228", "gnorm": "1.798", "loss_scale": "128", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:26:20,020][train_inner][INFO] - {"epoch": 39, "update": 38.921, "loss": "135.817", "nll_loss": "4.626", "total": "659.385", "n_correct": "329.445", "ppl": "24.7", "accuracy": "49.962", "wps": "669.8", "ups": "1.02", "wpb": "659.4", "bsz": "26.4", "num_updates": "11000", "lr": "0.000736", "gnorm": "1.633", "loss_scale": "128", "train_wall": "190", "gb_free": "10.7", "wall": "0"}
[2025-01-17 13:29:43,919][train_inner][INFO] - {"epoch": 39, "update": 38.955, "loss": "124.965", "nll_loss": "4.458", "total": "660.9", "n_correct": "341.34", "ppl": "21.98", "accuracy": "51.648", "wps": "648.3", "ups": "0.98", "wpb": "660.9", "bsz": "27.9", "num_updates": "11200", "lr": "0.0007492", "gnorm": "1.563", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:33:09,447][train_inner][INFO] - {"epoch": 39, "update": 38.989, "loss": "129.749", "nll_loss": "4.503", "total": "667.895", "n_correct": "341.01", "ppl": "22.67", "accuracy": "51.057", "wps": "649.9", "ups": "0.97", "wpb": "667.9", "bsz": "27.4", "num_updates": "11400", "lr": "0.0007624", "gnorm": "1.648", "loss_scale": "128", "train_wall": "199", "gb_free": "10.9", "wall": "0"}
[2025-01-17 13:34:02,028][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2025-01-17 13:34:02,032][train][INFO] - {"epoch": 39, "train_loss": "126.578", "train_nll_loss": "4.491", "train_total": "665.831", "train_n_correct": "341.971", "train_ppl": "22.49", "train_accuracy": "51.36", "train_wps": "638.3", "train_ups": "0.96", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "11464", "train_lr": "0.000766624", "train_gnorm": "1.442", "train_loss_scale": "128", "train_train_wall": "5883", "train_gb_free": "10.8", "train_wall": "0"}
[2025-01-17 13:34:03,249][fairseq.trainer][INFO] - begin training epoch 40
[2025-01-17 13:34:03,249][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 13:37:06,422][train_inner][INFO] - {"epoch": 40, "update": 39.023, "loss": "117.166", "nll_loss": "4.408", "total": "659.905", "n_correct": "344.665", "ppl": "21.23", "accuracy": "52.229", "wps": "557", "ups": "0.84", "wpb": "659.9", "bsz": "29.5", "num_updates": "11600", "lr": "0.0007756", "gnorm": "1.44", "loss_scale": "128", "train_wall": "194", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:40:35,964][train_inner][INFO] - {"epoch": 40, "update": 39.057, "loss": "124.015", "nll_loss": "4.467", "total": "658.755", "n_correct": "338.635", "ppl": "22.11", "accuracy": "51.405", "wps": "628.8", "ups": "0.95", "wpb": "658.8", "bsz": "28.1", "num_updates": "11800", "lr": "0.0007888", "gnorm": "1.585", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:43:55,301][train_inner][INFO] - {"epoch": 40, "update": 39.091, "loss": "136.009", "nll_loss": "4.636", "total": "656.685", "n_correct": "327.81", "ppl": "24.87", "accuracy": "49.919", "wps": "658.9", "ups": "1", "wpb": "656.7", "bsz": "26.3", "num_updates": "12000", "lr": "0.000802", "gnorm": "1.714", "loss_scale": "128", "train_wall": "192", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:47:19,434][train_inner][INFO] - {"epoch": 40, "update": 39.126, "loss": "132.368", "nll_loss": "4.639", "total": "663.94", "n_correct": "331.34", "ppl": "24.92", "accuracy": "49.905", "wps": "650.6", "ups": "0.98", "wpb": "663.9", "bsz": "27.3", "num_updates": "12200", "lr": "0.0008152", "gnorm": "1.775", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 13:50:53,421][train_inner][INFO] - {"epoch": 40, "update": 39.16, "loss": "115.499", "nll_loss": "4.308", "total": "654.595", "n_correct": "347.22", "ppl": "19.81", "accuracy": "53.043", "wps": "611.8", "ups": "0.93", "wpb": "654.6", "bsz": "29.2", "num_updates": "12400", "lr": "0.0008284", "gnorm": "1.485", "loss_scale": "256", "train_wall": "207", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:52:01,809][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2025-01-17 13:54:29,694][train_inner][INFO] - {"epoch": 40, "update": 39.194, "loss": "119.332", "nll_loss": "4.405", "total": "665.09", "n_correct": "346.535", "ppl": "21.19", "accuracy": "52.103", "wps": "615.1", "ups": "0.92", "wpb": "665.1", "bsz": "29.2", "num_updates": "12600", "lr": "0.0008416", "gnorm": "1.457", "loss_scale": "128", "train_wall": "210", "gb_free": "10.8", "wall": "0"}
[2025-01-17 13:57:55,945][train_inner][INFO] - {"epoch": 40, "update": 39.228, "loss": "128.814", "nll_loss": "4.563", "total": "667.75", "n_correct": "339.5", "ppl": "23.65", "accuracy": "50.842", "wps": "647.5", "ups": "0.97", "wpb": "667.8", "bsz": "27.9", "num_updates": "12800", "lr": "0.0008548", "gnorm": "1.383", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:01:24,671][train_inner][INFO] - {"epoch": 40, "update": 39.262, "loss": "125.371", "nll_loss": "4.406", "total": "669.605", "n_correct": "349.055", "ppl": "21.2", "accuracy": "52.128", "wps": "641.6", "ups": "0.96", "wpb": "669.6", "bsz": "28", "num_updates": "13000", "lr": "0.000868", "gnorm": "1.745", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:04:51,757][train_inner][INFO] - {"epoch": 40, "update": 39.296, "loss": "125.484", "nll_loss": "4.453", "total": "665.41", "n_correct": "343.865", "ppl": "21.9", "accuracy": "51.677", "wps": "642.7", "ups": "0.97", "wpb": "665.4", "bsz": "28", "num_updates": "13200", "lr": "0.0008812", "gnorm": "1.883", "loss_scale": "128", "train_wall": "200", "gb_free": "10.7", "wall": "0"}
[2025-01-17 14:08:20,821][train_inner][INFO] - {"epoch": 40, "update": 39.33, "loss": "126.465", "nll_loss": "4.507", "total": "670.235", "n_correct": "343.06", "ppl": "22.73", "accuracy": "51.185", "wps": "641.3", "ups": "0.96", "wpb": "670.2", "bsz": "28.2", "num_updates": "13400", "lr": "0.0008944", "gnorm": "1.855", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:11:49,019][train_inner][INFO] - {"epoch": 40, "update": 39.365, "loss": "123.768", "nll_loss": "4.433", "total": "668.115", "n_correct": "345.765", "ppl": "21.6", "accuracy": "51.752", "wps": "641.9", "ups": "0.96", "wpb": "668.1", "bsz": "28.4", "num_updates": "13600", "lr": "0.0009076", "gnorm": "1.676", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:15:25,664][train_inner][INFO] - {"epoch": 40, "update": 39.399, "loss": "119.814", "nll_loss": "4.452", "total": "667.4", "n_correct": "345.185", "ppl": "21.89", "accuracy": "51.721", "wps": "616.2", "ups": "0.92", "wpb": "667.4", "bsz": "29.4", "num_updates": "13800", "lr": "0.0009208", "gnorm": "1.633", "loss_scale": "128", "train_wall": "210", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:18:46,069][train_inner][INFO] - {"epoch": 40, "update": 39.433, "loss": "134.234", "nll_loss": "4.582", "total": "669.225", "n_correct": "336.955", "ppl": "23.96", "accuracy": "50.35", "wps": "668", "ups": "1", "wpb": "669.2", "bsz": "26.9", "num_updates": "14000", "lr": "0.000934", "gnorm": "1.933", "loss_scale": "128", "train_wall": "194", "gb_free": "10.7", "wall": "0"}
[2025-01-17 14:22:10,768][train_inner][INFO] - {"epoch": 40, "update": 39.467, "loss": "128.116", "nll_loss": "4.471", "total": "664.93", "n_correct": "341.75", "ppl": "22.18", "accuracy": "51.396", "wps": "649.7", "ups": "0.98", "wpb": "664.9", "bsz": "27.5", "num_updates": "14200", "lr": "0.0009472", "gnorm": "1.945", "loss_scale": "128", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 14:25:35,027][train_inner][INFO] - {"epoch": 40, "update": 39.501, "loss": "129.746", "nll_loss": "4.469", "total": "666.205", "n_correct": "341.77", "ppl": "22.14", "accuracy": "51.301", "wps": "652.3", "ups": "0.98", "wpb": "666.2", "bsz": "27.2", "num_updates": "14400", "lr": "0.0009604", "gnorm": "2.019", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:29:06,144][train_inner][INFO] - {"epoch": 40, "update": 39.535, "loss": "123.523", "nll_loss": "4.465", "total": "667.105", "n_correct": "343.955", "ppl": "22.09", "accuracy": "51.559", "wps": "632", "ups": "0.95", "wpb": "667.1", "bsz": "28.6", "num_updates": "14600", "lr": "0.0009736", "gnorm": "1.989", "loss_scale": "128", "train_wall": "204", "gb_free": "10.9", "wall": "0"}
[2025-01-17 14:32:37,402][train_inner][INFO] - {"epoch": 40, "update": 39.569, "loss": "125.41", "nll_loss": "4.569", "total": "665.715", "n_correct": "337.305", "ppl": "23.73", "accuracy": "50.668", "wps": "630.3", "ups": "0.95", "wpb": "665.7", "bsz": "28.6", "num_updates": "14800", "lr": "0.0009868", "gnorm": "2.288", "loss_scale": "128", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:35:11,699][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2025-01-17 14:36:01,657][train_inner][INFO] - {"epoch": 40, "update": 39.604, "loss": "132.552", "nll_loss": "4.506", "total": "674.145", "n_correct": "345.035", "ppl": "22.72", "accuracy": "51.181", "wps": "660.2", "ups": "0.98", "wpb": "674.1", "bsz": "27.1", "num_updates": "15000", "lr": "0.001", "gnorm": "3.333", "loss_scale": "64", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:39:36,858][train_inner][INFO] - {"epoch": 40, "update": 39.638, "loss": "117.513", "nll_loss": "4.365", "total": "665.825", "n_correct": "348.1", "ppl": "20.61", "accuracy": "52.281", "wps": "618.8", "ups": "0.93", "wpb": "665.8", "bsz": "29.5", "num_updates": "15200", "lr": "0.000980227", "gnorm": "2.617", "loss_scale": "64", "train_wall": "208", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:43:05,496][train_inner][INFO] - {"epoch": 40, "update": 39.672, "loss": "125.081", "nll_loss": "4.458", "total": "663.145", "n_correct": "344.51", "ppl": "21.98", "accuracy": "51.951", "wps": "635.7", "ups": "0.96", "wpb": "663.1", "bsz": "28", "num_updates": "15400", "lr": "0.000960844", "gnorm": "1.847", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:46:32,579][train_inner][INFO] - {"epoch": 40, "update": 39.706, "loss": "124.826", "nll_loss": "4.423", "total": "663.51", "n_correct": "343.4", "ppl": "21.44", "accuracy": "51.755", "wps": "640.8", "ups": "0.97", "wpb": "663.5", "bsz": "27.9", "num_updates": "15600", "lr": "0.000941845", "gnorm": "2.071", "loss_scale": "64", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 14:50:02,486][train_inner][INFO] - {"epoch": 40, "update": 39.74, "loss": "124.456", "nll_loss": "4.407", "total": "664.92", "n_correct": "346.345", "ppl": "21.21", "accuracy": "52.088", "wps": "633.8", "ups": "0.95", "wpb": "664.9", "bsz": "28", "num_updates": "15800", "lr": "0.000923221", "gnorm": "1.712", "loss_scale": "64", "train_wall": "203", "gb_free": "10.7", "wall": "0"}
[2025-01-17 14:53:27,461][train_inner][INFO] - {"epoch": 40, "update": 39.774, "loss": "124.552", "nll_loss": "4.47", "total": "669.355", "n_correct": "343.405", "ppl": "22.16", "accuracy": "51.304", "wps": "653.2", "ups": "0.98", "wpb": "669.4", "bsz": "28.4", "num_updates": "16000", "lr": "0.000904966", "gnorm": "1.562", "loss_scale": "64", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 14:56:51,178][train_inner][INFO] - {"epoch": 40, "update": 39.808, "loss": "131.624", "nll_loss": "4.521", "total": "669.59", "n_correct": "340.315", "ppl": "22.97", "accuracy": "50.824", "wps": "657.5", "ups": "0.98", "wpb": "669.6", "bsz": "27.1", "num_updates": "16200", "lr": "0.000887072", "gnorm": "2.298", "loss_scale": "64", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:00:19,213][train_inner][INFO] - {"epoch": 40, "update": 39.842, "loss": "128.242", "nll_loss": "4.522", "total": "672.77", "n_correct": "343.91", "ppl": "22.98", "accuracy": "51.119", "wps": "646.8", "ups": "0.96", "wpb": "672.8", "bsz": "28", "num_updates": "16400", "lr": "0.000869531", "gnorm": "2.712", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:03:43,411][train_inner][INFO] - {"epoch": 40, "update": 39.876, "loss": "134.935", "nll_loss": "4.648", "total": "673.705", "n_correct": "337.26", "ppl": "25.07", "accuracy": "50.06", "wps": "660.1", "ups": "0.98", "wpb": "673.7", "bsz": "27.2", "num_updates": "16600", "lr": "0.000852338", "gnorm": "2.012", "loss_scale": "64", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:07:09,093][train_inner][INFO] - {"epoch": 40, "update": 39.911, "loss": "125.414", "nll_loss": "4.439", "total": "660.645", "n_correct": "341.19", "ppl": "21.69", "accuracy": "51.645", "wps": "642.4", "ups": "0.97", "wpb": "660.6", "bsz": "27.7", "num_updates": "16800", "lr": "0.000835484", "gnorm": "1.887", "loss_scale": "64", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:10:30,048][train_inner][INFO] - {"epoch": 40, "update": 39.945, "loss": "129.853", "nll_loss": "4.502", "total": "665.155", "n_correct": "339.935", "ppl": "22.65", "accuracy": "51.106", "wps": "662", "ups": "1", "wpb": "665.2", "bsz": "27.2", "num_updates": "17000", "lr": "0.000818964", "gnorm": "2.053", "loss_scale": "64", "train_wall": "194", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:13:56,017][train_inner][INFO] - {"epoch": 40, "update": 39.979, "loss": "128.542", "nll_loss": "4.513", "total": "661.995", "n_correct": "338.585", "ppl": "22.83", "accuracy": "51.146", "wps": "642.8", "ups": "0.97", "wpb": "662", "bsz": "27.5", "num_updates": "17200", "lr": "0.00080277", "gnorm": "1.658", "loss_scale": "64", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 15:15:48,055][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-17 15:16:41,224][valid][INFO] - {"epoch": 40, "valid_loss": "39.978", "valid_nll_loss": "2.069", "valid_total": "678.4", "valid_n_correct": "499", "valid_ppl": "4.2", "valid_accuracy": "73.555", "valid_wps": "431", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "17324", "valid_best_accuracy": "73.688"}
[2025-01-17 15:16:41,226][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 17324 updates
[2025-01-17 15:16:41,227][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 15:16:45,962][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 15:16:45,967][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 17324 updates, score 73.555) (writing took 4.7406612718477845 seconds)
[2025-01-17 15:16:45,968][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2025-01-17 15:16:45,972][train][INFO] - {"epoch": 40, "train_loss": "126.425", "train_nll_loss": "4.485", "train_total": "665.827", "train_n_correct": "341.895", "train_ppl": "22.4", "train_accuracy": "51.349", "train_wps": "633", "train_ups": "0.95", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "17324", "train_lr": "0.000792891", "train_gnorm": "1.924", "train_loss_scale": "64", "train_train_wall": "5876", "train_gb_free": "10.7", "train_wall": "0"}
[2025-01-17 15:16:46,600][fairseq.trainer][INFO] - begin training epoch 41
[2025-01-17 15:16:46,601][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 15:18:46,779][train_inner][INFO] - {"epoch": 41, "update": 40.013, "loss": "124.37", "nll_loss": "4.434", "total": "670.62", "n_correct": "348.63", "ppl": "21.62", "accuracy": "51.986", "wps": "461.3", "ups": "0.69", "wpb": "670.6", "bsz": "28.4", "num_updates": "17400", "lr": "0.000786896", "gnorm": "1.965", "loss_scale": "64", "train_wall": "187", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:22:18,260][train_inner][INFO] - {"epoch": 41, "update": 40.047, "loss": "125.533", "nll_loss": "4.416", "total": "670.22", "n_correct": "348.555", "ppl": "21.35", "accuracy": "52.006", "wps": "633.9", "ups": "0.95", "wpb": "670.2", "bsz": "28", "num_updates": "17600", "lr": "0.000771337", "gnorm": "1.964", "loss_scale": "64", "train_wall": "204", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:25:55,849][train_inner][INFO] - {"epoch": 41, "update": 40.081, "loss": "121.144", "nll_loss": "4.394", "total": "665.81", "n_correct": "346.415", "ppl": "21.02", "accuracy": "52.029", "wps": "612.1", "ups": "0.92", "wpb": "665.8", "bsz": "28.7", "num_updates": "17800", "lr": "0.000756085", "gnorm": "1.692", "loss_scale": "64", "train_wall": "210", "gb_free": "10.9", "wall": "0"}
[2025-01-17 15:29:26,016][train_inner][INFO] - {"epoch": 41, "update": 40.115, "loss": "122.96", "nll_loss": "4.493", "total": "664.405", "n_correct": "341.645", "ppl": "22.52", "accuracy": "51.421", "wps": "632.3", "ups": "0.95", "wpb": "664.4", "bsz": "28.7", "num_updates": "18000", "lr": "0.000741134", "gnorm": "1.684", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:32:50,774][train_inner][INFO] - {"epoch": 41, "update": 40.149, "loss": "131.334", "nll_loss": "4.534", "total": "671.495", "n_correct": "341.58", "ppl": "23.17", "accuracy": "50.869", "wps": "655.9", "ups": "0.98", "wpb": "671.5", "bsz": "27.3", "num_updates": "18200", "lr": "0.00072648", "gnorm": "1.617", "loss_scale": "64", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:36:20,551][train_inner][INFO] - {"epoch": 41, "update": 40.184, "loss": "125.893", "nll_loss": "4.552", "total": "666.26", "n_correct": "337.77", "ppl": "23.46", "accuracy": "50.696", "wps": "635.3", "ups": "0.95", "wpb": "666.3", "bsz": "28.4", "num_updates": "18400", "lr": "0.000712115", "gnorm": "1.71", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:39:41,739][train_inner][INFO] - {"epoch": 41, "update": 40.218, "loss": "137.895", "nll_loss": "4.668", "total": "667.84", "n_correct": "331.56", "ppl": "25.42", "accuracy": "49.647", "wps": "664", "ups": "0.99", "wpb": "667.8", "bsz": "26.5", "num_updates": "18600", "lr": "0.000698034", "gnorm": "2.095", "loss_scale": "64", "train_wall": "194", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:43:08,890][train_inner][INFO] - {"epoch": 41, "update": 40.252, "loss": "127.984", "nll_loss": "4.494", "total": "659.355", "n_correct": "337.415", "ppl": "22.53", "accuracy": "51.173", "wps": "636.6", "ups": "0.97", "wpb": "659.4", "bsz": "27.4", "num_updates": "18800", "lr": "0.000684231", "gnorm": "1.722", "loss_scale": "64", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:46:42,545][train_inner][INFO] - {"epoch": 41, "update": 40.286, "loss": "120.614", "nll_loss": "4.418", "total": "664.3", "n_correct": "344.88", "ppl": "21.37", "accuracy": "51.916", "wps": "621.9", "ups": "0.94", "wpb": "664.3", "bsz": "28.9", "num_updates": "19000", "lr": "0.000670702", "gnorm": "1.913", "loss_scale": "64", "train_wall": "207", "gb_free": "10.7", "wall": "0"}
[2025-01-17 15:50:13,156][train_inner][INFO] - {"epoch": 41, "update": 40.32, "loss": "125.732", "nll_loss": "4.433", "total": "663.295", "n_correct": "343.825", "ppl": "21.6", "accuracy": "51.836", "wps": "629.9", "ups": "0.95", "wpb": "663.3", "bsz": "27.8", "num_updates": "19200", "lr": "0.00065744", "gnorm": "1.319", "loss_scale": "128", "train_wall": "204", "gb_free": "10.9", "wall": "0"}
[2025-01-17 15:53:43,610][train_inner][INFO] - {"epoch": 41, "update": 40.354, "loss": "118.252", "nll_loss": "4.325", "total": "668.16", "n_correct": "352.75", "ppl": "20.05", "accuracy": "52.794", "wps": "635.1", "ups": "0.95", "wpb": "668.2", "bsz": "29.2", "num_updates": "19400", "lr": "0.00064444", "gnorm": "1.624", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 15:57:14,104][train_inner][INFO] - {"epoch": 41, "update": 40.388, "loss": "129.175", "nll_loss": "4.505", "total": "666.655", "n_correct": "341.51", "ppl": "22.71", "accuracy": "51.227", "wps": "633.4", "ups": "0.95", "wpb": "666.7", "bsz": "27.5", "num_updates": "19600", "lr": "0.000631697", "gnorm": "2.484", "loss_scale": "128", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:00:40,768][train_inner][INFO] - {"epoch": 41, "update": 40.422, "loss": "127.095", "nll_loss": "4.493", "total": "668.705", "n_correct": "342.825", "ppl": "22.52", "accuracy": "51.267", "wps": "647.2", "ups": "0.97", "wpb": "668.7", "bsz": "27.9", "num_updates": "19800", "lr": "0.000619206", "gnorm": "1.843", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:04:07,268][train_inner][INFO] - {"epoch": 41, "update": 40.456, "loss": "124.857", "nll_loss": "4.457", "total": "665.005", "n_correct": "342.86", "ppl": "21.96", "accuracy": "51.558", "wps": "644.1", "ups": "0.97", "wpb": "665", "bsz": "28.1", "num_updates": "20000", "lr": "0.000606962", "gnorm": "1.645", "loss_scale": "128", "train_wall": "201", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:07:36,125][train_inner][INFO] - {"epoch": 41, "update": 40.491, "loss": "129.215", "nll_loss": "4.513", "total": "662.265", "n_correct": "337", "ppl": "22.84", "accuracy": "50.886", "wps": "634.2", "ups": "0.96", "wpb": "662.3", "bsz": "27.3", "num_updates": "20200", "lr": "0.000594961", "gnorm": "2.084", "loss_scale": "128", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 16:10:57,739][train_inner][INFO] - {"epoch": 41, "update": 40.525, "loss": "136.287", "nll_loss": "4.726", "total": "668.89", "n_correct": "329.76", "ppl": "26.47", "accuracy": "49.3", "wps": "663.6", "ups": "0.99", "wpb": "668.9", "bsz": "27.1", "num_updates": "20400", "lr": "0.000583196", "gnorm": "1.912", "loss_scale": "128", "train_wall": "195", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:14:28,176][train_inner][INFO] - {"epoch": 41, "update": 40.559, "loss": "121.767", "nll_loss": "4.383", "total": "668.215", "n_correct": "348.79", "ppl": "20.86", "accuracy": "52.197", "wps": "635.2", "ups": "0.95", "wpb": "668.2", "bsz": "28.6", "num_updates": "20600", "lr": "0.000571664", "gnorm": "2.164", "loss_scale": "128", "train_wall": "203", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:17:55,032][train_inner][INFO] - {"epoch": 41, "update": 40.593, "loss": "124.464", "nll_loss": "4.395", "total": "672.35", "n_correct": "350.785", "ppl": "21.05", "accuracy": "52.173", "wps": "650.1", "ups": "0.97", "wpb": "672.4", "bsz": "28.2", "num_updates": "20800", "lr": "0.000560361", "gnorm": "1.526", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:21:17,032][train_inner][INFO] - {"epoch": 41, "update": 40.627, "loss": "134.457", "nll_loss": "4.619", "total": "663.4", "n_correct": "331.805", "ppl": "24.58", "accuracy": "50.016", "wps": "656.9", "ups": "0.99", "wpb": "663.4", "bsz": "26.8", "num_updates": "21000", "lr": "0.00054928", "gnorm": "1.962", "loss_scale": "128", "train_wall": "195", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:24:44,726][train_inner][INFO] - {"epoch": 41, "update": 40.661, "loss": "125.066", "nll_loss": "4.492", "total": "660.56", "n_correct": "339.4", "ppl": "22.5", "accuracy": "51.381", "wps": "636.2", "ups": "0.96", "wpb": "660.6", "bsz": "28.1", "num_updates": "21200", "lr": "0.000538419", "gnorm": "1.66", "loss_scale": "128", "train_wall": "201", "gb_free": "10.7", "wall": "0"}
[2025-01-17 16:28:14,239][train_inner][INFO] - {"epoch": 41, "update": 40.695, "loss": "127.347", "nll_loss": "4.518", "total": "667.24", "n_correct": "340.72", "ppl": "22.91", "accuracy": "51.064", "wps": "637", "ups": "0.95", "wpb": "667.2", "bsz": "27.9", "num_updates": "21400", "lr": "0.000527773", "gnorm": "1.386", "loss_scale": "128", "train_wall": "203", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:31:46,355][train_inner][INFO] - {"epoch": 41, "update": 40.729, "loss": "120.252", "nll_loss": "4.434", "total": "662.18", "n_correct": "342.615", "ppl": "21.62", "accuracy": "51.74", "wps": "624.4", "ups": "0.94", "wpb": "662.2", "bsz": "29", "num_updates": "21600", "lr": "0.000517337", "gnorm": "1.493", "loss_scale": "128", "train_wall": "205", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:35:17,684][train_inner][INFO] - {"epoch": 41, "update": 40.764, "loss": "122.821", "nll_loss": "4.462", "total": "660.69", "n_correct": "339.465", "ppl": "22.05", "accuracy": "51.38", "wps": "625.3", "ups": "0.95", "wpb": "660.7", "bsz": "28.4", "num_updates": "21800", "lr": "0.000507107", "gnorm": "1.561", "loss_scale": "128", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 16:38:43,016][train_inner][INFO] - {"epoch": 41, "update": 40.798, "loss": "128.413", "nll_loss": "4.544", "total": "666.97", "n_correct": "339.5", "ppl": "23.33", "accuracy": "50.902", "wps": "649.7", "ups": "0.97", "wpb": "667", "bsz": "27.8", "num_updates": "22000", "lr": "0.00049708", "gnorm": "1.654", "loss_scale": "128", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:42:10,966][train_inner][INFO] - {"epoch": 41, "update": 40.832, "loss": "126.749", "nll_loss": "4.435", "total": "665.745", "n_correct": "344.275", "ppl": "21.62", "accuracy": "51.713", "wps": "640.3", "ups": "0.96", "wpb": "665.7", "bsz": "27.6", "num_updates": "22200", "lr": "0.000487251", "gnorm": "1.804", "loss_scale": "128", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 16:45:37,251][train_inner][INFO] - {"epoch": 41, "update": 40.866, "loss": "124.515", "nll_loss": "4.447", "total": "666.215", "n_correct": "345.415", "ppl": "21.82", "accuracy": "51.847", "wps": "645.9", "ups": "0.97", "wpb": "666.2", "bsz": "28.2", "num_updates": "22400", "lr": "0.000477616", "gnorm": "1.729", "loss_scale": "128", "train_wall": "200", "gb_free": "10.6", "wall": "0"}
[2025-01-17 16:48:09,674][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2025-01-17 16:49:06,754][train_inner][INFO] - {"epoch": 41, "update": 40.9, "loss": "123.74", "nll_loss": "4.399", "total": "663.62", "n_correct": "344.675", "ppl": "21.1", "accuracy": "51.939", "wps": "633.6", "ups": "0.95", "wpb": "663.6", "bsz": "28", "num_updates": "22600", "lr": "0.000468172", "gnorm": "2.029", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:52:30,269][train_inner][INFO] - {"epoch": 41, "update": 40.934, "loss": "127.33", "nll_loss": "4.41", "total": "658.645", "n_correct": "341.05", "ppl": "21.26", "accuracy": "51.781", "wps": "647.3", "ups": "0.98", "wpb": "658.6", "bsz": "27.1", "num_updates": "22800", "lr": "0.000458915", "gnorm": "1.648", "loss_scale": "64", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 16:55:52,473][train_inner][INFO] - {"epoch": 41, "update": 40.968, "loss": "135.22", "nll_loss": "4.542", "total": "671.4", "n_correct": "341.05", "ppl": "23.29", "accuracy": "50.797", "wps": "664.2", "ups": "0.99", "wpb": "671.4", "bsz": "26.6", "num_updates": "23000", "lr": "0.000449841", "gnorm": "1.619", "loss_scale": "64", "train_wall": "196", "gb_free": "10.9", "wall": "0"}
[2025-01-17 16:58:49,503][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2025-01-17 16:58:49,507][train][INFO] - {"epoch": 41, "train_loss": "126.336", "train_nll_loss": "4.482", "train_total": "665.819", "train_n_correct": "341.877", "train_ppl": "22.34", "train_accuracy": "51.347", "train_wps": "637.3", "train_ups": "0.96", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "23185", "train_lr": "0.000441607", "train_gnorm": "1.769", "train_loss_scale": "64", "train_train_wall": "5886", "train_gb_free": "10.8", "train_wall": "0"}
[2025-01-17 16:58:50,601][fairseq.trainer][INFO] - begin training epoch 42
[2025-01-17 16:58:50,601][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 16:59:42,082][train_inner][INFO] - {"epoch": 42, "update": 41.003, "loss": "122.075", "nll_loss": "4.493", "total": "669.375", "n_correct": "342.345", "ppl": "22.53", "accuracy": "51.144", "wps": "583.1", "ups": "0.87", "wpb": "669.4", "bsz": "29.1", "num_updates": "23200", "lr": "0.000440946", "gnorm": "1.597", "loss_scale": "64", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 17:03:15,330][train_inner][INFO] - {"epoch": 42, "update": 41.037, "loss": "124.908", "nll_loss": "4.543", "total": "665.42", "n_correct": "337.305", "ppl": "23.32", "accuracy": "50.691", "wps": "624.1", "ups": "0.94", "wpb": "665.4", "bsz": "28.5", "num_updates": "23400", "lr": "0.000432227", "gnorm": "1.576", "loss_scale": "64", "train_wall": "206", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:06:44,318][train_inner][INFO] - {"epoch": 42, "update": 41.071, "loss": "127.589", "nll_loss": "4.505", "total": "664.65", "n_correct": "340.855", "ppl": "22.71", "accuracy": "51.283", "wps": "636.1", "ups": "0.96", "wpb": "664.6", "bsz": "27.7", "num_updates": "23600", "lr": "0.00042368", "gnorm": "1.633", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:10:10,719][train_inner][INFO] - {"epoch": 42, "update": 41.105, "loss": "129.036", "nll_loss": "4.478", "total": "668.39", "n_correct": "343.13", "ppl": "22.28", "accuracy": "51.337", "wps": "647.8", "ups": "0.97", "wpb": "668.4", "bsz": "27.5", "num_updates": "23800", "lr": "0.000415302", "gnorm": "1.939", "loss_scale": "64", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 17:13:39,864][train_inner][INFO] - {"epoch": 42, "update": 41.139, "loss": "122.206", "nll_loss": "4.4", "total": "667.3", "n_correct": "348.8", "ppl": "21.11", "accuracy": "52.27", "wps": "638.2", "ups": "0.96", "wpb": "667.3", "bsz": "28.6", "num_updates": "24000", "lr": "0.000407091", "gnorm": "1.752", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:17:09,293][train_inner][INFO] - {"epoch": 42, "update": 41.173, "loss": "126.871", "nll_loss": "4.523", "total": "674.205", "n_correct": "344.665", "ppl": "22.99", "accuracy": "51.122", "wps": "643.9", "ups": "0.96", "wpb": "674.2", "bsz": "28.4", "num_updates": "24200", "lr": "0.000399041", "gnorm": "1.926", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:20:41,706][train_inner][INFO] - {"epoch": 42, "update": 41.207, "loss": "124.753", "nll_loss": "4.471", "total": "665.755", "n_correct": "343.01", "ppl": "22.18", "accuracy": "51.522", "wps": "626.9", "ups": "0.94", "wpb": "665.8", "bsz": "28.3", "num_updates": "24400", "lr": "0.000391151", "gnorm": "1.764", "loss_scale": "64", "train_wall": "206", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:24:13,254][train_inner][INFO] - {"epoch": 42, "update": 41.241, "loss": "126.109", "nll_loss": "4.534", "total": "665.615", "n_correct": "339.78", "ppl": "23.17", "accuracy": "51.048", "wps": "629.3", "ups": "0.95", "wpb": "665.6", "bsz": "28.2", "num_updates": "24600", "lr": "0.000383416", "gnorm": "1.97", "loss_scale": "64", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:27:42,410][train_inner][INFO] - {"epoch": 42, "update": 41.276, "loss": "121.693", "nll_loss": "4.393", "total": "660.555", "n_correct": "343.68", "ppl": "21.01", "accuracy": "52.029", "wps": "631.7", "ups": "0.96", "wpb": "660.6", "bsz": "28.4", "num_updates": "24800", "lr": "0.000375835", "gnorm": "1.514", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:31:08,007][train_inner][INFO] - {"epoch": 42, "update": 41.31, "loss": "127.542", "nll_loss": "4.432", "total": "662.425", "n_correct": "343.25", "ppl": "21.58", "accuracy": "51.817", "wps": "644.5", "ups": "0.97", "wpb": "662.4", "bsz": "27.3", "num_updates": "25000", "lr": "0.000368403", "gnorm": "1.833", "loss_scale": "64", "train_wall": "199", "gb_free": "11", "wall": "0"}
[2025-01-17 17:34:32,203][train_inner][INFO] - {"epoch": 42, "update": 41.344, "loss": "130.796", "nll_loss": "4.563", "total": "661.515", "n_correct": "334.255", "ppl": "23.63", "accuracy": "50.529", "wps": "648", "ups": "0.98", "wpb": "661.5", "bsz": "27.2", "num_updates": "25200", "lr": "0.000361119", "gnorm": "1.604", "loss_scale": "64", "train_wall": "197", "gb_free": "10.7", "wall": "0"}
[2025-01-17 17:37:55,139][train_inner][INFO] - {"epoch": 42, "update": 41.378, "loss": "131.787", "nll_loss": "4.512", "total": "666.845", "n_correct": "340.535", "ppl": "22.82", "accuracy": "51.067", "wps": "657.2", "ups": "0.99", "wpb": "666.8", "bsz": "27", "num_updates": "25400", "lr": "0.000353978", "gnorm": "1.806", "loss_scale": "64", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:41:20,751][train_inner][INFO] - {"epoch": 42, "update": 41.412, "loss": "134.726", "nll_loss": "4.722", "total": "665.005", "n_correct": "327.22", "ppl": "26.39", "accuracy": "49.206", "wps": "646.9", "ups": "0.97", "wpb": "665", "bsz": "27.2", "num_updates": "25600", "lr": "0.000346979", "gnorm": "1.894", "loss_scale": "64", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:44:45,304][train_inner][INFO] - {"epoch": 42, "update": 41.446, "loss": "126.596", "nll_loss": "4.437", "total": "664.83", "n_correct": "344.32", "ppl": "21.66", "accuracy": "51.791", "wps": "650.1", "ups": "0.98", "wpb": "664.8", "bsz": "27.6", "num_updates": "25800", "lr": "0.000340118", "gnorm": "1.499", "loss_scale": "64", "train_wall": "198", "gb_free": "10.9", "wall": "0"}
[2025-01-17 17:48:18,452][train_inner][INFO] - {"epoch": 42, "update": 41.48, "loss": "126.322", "nll_loss": "4.519", "total": "666.08", "n_correct": "339.055", "ppl": "22.93", "accuracy": "50.903", "wps": "625", "ups": "0.94", "wpb": "666.1", "bsz": "28.1", "num_updates": "26000", "lr": "0.000333392", "gnorm": "1.836", "loss_scale": "64", "train_wall": "206", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:51:47,942][train_inner][INFO] - {"epoch": 42, "update": 41.514, "loss": "121.153", "nll_loss": "4.382", "total": "669.03", "n_correct": "349.17", "ppl": "20.85", "accuracy": "52.19", "wps": "638.8", "ups": "0.95", "wpb": "669", "bsz": "28.8", "num_updates": "26200", "lr": "0.0003268", "gnorm": "2.032", "loss_scale": "64", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:55:13,759][train_inner][INFO] - {"epoch": 42, "update": 41.548, "loss": "126.424", "nll_loss": "4.457", "total": "664.985", "n_correct": "342", "ppl": "21.96", "accuracy": "51.43", "wps": "646.2", "ups": "0.97", "wpb": "665", "bsz": "27.8", "num_updates": "26400", "lr": "0.000320338", "gnorm": "1.975", "loss_scale": "64", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 17:58:42,311][train_inner][INFO] - {"epoch": 42, "update": 41.583, "loss": "124.514", "nll_loss": "4.467", "total": "665.87", "n_correct": "343.075", "ppl": "22.12", "accuracy": "51.523", "wps": "638.6", "ups": "0.96", "wpb": "665.9", "bsz": "28.3", "num_updates": "26600", "lr": "0.000314004", "gnorm": "2.076", "loss_scale": "64", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:01:59,595][train_inner][INFO] - {"epoch": 42, "update": 41.617, "loss": "138.858", "nll_loss": "4.646", "total": "665.975", "n_correct": "332.065", "ppl": "25.03", "accuracy": "49.861", "wps": "675.3", "ups": "1.01", "wpb": "666", "bsz": "26.1", "num_updates": "26800", "lr": "0.000307795", "gnorm": "2.296", "loss_scale": "128", "train_wall": "190", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:05:25,479][train_inner][INFO] - {"epoch": 42, "update": 41.651, "loss": "127.803", "nll_loss": "4.446", "total": "663.825", "n_correct": "341.915", "ppl": "21.8", "accuracy": "51.507", "wps": "644.9", "ups": "0.97", "wpb": "663.8", "bsz": "27.4", "num_updates": "27000", "lr": "0.000301709", "gnorm": "2.201", "loss_scale": "128", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:08:48,981][train_inner][INFO] - {"epoch": 42, "update": 41.685, "loss": "134.781", "nll_loss": "4.578", "total": "667.395", "n_correct": "334.87", "ppl": "23.88", "accuracy": "50.176", "wps": "655.9", "ups": "0.98", "wpb": "667.4", "bsz": "26.7", "num_updates": "27200", "lr": "0.000295743", "gnorm": "1.97", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:12:13,667][train_inner][INFO] - {"epoch": 42, "update": 41.719, "loss": "126.201", "nll_loss": "4.463", "total": "656.07", "n_correct": "337.94", "ppl": "22.06", "accuracy": "51.51", "wps": "641.3", "ups": "0.98", "wpb": "656.1", "bsz": "27.5", "num_updates": "27400", "lr": "0.000289895", "gnorm": "1.956", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:15:38,299][train_inner][INFO] - {"epoch": 42, "update": 41.753, "loss": "129.554", "nll_loss": "4.544", "total": "661.995", "n_correct": "334.98", "ppl": "23.34", "accuracy": "50.602", "wps": "647.1", "ups": "0.98", "wpb": "662", "bsz": "27.4", "num_updates": "27600", "lr": "0.000284163", "gnorm": "2.091", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:19:02,852][train_inner][INFO] - {"epoch": 42, "update": 41.787, "loss": "125.27", "nll_loss": "4.423", "total": "673.16", "n_correct": "350.39", "ppl": "21.46", "accuracy": "52.052", "wps": "658.2", "ups": "0.98", "wpb": "673.2", "bsz": "28.2", "num_updates": "27800", "lr": "0.000278544", "gnorm": "1.963", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:22:35,837][train_inner][INFO] - {"epoch": 42, "update": 41.821, "loss": "122.931", "nll_loss": "4.441", "total": "671.615", "n_correct": "348.15", "ppl": "21.71", "accuracy": "51.838", "wps": "630.7", "ups": "0.94", "wpb": "671.6", "bsz": "28.8", "num_updates": "28000", "lr": "0.000273036", "gnorm": "2.179", "loss_scale": "128", "train_wall": "206", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:26:03,836][train_inner][INFO] - {"epoch": 42, "update": 41.856, "loss": "119.32", "nll_loss": "4.335", "total": "658.83", "n_correct": "346.405", "ppl": "20.18", "accuracy": "52.579", "wps": "633.7", "ups": "0.96", "wpb": "658.8", "bsz": "28.6", "num_updates": "28200", "lr": "0.000267637", "gnorm": "2.348", "loss_scale": "128", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:29:32,933][train_inner][INFO] - {"epoch": 42, "update": 41.89, "loss": "126.393", "nll_loss": "4.508", "total": "666.315", "n_correct": "341.43", "ppl": "22.76", "accuracy": "51.242", "wps": "637.4", "ups": "0.96", "wpb": "666.3", "bsz": "28.1", "num_updates": "28400", "lr": "0.000262345", "gnorm": "1.99", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:33:04,009][train_inner][INFO] - {"epoch": 42, "update": 41.924, "loss": "120.885", "nll_loss": "4.36", "total": "670.04", "n_correct": "351.435", "ppl": "20.53", "accuracy": "52.45", "wps": "634.9", "ups": "0.95", "wpb": "670", "bsz": "28.8", "num_updates": "28600", "lr": "0.000257158", "gnorm": "1.783", "loss_scale": "128", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:36:40,333][train_inner][INFO] - {"epoch": 42, "update": 41.958, "loss": "115.208", "nll_loss": "4.3", "total": "665.795", "n_correct": "351.72", "ppl": "19.7", "accuracy": "52.827", "wps": "615.6", "ups": "0.92", "wpb": "665.8", "bsz": "29.7", "num_updates": "28800", "lr": "0.000252073", "gnorm": "2.235", "loss_scale": "128", "train_wall": "210", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:40:06,237][train_inner][INFO] - {"epoch": 42, "update": 41.992, "loss": "126.807", "nll_loss": "4.514", "total": "663.07", "n_correct": "339.63", "ppl": "22.85", "accuracy": "51.221", "wps": "644.1", "ups": "0.97", "wpb": "663.1", "bsz": "27.9", "num_updates": "29000", "lr": "0.000247089", "gnorm": "2.165", "loss_scale": "128", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:40:39,213][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-17 18:41:34,701][valid][INFO] - {"epoch": 42, "valid_loss": "40.006", "valid_nll_loss": "2.072", "valid_total": "678.4", "valid_n_correct": "498.5", "valid_ppl": "4.21", "valid_accuracy": "73.482", "valid_wps": "587.1", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "29047", "valid_best_accuracy": "73.688"}
[2025-01-17 18:41:34,704][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 29047 updates
[2025-01-17 18:41:34,704][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 18:41:39,390][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 18:41:39,395][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 42 @ 29047 updates, score 73.482) (writing took 4.690885867923498 seconds)
[2025-01-17 18:41:39,395][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2025-01-17 18:41:39,397][train][INFO] - {"epoch": 42, "train_loss": "126.278", "train_nll_loss": "4.479", "train_total": "665.831", "train_n_correct": "342.009", "train_ppl": "22.3", "train_accuracy": "51.366", "train_wps": "632.6", "train_ups": "0.95", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "29047", "train_lr": "0.000245932", "train_gnorm": "1.922", "train_loss_scale": "128", "train_train_wall": "5887", "train_gb_free": "10.8", "train_wall": "0"}
[2025-01-17 18:41:39,994][fairseq.trainer][INFO] - begin training epoch 43
[2025-01-17 18:41:39,994][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 18:45:08,333][train_inner][INFO] - {"epoch": 43, "update": 42.026, "loss": "116.875", "nll_loss": "4.338", "total": "675.61", "n_correct": "354.905", "ppl": "20.22", "accuracy": "52.531", "wps": "447.3", "ups": "0.66", "wpb": "675.6", "bsz": "29.9", "num_updates": "29200", "lr": "0.000242203", "gnorm": "1.965", "loss_scale": "128", "train_wall": "196", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:48:32,062][train_inner][INFO] - {"epoch": 43, "update": 42.06, "loss": "132.262", "nll_loss": "4.543", "total": "663.635", "n_correct": "337.39", "ppl": "23.31", "accuracy": "50.84", "wps": "651.5", "ups": "0.98", "wpb": "663.6", "bsz": "26.9", "num_updates": "29400", "lr": "0.000237414", "gnorm": "2.346", "loss_scale": "128", "train_wall": "197", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:51:58,707][train_inner][INFO] - {"epoch": 43, "update": 42.094, "loss": "134.265", "nll_loss": "4.598", "total": "667.065", "n_correct": "336.385", "ppl": "24.22", "accuracy": "50.428", "wps": "645.7", "ups": "0.97", "wpb": "667.1", "bsz": "26.9", "num_updates": "29600", "lr": "0.000232719", "gnorm": "2.16", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 18:55:28,846][train_inner][INFO] - {"epoch": 43, "update": 42.128, "loss": "126.064", "nll_loss": "4.545", "total": "670.245", "n_correct": "341.145", "ppl": "23.34", "accuracy": "50.899", "wps": "637.9", "ups": "0.95", "wpb": "670.2", "bsz": "28.5", "num_updates": "29800", "lr": "0.000228117", "gnorm": "2.206", "loss_scale": "128", "train_wall": "204", "gb_free": "10.7", "wall": "0"}
[2025-01-17 18:58:48,476][train_inner][INFO] - {"epoch": 43, "update": 42.163, "loss": "135.237", "nll_loss": "4.603", "total": "666.25", "n_correct": "334.195", "ppl": "24.3", "accuracy": "50.161", "wps": "667.5", "ups": "1", "wpb": "666.2", "bsz": "26.7", "num_updates": "30000", "lr": "0.000223607", "gnorm": "2.091", "loss_scale": "128", "train_wall": "194", "gb_free": "10.9", "wall": "0"}
[2025-01-17 19:02:23,072][train_inner][INFO] - {"epoch": 43, "update": 42.197, "loss": "121.646", "nll_loss": "4.368", "total": "673.995", "n_correct": "353.21", "ppl": "20.65", "accuracy": "52.405", "wps": "628.2", "ups": "0.93", "wpb": "674", "bsz": "28.8", "num_updates": "30200", "lr": "0.000219185", "gnorm": "2.263", "loss_scale": "128", "train_wall": "207", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:05:55,287][train_inner][INFO] - {"epoch": 43, "update": 42.231, "loss": "119.791", "nll_loss": "4.403", "total": "659.065", "n_correct": "344.6", "ppl": "21.16", "accuracy": "52.286", "wps": "621.2", "ups": "0.94", "wpb": "659.1", "bsz": "28.8", "num_updates": "30400", "lr": "0.000214851", "gnorm": "1.864", "loss_scale": "128", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 19:09:24,925][train_inner][INFO] - {"epoch": 43, "update": 42.265, "loss": "125.848", "nll_loss": "4.464", "total": "675.815", "n_correct": "348.56", "ppl": "22.06", "accuracy": "51.576", "wps": "644.8", "ups": "0.95", "wpb": "675.8", "bsz": "28.4", "num_updates": "30600", "lr": "0.000210603", "gnorm": "2.071", "loss_scale": "128", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:12:52,791][train_inner][INFO] - {"epoch": 43, "update": 42.299, "loss": "125.074", "nll_loss": "4.505", "total": "662.315", "n_correct": "339.06", "ppl": "22.71", "accuracy": "51.193", "wps": "637.4", "ups": "0.96", "wpb": "662.3", "bsz": "28.2", "num_updates": "30800", "lr": "0.000206439", "gnorm": "1.997", "loss_scale": "256", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:16:21,395][train_inner][INFO] - {"epoch": 43, "update": 42.333, "loss": "127.595", "nll_loss": "4.498", "total": "669.38", "n_correct": "342.605", "ppl": "22.6", "accuracy": "51.182", "wps": "641.8", "ups": "0.96", "wpb": "669.4", "bsz": "27.9", "num_updates": "31000", "lr": "0.000202357", "gnorm": "2.009", "loss_scale": "256", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:19:47,223][train_inner][INFO] - {"epoch": 43, "update": 42.367, "loss": "126.847", "nll_loss": "4.409", "total": "660.155", "n_correct": "343.435", "ppl": "21.24", "accuracy": "52.023", "wps": "641.6", "ups": "0.97", "wpb": "660.2", "bsz": "27.3", "num_updates": "31200", "lr": "0.000198355", "gnorm": "2.176", "loss_scale": "256", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 19:23:19,489][train_inner][INFO] - {"epoch": 43, "update": 42.401, "loss": "122.922", "nll_loss": "4.474", "total": "666.65", "n_correct": "343.405", "ppl": "22.23", "accuracy": "51.512", "wps": "628.2", "ups": "0.94", "wpb": "666.6", "bsz": "28.7", "num_updates": "31400", "lr": "0.000194433", "gnorm": "2.106", "loss_scale": "256", "train_wall": "206", "gb_free": "10.9", "wall": "0"}
[2025-01-17 19:26:49,533][train_inner][INFO] - {"epoch": 43, "update": 42.436, "loss": "120.706", "nll_loss": "4.398", "total": "667.155", "n_correct": "349.34", "ppl": "21.09", "accuracy": "52.363", "wps": "635.3", "ups": "0.95", "wpb": "667.2", "bsz": "28.9", "num_updates": "31600", "lr": "0.000190589", "gnorm": "1.908", "loss_scale": "256", "train_wall": "204", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:27:44,957][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2025-01-17 19:30:22,502][train_inner][INFO] - {"epoch": 43, "update": 42.47, "loss": "120.885", "nll_loss": "4.353", "total": "668.205", "n_correct": "350.225", "ppl": "20.44", "accuracy": "52.413", "wps": "627.5", "ups": "0.94", "wpb": "668.2", "bsz": "28.7", "num_updates": "31800", "lr": "0.00018682", "gnorm": "1.926", "loss_scale": "128", "train_wall": "207", "gb_free": "10.9", "wall": "0"}
[2025-01-17 19:33:47,200][train_inner][INFO] - {"epoch": 43, "update": 42.504, "loss": "124.014", "nll_loss": "4.427", "total": "658.955", "n_correct": "341.035", "ppl": "21.52", "accuracy": "51.754", "wps": "643.9", "ups": "0.98", "wpb": "659", "bsz": "27.9", "num_updates": "32000", "lr": "0.000183126", "gnorm": "1.91", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 19:37:15,289][train_inner][INFO] - {"epoch": 43, "update": 42.538, "loss": "126.297", "nll_loss": "4.481", "total": "660.24", "n_correct": "338.935", "ppl": "22.33", "accuracy": "51.335", "wps": "634.6", "ups": "0.96", "wpb": "660.2", "bsz": "27.7", "num_updates": "32200", "lr": "0.000179505", "gnorm": "2.206", "loss_scale": "128", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 19:40:41,579][train_inner][INFO] - {"epoch": 43, "update": 42.572, "loss": "124.722", "nll_loss": "4.403", "total": "663.735", "n_correct": "345.225", "ppl": "21.15", "accuracy": "52.012", "wps": "643.6", "ups": "0.97", "wpb": "663.7", "bsz": "27.8", "num_updates": "32400", "lr": "0.000175955", "gnorm": "2.023", "loss_scale": "128", "train_wall": "199", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:44:15,042][train_inner][INFO] - {"epoch": 43, "update": 42.606, "loss": "121.705", "nll_loss": "4.366", "total": "672.14", "n_correct": "351.685", "ppl": "20.62", "accuracy": "52.323", "wps": "629.8", "ups": "0.94", "wpb": "672.1", "bsz": "28.7", "num_updates": "32600", "lr": "0.000172476", "gnorm": "2.105", "loss_scale": "128", "train_wall": "207", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:47:37,746][train_inner][INFO] - {"epoch": 43, "update": 42.64, "loss": "127.042", "nll_loss": "4.487", "total": "663.86", "n_correct": "340.38", "ppl": "22.43", "accuracy": "51.273", "wps": "655.1", "ups": "0.99", "wpb": "663.9", "bsz": "27.7", "num_updates": "32800", "lr": "0.000169066", "gnorm": "2.132", "loss_scale": "128", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:50:53,634][train_inner][INFO] - {"epoch": 43, "update": 42.675, "loss": "137.296", "nll_loss": "4.619", "total": "665.255", "n_correct": "332.79", "ppl": "24.58", "accuracy": "50.024", "wps": "679.3", "ups": "1.02", "wpb": "665.3", "bsz": "26.3", "num_updates": "33000", "lr": "0.000165723", "gnorm": "2.268", "loss_scale": "128", "train_wall": "189", "gb_free": "10.8", "wall": "0"}
[2025-01-17 19:54:27,702][train_inner][INFO] - {"epoch": 43, "update": 42.709, "loss": "120.161", "nll_loss": "4.466", "total": "668.98", "n_correct": "345.3", "ppl": "22.09", "accuracy": "51.616", "wps": "625.1", "ups": "0.93", "wpb": "669", "bsz": "29.5", "num_updates": "33200", "lr": "0.000162446", "gnorm": "1.969", "loss_scale": "128", "train_wall": "207", "gb_free": "10.9", "wall": "0"}
[2025-01-17 19:57:47,320][train_inner][INFO] - {"epoch": 43, "update": 42.743, "loss": "134.619", "nll_loss": "4.623", "total": "662.395", "n_correct": "332.435", "ppl": "24.65", "accuracy": "50.187", "wps": "663.7", "ups": "1", "wpb": "662.4", "bsz": "26.7", "num_updates": "33400", "lr": "0.000159234", "gnorm": "1.744", "loss_scale": "128", "train_wall": "193", "gb_free": "10.8", "wall": "0"}
[2025-01-17 20:01:10,729][train_inner][INFO] - {"epoch": 43, "update": 42.777, "loss": "132.782", "nll_loss": "4.625", "total": "657.605", "n_correct": "329.365", "ppl": "24.67", "accuracy": "50.086", "wps": "646.7", "ups": "0.98", "wpb": "657.6", "bsz": "26.9", "num_updates": "33600", "lr": "0.000156085", "gnorm": "1.986", "loss_scale": "128", "train_wall": "197", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:04:34,442][train_inner][INFO] - {"epoch": 43, "update": 42.811, "loss": "130.688", "nll_loss": "4.557", "total": "662.15", "n_correct": "334.09", "ppl": "23.53", "accuracy": "50.455", "wps": "650.1", "ups": "0.98", "wpb": "662.1", "bsz": "27.2", "num_updates": "33800", "lr": "0.000152999", "gnorm": "1.942", "loss_scale": "128", "train_wall": "197", "gb_free": "10.9", "wall": "0"}
[2025-01-17 20:08:06,427][train_inner][INFO] - {"epoch": 43, "update": 42.845, "loss": "123.16", "nll_loss": "4.372", "total": "671.735", "n_correct": "351.16", "ppl": "20.71", "accuracy": "52.277", "wps": "633.8", "ups": "0.94", "wpb": "671.7", "bsz": "28.4", "num_updates": "34000", "lr": "0.000149973", "gnorm": "1.946", "loss_scale": "128", "train_wall": "206", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:11:25,527][train_inner][INFO] - {"epoch": 43, "update": 42.879, "loss": "127.466", "nll_loss": "4.458", "total": "656.015", "n_correct": "337.95", "ppl": "21.98", "accuracy": "51.516", "wps": "659", "ups": "1", "wpb": "656", "bsz": "27.2", "num_updates": "34200", "lr": "0.000147008", "gnorm": "1.959", "loss_scale": "128", "train_wall": "193", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:14:54,235][train_inner][INFO] - {"epoch": 43, "update": 42.913, "loss": "123.74", "nll_loss": "4.397", "total": "667.935", "n_correct": "348.38", "ppl": "21.07", "accuracy": "52.158", "wps": "640.1", "ups": "0.96", "wpb": "667.9", "bsz": "28.2", "num_updates": "34400", "lr": "0.000144101", "gnorm": "1.938", "loss_scale": "128", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:18:25,644][train_inner][INFO] - {"epoch": 43, "update": 42.947, "loss": "124.07", "nll_loss": "4.459", "total": "667.635", "n_correct": "343.59", "ppl": "21.99", "accuracy": "51.464", "wps": "631.7", "ups": "0.95", "wpb": "667.6", "bsz": "28.4", "num_updates": "34600", "lr": "0.000141252", "gnorm": "1.745", "loss_scale": "128", "train_wall": "204", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:21:47,846][train_inner][INFO] - {"epoch": 43, "update": 42.982, "loss": "132.168", "nll_loss": "4.615", "total": "673.005", "n_correct": "337.19", "ppl": "24.5", "accuracy": "50.102", "wps": "665.7", "ups": "0.99", "wpb": "673", "bsz": "27.6", "num_updates": "34800", "lr": "0.000138459", "gnorm": "2.02", "loss_scale": "128", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 20:23:21,295][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2025-01-17 20:23:21,300][train][INFO] - {"epoch": 43, "train_loss": "126.27", "train_nll_loss": "4.478", "train_total": "665.821", "train_n_correct": "342.19", "train_ppl": "22.28", "train_accuracy": "51.394", "train_wps": "639.5", "train_ups": "0.96", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "34908", "train_lr": "0.000136973", "train_gnorm": "2.037", "train_loss_scale": "128", "train_train_wall": "5873", "train_gb_free": "10.8", "train_wall": "0"}
[2025-01-17 20:23:22,477][fairseq.trainer][INFO] - begin training epoch 44
[2025-01-17 20:23:22,478][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 20:25:40,687][train_inner][INFO] - {"epoch": 44, "update": 43.016, "loss": "121.525", "nll_loss": "4.428", "total": "658.8", "n_correct": "342.175", "ppl": "21.53", "accuracy": "51.939", "wps": "565.9", "ups": "0.86", "wpb": "658.8", "bsz": "28.5", "num_updates": "35000", "lr": "0.000135721", "gnorm": "1.947", "loss_scale": "128", "train_wall": "197", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:29:07,345][train_inner][INFO] - {"epoch": 44, "update": 43.05, "loss": "124.425", "nll_loss": "4.35", "total": "663.045", "n_correct": "348.14", "ppl": "20.39", "accuracy": "52.506", "wps": "641.7", "ups": "0.97", "wpb": "663", "bsz": "27.6", "num_updates": "35200", "lr": "0.000133037", "gnorm": "1.915", "loss_scale": "128", "train_wall": "200", "gb_free": "10.8", "wall": "0"}
[2025-01-17 20:32:39,618][train_inner][INFO] - {"epoch": 44, "update": 43.084, "loss": "123.824", "nll_loss": "4.391", "total": "673.85", "n_correct": "350.235", "ppl": "20.98", "accuracy": "51.975", "wps": "634.9", "ups": "0.94", "wpb": "673.9", "bsz": "28.4", "num_updates": "35400", "lr": "0.000130407", "gnorm": "2.13", "loss_scale": "128", "train_wall": "206", "gb_free": "10.8", "wall": "0"}
[2025-01-17 20:36:02,954][train_inner][INFO] - {"epoch": 44, "update": 43.118, "loss": "129.339", "nll_loss": "4.524", "total": "659.05", "n_correct": "338.905", "ppl": "23.01", "accuracy": "51.423", "wps": "648.3", "ups": "0.98", "wpb": "659.1", "bsz": "27.2", "num_updates": "35600", "lr": "0.000127828", "gnorm": "1.756", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 20:39:30,038][train_inner][INFO] - {"epoch": 44, "update": 43.152, "loss": "130.915", "nll_loss": "4.587", "total": "671.32", "n_correct": "339.565", "ppl": "24.03", "accuracy": "50.582", "wps": "648.4", "ups": "0.97", "wpb": "671.3", "bsz": "27.7", "num_updates": "35800", "lr": "0.0001253", "gnorm": "1.987", "loss_scale": "256", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 20:42:59,353][train_inner][INFO] - {"epoch": 44, "update": 43.186, "loss": "125.405", "nll_loss": "4.486", "total": "669.21", "n_correct": "344.895", "ppl": "22.41", "accuracy": "51.538", "wps": "639.5", "ups": "0.96", "wpb": "669.2", "bsz": "28.3", "num_updates": "36000", "lr": "0.000122823", "gnorm": "1.859", "loss_scale": "256", "train_wall": "202", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:46:23,777][train_inner][INFO] - {"epoch": 44, "update": 43.22, "loss": "130.74", "nll_loss": "4.521", "total": "663.84", "n_correct": "338.79", "ppl": "22.96", "accuracy": "51.035", "wps": "649.5", "ups": "0.98", "wpb": "663.8", "bsz": "27.1", "num_updates": "36200", "lr": "0.000120394", "gnorm": "2.021", "loss_scale": "256", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 20:49:53,108][train_inner][INFO] - {"epoch": 44, "update": 43.255, "loss": "122.575", "nll_loss": "4.473", "total": "668.76", "n_correct": "343.475", "ppl": "22.2", "accuracy": "51.36", "wps": "639", "ups": "0.96", "wpb": "668.8", "bsz": "28.9", "num_updates": "36400", "lr": "0.000118014", "gnorm": "2.119", "loss_scale": "256", "train_wall": "203", "gb_free": "11", "wall": "0"}
[2025-01-17 20:50:51,422][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2025-01-17 20:53:21,939][train_inner][INFO] - {"epoch": 44, "update": 43.289, "loss": "124.637", "nll_loss": "4.431", "total": "669.7", "n_correct": "346.43", "ppl": "21.57", "accuracy": "51.729", "wps": "641.4", "ups": "0.96", "wpb": "669.7", "bsz": "28.2", "num_updates": "36600", "lr": "0.00011568", "gnorm": "1.918", "loss_scale": "128", "train_wall": "202", "gb_free": "10.6", "wall": "0"}
[2025-01-17 20:56:51,773][train_inner][INFO] - {"epoch": 44, "update": 43.323, "loss": "123.518", "nll_loss": "4.445", "total": "664.9", "n_correct": "342.945", "ppl": "21.78", "accuracy": "51.578", "wps": "633.8", "ups": "0.95", "wpb": "664.9", "bsz": "28.4", "num_updates": "36800", "lr": "0.000113393", "gnorm": "2.03", "loss_scale": "128", "train_wall": "203", "gb_free": "10.7", "wall": "0"}
[2025-01-17 21:00:15,836][train_inner][INFO] - {"epoch": 44, "update": 43.357, "loss": "130.946", "nll_loss": "4.593", "total": "664.955", "n_correct": "335.97", "ppl": "24.13", "accuracy": "50.525", "wps": "651.8", "ups": "0.98", "wpb": "665", "bsz": "27.4", "num_updates": "37000", "lr": "0.00011115", "gnorm": "1.873", "loss_scale": "128", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:03:42,160][train_inner][INFO] - {"epoch": 44, "update": 43.391, "loss": "128.136", "nll_loss": "4.55", "total": "661.03", "n_correct": "336.55", "ppl": "23.43", "accuracy": "50.913", "wps": "640.8", "ups": "0.97", "wpb": "661", "bsz": "27.7", "num_updates": "37200", "lr": "0.000108953", "gnorm": "1.851", "loss_scale": "128", "train_wall": "199", "gb_free": "10.9", "wall": "0"}
[2025-01-17 21:07:03,184][train_inner][INFO] - {"epoch": 44, "update": 43.425, "loss": "131.538", "nll_loss": "4.518", "total": "669.175", "n_correct": "342.525", "ppl": "22.9", "accuracy": "51.186", "wps": "665.8", "ups": "0.99", "wpb": "669.2", "bsz": "27.1", "num_updates": "37400", "lr": "0.000106798", "gnorm": "1.856", "loss_scale": "128", "train_wall": "195", "gb_free": "10.9", "wall": "0"}
[2025-01-17 21:10:31,671][train_inner][INFO] - {"epoch": 44, "update": 43.459, "loss": "125.319", "nll_loss": "4.453", "total": "662.735", "n_correct": "341.54", "ppl": "21.91", "accuracy": "51.535", "wps": "635.8", "ups": "0.96", "wpb": "662.7", "bsz": "27.9", "num_updates": "37600", "lr": "0.000104687", "gnorm": "1.894", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:13:56,147][train_inner][INFO] - {"epoch": 44, "update": 43.494, "loss": "127.161", "nll_loss": "4.508", "total": "662.2", "n_correct": "338.28", "ppl": "22.75", "accuracy": "51.084", "wps": "647.7", "ups": "0.98", "wpb": "662.2", "bsz": "27.7", "num_updates": "37800", "lr": "0.000102617", "gnorm": "1.948", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:17:21,922][train_inner][INFO] - {"epoch": 44, "update": 43.528, "loss": "126.528", "nll_loss": "4.452", "total": "664.55", "n_correct": "341.45", "ppl": "21.88", "accuracy": "51.381", "wps": "646", "ups": "0.97", "wpb": "664.6", "bsz": "27.7", "num_updates": "38000", "lr": "0.000100587", "gnorm": "2.01", "loss_scale": "128", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 21:20:51,959][train_inner][INFO] - {"epoch": 44, "update": 43.562, "loss": "122.198", "nll_loss": "4.368", "total": "662.55", "n_correct": "346.655", "ppl": "20.65", "accuracy": "52.321", "wps": "630.9", "ups": "0.95", "wpb": "662.6", "bsz": "28.2", "num_updates": "38200", "lr": "9.85985e-05", "gnorm": "1.714", "loss_scale": "128", "train_wall": "204", "gb_free": "10.7", "wall": "0"}
[2025-01-17 21:24:21,087][train_inner][INFO] - {"epoch": 44, "update": 43.596, "loss": "123.635", "nll_loss": "4.421", "total": "664.065", "n_correct": "344.73", "ppl": "21.42", "accuracy": "51.912", "wps": "635.1", "ups": "0.96", "wpb": "664.1", "bsz": "28.2", "num_updates": "38400", "lr": "9.66488e-05", "gnorm": "1.955", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:27:51,289][train_inner][INFO] - {"epoch": 44, "update": 43.63, "loss": "124.821", "nll_loss": "4.467", "total": "669.41", "n_correct": "343.61", "ppl": "22.12", "accuracy": "51.33", "wps": "637", "ups": "0.95", "wpb": "669.4", "bsz": "28.4", "num_updates": "38600", "lr": "9.47378e-05", "gnorm": "2.004", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:31:13,468][train_inner][INFO] - {"epoch": 44, "update": 43.664, "loss": "129.507", "nll_loss": "4.536", "total": "656.715", "n_correct": "332.855", "ppl": "23.19", "accuracy": "50.685", "wps": "649.7", "ups": "0.99", "wpb": "656.7", "bsz": "27.1", "num_updates": "38800", "lr": "9.28645e-05", "gnorm": "1.785", "loss_scale": "128", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:34:37,340][train_inner][INFO] - {"epoch": 44, "update": 43.698, "loss": "131.084", "nll_loss": "4.567", "total": "663.475", "n_correct": "335.67", "ppl": "23.71", "accuracy": "50.593", "wps": "650.9", "ups": "0.98", "wpb": "663.5", "bsz": "27.2", "num_updates": "39000", "lr": "9.10282e-05", "gnorm": "1.793", "loss_scale": "128", "train_wall": "197", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:38:01,403][train_inner][INFO] - {"epoch": 44, "update": 43.732, "loss": "130.206", "nll_loss": "4.527", "total": "669.685", "n_correct": "340.61", "ppl": "23.06", "accuracy": "50.861", "wps": "656.4", "ups": "0.98", "wpb": "669.7", "bsz": "27.5", "num_updates": "39200", "lr": "8.92283e-05", "gnorm": "1.764", "loss_scale": "128", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:41:31,968][train_inner][INFO] - {"epoch": 44, "update": 43.766, "loss": "127.334", "nll_loss": "4.533", "total": "672.485", "n_correct": "341.75", "ppl": "23.15", "accuracy": "50.819", "wps": "638.8", "ups": "0.95", "wpb": "672.5", "bsz": "28.2", "num_updates": "39400", "lr": "8.74639e-05", "gnorm": "1.736", "loss_scale": "128", "train_wall": "205", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:45:02,734][train_inner][INFO] - {"epoch": 44, "update": 43.801, "loss": "123.71", "nll_loss": "4.474", "total": "666.875", "n_correct": "342.26", "ppl": "22.22", "accuracy": "51.323", "wps": "632.8", "ups": "0.95", "wpb": "666.9", "bsz": "28.6", "num_updates": "39600", "lr": "8.57345e-05", "gnorm": "2.172", "loss_scale": "128", "train_wall": "205", "gb_free": "10.7", "wall": "0"}
[2025-01-17 21:48:31,548][train_inner][INFO] - {"epoch": 44, "update": 43.835, "loss": "124.321", "nll_loss": "4.466", "total": "669.355", "n_correct": "344.02", "ppl": "22.1", "accuracy": "51.396", "wps": "641.2", "ups": "0.96", "wpb": "669.4", "bsz": "28.5", "num_updates": "39800", "lr": "8.40392e-05", "gnorm": "2.145", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:51:59,736][train_inner][INFO] - {"epoch": 44, "update": 43.869, "loss": "126.47", "nll_loss": "4.471", "total": "664.37", "n_correct": "340.75", "ppl": "22.18", "accuracy": "51.289", "wps": "638.3", "ups": "0.96", "wpb": "664.4", "bsz": "27.8", "num_updates": "40000", "lr": "8.23774e-05", "gnorm": "1.856", "loss_scale": "128", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:55:27,671][train_inner][INFO] - {"epoch": 44, "update": 43.903, "loss": "121.056", "nll_loss": "4.387", "total": "663.33", "n_correct": "346.28", "ppl": "20.92", "accuracy": "52.203", "wps": "638.1", "ups": "0.96", "wpb": "663.3", "bsz": "28.6", "num_updates": "40200", "lr": "8.07486e-05", "gnorm": "1.792", "loss_scale": "128", "train_wall": "201", "gb_free": "10.8", "wall": "0"}
[2025-01-17 21:58:51,878][train_inner][INFO] - {"epoch": 44, "update": 43.937, "loss": "129.691", "nll_loss": "4.569", "total": "666.1", "n_correct": "336.085", "ppl": "23.73", "accuracy": "50.456", "wps": "652.4", "ups": "0.98", "wpb": "666.1", "bsz": "27.6", "num_updates": "40400", "lr": "7.91519e-05", "gnorm": "1.81", "loss_scale": "128", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:02:14,284][train_inner][INFO] - {"epoch": 44, "update": 43.971, "loss": "131.544", "nll_loss": "4.619", "total": "666.59", "n_correct": "334.41", "ppl": "24.58", "accuracy": "50.167", "wps": "658.7", "ups": "0.99", "wpb": "666.6", "bsz": "27.5", "num_updates": "40600", "lr": "7.75868e-05", "gnorm": "1.942", "loss_scale": "256", "train_wall": "195", "gb_free": "10.9", "wall": "0"}
[2025-01-17 22:04:56,624][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-17 22:05:49,005][valid][INFO] - {"epoch": 44, "valid_loss": "40.071", "valid_nll_loss": "2.079", "valid_total": "678.4", "valid_n_correct": "498.1", "valid_ppl": "4.22", "valid_accuracy": "73.423", "valid_wps": "517.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "40769", "valid_best_accuracy": "73.688"}
[2025-01-17 22:05:49,008][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 40769 updates
[2025-01-17 22:05:49,008][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 22:05:53,566][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 22:05:53,570][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 40769 updates, score 73.423) (writing took 4.562923082150519 seconds)
[2025-01-17 22:05:53,571][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2025-01-17 22:05:53,575][train][INFO] - {"epoch": 44, "train_loss": "126.292", "train_nll_loss": "4.48", "train_total": "665.824", "train_n_correct": "341.959", "train_ppl": "22.32", "train_accuracy": "51.359", "train_wps": "634.3", "train_ups": "0.95", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "40769", "train_lr": "7.62884e-05", "train_gnorm": "1.91", "train_loss_scale": "256", "train_train_wall": "5874", "train_gb_free": "10.7", "train_wall": "0"}
[2025-01-17 22:05:54,159][fairseq.trainer][INFO] - begin training epoch 45
[2025-01-17 22:05:54,159][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-17 22:07:04,390][train_inner][INFO] - {"epoch": 45, "update": 44.005, "loss": "121.16", "nll_loss": "4.324", "total": "670.72", "n_correct": "353.615", "ppl": "20.03", "accuracy": "52.722", "wps": "462.4", "ups": "0.69", "wpb": "670.7", "bsz": "28.6", "num_updates": "40800", "lr": "7.60526e-05", "gnorm": "1.833", "loss_scale": "256", "train_wall": "188", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:10:33,319][train_inner][INFO] - {"epoch": 45, "update": 44.039, "loss": "127.569", "nll_loss": "4.578", "total": "661.805", "n_correct": "333.57", "ppl": "23.89", "accuracy": "50.403", "wps": "633.6", "ups": "0.96", "wpb": "661.8", "bsz": "28", "num_updates": "41000", "lr": "7.45488e-05", "gnorm": "2.099", "loss_scale": "256", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:14:01,198][train_inner][INFO] - {"epoch": 45, "update": 44.074, "loss": "126.522", "nll_loss": "4.517", "total": "665.39", "n_correct": "338.82", "ppl": "22.9", "accuracy": "50.921", "wps": "640.2", "ups": "0.96", "wpb": "665.4", "bsz": "28.1", "num_updates": "41200", "lr": "7.30747e-05", "gnorm": "2.015", "loss_scale": "256", "train_wall": "201", "gb_free": "10.7", "wall": "0"}
[2025-01-17 22:17:33,975][train_inner][INFO] - {"epoch": 45, "update": 44.108, "loss": "122.376", "nll_loss": "4.437", "total": "669.3", "n_correct": "347.19", "ppl": "21.67", "accuracy": "51.874", "wps": "629.1", "ups": "0.94", "wpb": "669.3", "bsz": "28.8", "num_updates": "41400", "lr": "7.16298e-05", "gnorm": "1.77", "loss_scale": "256", "train_wall": "207", "gb_free": "10.9", "wall": "0"}
[2025-01-17 22:21:04,115][train_inner][INFO] - {"epoch": 45, "update": 44.142, "loss": "123.245", "nll_loss": "4.372", "total": "668.35", "n_correct": "349.83", "ppl": "20.71", "accuracy": "52.342", "wps": "636.1", "ups": "0.95", "wpb": "668.4", "bsz": "28.2", "num_updates": "41600", "lr": "7.02134e-05", "gnorm": "2.329", "loss_scale": "256", "train_wall": "203", "gb_free": "10.7", "wall": "0"}
[2025-01-17 22:24:25,547][train_inner][INFO] - {"epoch": 45, "update": 44.176, "loss": "131.184", "nll_loss": "4.465", "total": "670.585", "n_correct": "345.63", "ppl": "22.08", "accuracy": "51.542", "wps": "665.9", "ups": "0.99", "wpb": "670.6", "bsz": "27", "num_updates": "41800", "lr": "6.88251e-05", "gnorm": "1.767", "loss_scale": "256", "train_wall": "195", "gb_free": "10.9", "wall": "0"}
[2025-01-17 22:27:49,455][train_inner][INFO] - {"epoch": 45, "update": 44.21, "loss": "129.279", "nll_loss": "4.517", "total": "665.71", "n_correct": "339.19", "ppl": "22.89", "accuracy": "50.952", "wps": "653", "ups": "0.98", "wpb": "665.7", "bsz": "27.5", "num_updates": "42000", "lr": "6.74641e-05", "gnorm": "1.764", "loss_scale": "256", "train_wall": "197", "gb_free": "11", "wall": "0"}
[2025-01-17 22:31:18,596][train_inner][INFO] - {"epoch": 45, "update": 44.244, "loss": "125.313", "nll_loss": "4.472", "total": "663.86", "n_correct": "339.79", "ppl": "22.19", "accuracy": "51.184", "wps": "634.9", "ups": "0.96", "wpb": "663.9", "bsz": "28.1", "num_updates": "42200", "lr": "6.61301e-05", "gnorm": "1.809", "loss_scale": "256", "train_wall": "202", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:34:53,852][train_inner][INFO] - {"epoch": 45, "update": 44.278, "loss": "117.761", "nll_loss": "4.326", "total": "670.43", "n_correct": "353.285", "ppl": "20.06", "accuracy": "52.695", "wps": "622.9", "ups": "0.93", "wpb": "670.4", "bsz": "29.4", "num_updates": "42400", "lr": "6.48225e-05", "gnorm": "1.647", "loss_scale": "256", "train_wall": "209", "gb_free": "10.7", "wall": "0"}
[2025-01-17 22:35:06,208][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2025-01-17 22:38:19,033][train_inner][INFO] - {"epoch": 45, "update": 44.313, "loss": "128.588", "nll_loss": "4.544", "total": "664.145", "n_correct": "337.415", "ppl": "23.32", "accuracy": "50.804", "wps": "647.4", "ups": "0.97", "wpb": "664.1", "bsz": "27.7", "num_updates": "42600", "lr": "6.35408e-05", "gnorm": "2.183", "loss_scale": "128", "train_wall": "199", "gb_free": "10.7", "wall": "0"}
[2025-01-17 22:41:48,963][train_inner][INFO] - {"epoch": 45, "update": 44.347, "loss": "125.798", "nll_loss": "4.497", "total": "662.425", "n_correct": "339.13", "ppl": "22.58", "accuracy": "51.195", "wps": "631.2", "ups": "0.95", "wpb": "662.4", "bsz": "28", "num_updates": "42800", "lr": "6.22843e-05", "gnorm": "2.003", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:45:23,776][train_inner][INFO] - {"epoch": 45, "update": 44.381, "loss": "117.752", "nll_loss": "4.365", "total": "663.715", "n_correct": "348.7", "ppl": "20.6", "accuracy": "52.538", "wps": "618", "ups": "0.93", "wpb": "663.7", "bsz": "29.3", "num_updates": "43000", "lr": "6.10528e-05", "gnorm": "1.741", "loss_scale": "128", "train_wall": "209", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:48:52,740][train_inner][INFO] - {"epoch": 45, "update": 44.415, "loss": "123.853", "nll_loss": "4.386", "total": "669.135", "n_correct": "349.225", "ppl": "20.91", "accuracy": "52.191", "wps": "640.4", "ups": "0.96", "wpb": "669.1", "bsz": "28.2", "num_updates": "43200", "lr": "5.98455e-05", "gnorm": "1.85", "loss_scale": "128", "train_wall": "203", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:52:15,229][train_inner][INFO] - {"epoch": 45, "update": 44.449, "loss": "132.869", "nll_loss": "4.573", "total": "667.375", "n_correct": "337.245", "ppl": "23.81", "accuracy": "50.533", "wps": "659.4", "ups": "0.99", "wpb": "667.4", "bsz": "27", "num_updates": "43400", "lr": "5.86622e-05", "gnorm": "1.781", "loss_scale": "128", "train_wall": "196", "gb_free": "10.8", "wall": "0"}
[2025-01-17 22:55:37,860][train_inner][INFO] - {"epoch": 45, "update": 44.483, "loss": "131.804", "nll_loss": "4.574", "total": "668.215", "n_correct": "337.745", "ppl": "23.82", "accuracy": "50.544", "wps": "659.6", "ups": "0.99", "wpb": "668.2", "bsz": "27.3", "num_updates": "43600", "lr": "5.75022e-05", "gnorm": "1.968", "loss_scale": "128", "train_wall": "196", "gb_free": "10.7", "wall": "0"}
[2025-01-17 22:58:59,121][train_inner][INFO] - {"epoch": 45, "update": 44.517, "loss": "135.394", "nll_loss": "4.68", "total": "662.885", "n_correct": "329.535", "ppl": "25.64", "accuracy": "49.712", "wps": "658.8", "ups": "0.99", "wpb": "662.9", "bsz": "26.8", "num_updates": "43800", "lr": "5.63652e-05", "gnorm": "2.202", "loss_scale": "128", "train_wall": "195", "gb_free": "10.8", "wall": "0"}
[2025-01-17 23:02:23,750][train_inner][INFO] - {"epoch": 45, "update": 44.551, "loss": "124.756", "nll_loss": "4.465", "total": "659.825", "n_correct": "339.485", "ppl": "22.09", "accuracy": "51.451", "wps": "644.9", "ups": "0.98", "wpb": "659.8", "bsz": "28", "num_updates": "44000", "lr": "5.52507e-05", "gnorm": "1.756", "loss_scale": "128", "train_wall": "198", "gb_free": "10.7", "wall": "0"}
[2025-01-17 23:05:43,377][train_inner][INFO] - {"epoch": 45, "update": 44.585, "loss": "135.68", "nll_loss": "4.592", "total": "662.8", "n_correct": "333.72", "ppl": "24.12", "accuracy": "50.35", "wps": "664.1", "ups": "1", "wpb": "662.8", "bsz": "26.4", "num_updates": "44200", "lr": "5.41582e-05", "gnorm": "1.811", "loss_scale": "128", "train_wall": "193", "gb_free": "10.8", "wall": "0"}
[2025-01-17 23:09:10,093][train_inner][INFO] - {"epoch": 45, "update": 44.62, "loss": "127.699", "nll_loss": "4.487", "total": "666.29", "n_correct": "341.195", "ppl": "22.43", "accuracy": "51.208", "wps": "644.7", "ups": "0.97", "wpb": "666.3", "bsz": "27.7", "num_updates": "44400", "lr": "5.30873e-05", "gnorm": "1.921", "loss_scale": "128", "train_wall": "200", "gb_free": "10.9", "wall": "0"}
[2025-01-17 23:12:44,204][train_inner][INFO] - {"epoch": 45, "update": 44.654, "loss": "124.725", "nll_loss": "4.472", "total": "673.105", "n_correct": "345.48", "ppl": "22.2", "accuracy": "51.326", "wps": "628.8", "ups": "0.93", "wpb": "673.1", "bsz": "28.6", "num_updates": "44600", "lr": "5.20376e-05", "gnorm": "1.796", "loss_scale": "128", "train_wall": "207", "gb_free": "10.7", "wall": "0"}
[2025-01-17 23:16:09,086][train_inner][INFO] - {"epoch": 45, "update": 44.688, "loss": "120.559", "nll_loss": "4.349", "total": "665.365", "n_correct": "349.3", "ppl": "20.37", "accuracy": "52.498", "wps": "649.6", "ups": "0.98", "wpb": "665.4", "bsz": "28.6", "num_updates": "44800", "lr": "5.10086e-05", "gnorm": "1.759", "loss_scale": "128", "train_wall": "198", "gb_free": "10.8", "wall": "0"}
[2025-01-17 23:19:42,331][train_inner][INFO] - {"epoch": 45, "update": 44.722, "loss": "122.549", "nll_loss": "4.477", "total": "663.695", "n_correct": "341.575", "ppl": "22.27", "accuracy": "51.466", "wps": "622.5", "ups": "0.94", "wpb": "663.7", "bsz": "28.7", "num_updates": "45000", "lr": "5e-05", "gnorm": "1.606", "loss_scale": "128", "train_wall": "207", "gb_free": "10.9", "wall": "0"}
[2025-01-17 23:19:42,332][fairseq_cli.train][INFO] - Stopping training due to num_updates: 45000 >= max_update: 45000
[2025-01-17 23:19:42,334][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-17 23:20:33,990][valid][INFO] - {"epoch": 45, "valid_loss": "40.059", "valid_nll_loss": "2.078", "valid_total": "678.4", "valid_n_correct": "498.55", "valid_ppl": "4.22", "valid_accuracy": "73.489", "valid_wps": "516.4", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "45000", "valid_best_accuracy": "73.688"}
[2025-01-17 23:20:33,993][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 45000 updates
[2025-01-17 23:20:33,993][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 23:20:38,142][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-17 23:20:38,147][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 45 @ 45000 updates, score 73.489) (writing took 4.154457695782185 seconds)
[2025-01-17 23:20:38,149][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2025-01-17 23:20:38,154][train][INFO] - {"epoch": 45, "train_loss": "126.501", "train_nll_loss": "4.485", "train_total": "666.007", "train_n_correct": "341.661", "train_ppl": "22.4", "train_accuracy": "51.3", "train_wps": "628.3", "train_ups": "0.94", "train_wpb": "666", "train_bsz": "27.9", "train_num_updates": "45000", "train_lr": "5e-05", "train_gnorm": "1.886", "train_loss_scale": "128", "train_train_wall": "4251", "train_gb_free": "10.9", "train_wall": "0"}
[2025-01-17 23:20:38,155][fairseq_cli.train][INFO] - done training in 47254.3 seconds
