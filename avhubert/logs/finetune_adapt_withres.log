2025-01-30 00:16:06 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15245
2025-01-30 00:16:06 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15245
[W130 00:16:06.375966055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-30 00:16:06 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 1
2025-01-30 00:16:07 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15245
[W130 00:16:07.449242485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-30 00:16:07 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 3
2025-01-30 00:16:07 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15245
[W130 00:16:07.640804778 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W130 00:16:07.641056267 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
2025-01-30 00:16:07 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 2
2025-01-30 00:16:07 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 0
[2025-01-30 00:16:08,977][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/workspace/av_hubert/avhubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15245', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 30000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/workspace/AV_HuBERT_pretrained/base_vox_iter5.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 24000, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True, 'prompting': True}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/workspace/lrs2/29h_data', 'label_dir': '/workspace/lrs2/29h_data', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'fine_tuning': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video', 'audio'], 'image_aug': True, 'pad_audio': True, 'random_crop': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 0, 'decay_steps': 20000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 30000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2025-01-30 00:16:08,995][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/avhubert/finetune_adapt_withres
[2025-01-30 00:16:08,996][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/29h_data', 'labels': ['wrd'], 'label_dir': '/workspace/lrs2/29h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video', 'audio'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}
2025-01-30 00:16:10 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2025-01-30 00:16:10,949][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/avhubert/finetune_adapt_withres
[2025-01-30 00:16:10,949][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/29h_data', 'labels': ['km'], 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'label_rate': 25, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 2000, 'min_sample_size': 5, 'max_trim_sample_size': 400, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': False}
[2025-01-30 00:16:10,973][avhubert.hubert][INFO] - HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
2025-01-30 00:16:11 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
2025-01-30 00:16:11 | INFO | avhubert.hubert | HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
all_params: 162.59M learnable_params: 162.59M
[2025-01-30 00:16:26,300][fairseq_cli.train][INFO] - AVHubertSeq2Seq(
  (encoder): HubertEncoderWrapper(
    (w2v_model): AVHubertModel(
      (modal_prompt_learner): MultiModalPromptLearner(
        (compound_prompt_projections_audio): ModuleList(
          (0-3): 4 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_audio): ModuleList(
          (0-3): 4 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (compound_prompt_projections_video): ModuleList(
          (0-3): 4 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_video): ModuleList(
          (0-3): 4 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (common_prompt_projection_video): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
        (common_prompt_projection_audio): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
      )
      (feature_extractor_audio): SubModel(
        (proj): Linear(in_features=104, out_features=768, bias=True)
      )
      (feature_extractor_video): SubModel(
        (resnet): ResEncoder(
          (frontend3D): Sequential(
            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): PReLU(num_parameters=64)
            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
          )
          (trunk): ResNet(
            (layer1): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer2): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer3): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer4): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (avgpool): AdaptiveAvgPool2d(output_size=1)
          )
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (resblocks_audio): Sequential()
      (resblocks_video): Sequential()
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2025-01-30 00:16:26,306][fairseq_cli.train][INFO] - task: AVHubertPretrainingTask
[2025-01-30 00:16:26,306][fairseq_cli.train][INFO] - model: AVHubertSeq2Seq
[2025-01-30 00:16:26,307][fairseq_cli.train][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2025-01-30 00:16:26,310][fairseq_cli.train][INFO] - num. shared model params: 162,586,696 (num. trained: 162,586,696)
[2025-01-30 00:16:26,313][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2025-01-30 00:16:26,325][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2025-01-30 00:16:26,351][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 1082, skipped 0 short and 0 long and 0 unaligned, longest-loaded=153, shortest-loaded=14
[2025-01-30 00:16:26,352][avhubert.hubert_dataset][INFO] - /workspace/lrs2/29h_data/valid.wrd is sequence label. skipped
[2025-01-30 00:16:26,352][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <avhubert.utils.CenterCrop object at 0x7f782374f0a0>
    Normalize(mean=0.421, std=0.165)
)
[2025-01-30 00:16:26,352][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2025-01-30 00:16:26,353][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2025-01-30 00:16:36,270][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv1.bias
[2025-01-30 00:16:36,271][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv2.bias
[2025-01-30 00:16:36,271][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv1.bias
[2025-01-30 00:16:36,272][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv2.bias
[2025-01-30 00:16:36,272][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv1.bias
[2025-01-30 00:16:36,272][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv2.bias
[2025-01-30 00:16:36,272][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.downsample.0.bias
[2025-01-30 00:16:36,273][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv1.bias
[2025-01-30 00:16:36,273][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv2.bias
[2025-01-30 00:16:36,273][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv1.bias
[2025-01-30 00:16:36,273][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv2.bias
[2025-01-30 00:16:36,274][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.downsample.0.bias
[2025-01-30 00:16:36,274][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv1.bias
[2025-01-30 00:16:36,274][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv2.bias
[2025-01-30 00:16:36,274][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv1.bias
[2025-01-30 00:16:36,275][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv2.bias
[2025-01-30 00:16:36,275][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.downsample.0.bias
[2025-01-30 00:16:36,275][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv1.bias
[2025-01-30 00:16:36,275][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv2.bias
[2025-01-30 00:16:36,573][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2025-01-30 00:16:36,573][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-30 00:16:36,573][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-30 00:16:36,573][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-30 00:16:36,574][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2025-01-30 00:16:36,574][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2025-01-30 00:16:36,575][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2025-01-30 00:16:36,576][fairseq_cli.train][INFO] - max tokens per device = 1000 and max sentences per device = None
[2025-01-30 00:16:36,583][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2025-01-30 00:16:36,584][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2025-01-30 00:16:36,584][fairseq.trainer][INFO] - loading train data for epoch 1
[2025-01-30 00:16:36,585][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2025-01-30 00:16:37,214][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 45840, skipped 0 short and 0 long and 0 unaligned, longest-loaded=154, shortest-loaded=0
[2025-01-30 00:16:37,310][avhubert.hubert_dataset][INFO] - /workspace/lrs2/29h_data/train.wrd is sequence label. skipped
[2025-01-30 00:16:37,310][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <avhubert.utils.HorizontalFlip object at 0x7f77f22c2970>
    Normalize(mean=0.421, std=0.165)
)
[2025-01-30 00:16:37,310][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2025-01-30 00:16:37,310][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2025-01-30 00:16:42,841][fairseq.trainer][INFO] - begin training epoch 1
[2025-01-30 00:16:42,845][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
all_params: 162.59M learnable_params: 162.59M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
all_params: 162.59M learnable_params: 162.59M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
all_params: 162.59M learnable_params: 162.59M
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
[2025-01-30 00:27:21,057][train_inner][INFO] - {"epoch": 1, "update": 0.249, "loss": "104.566", "nll_loss": "8.206", "total": "711.38", "n_correct": "70.21", "ppl": "295.34", "accuracy": "9.87", "wps": "264.5", "ups": "0.37", "wpb": "711.4", "bsz": "57.7", "num_updates": "200", "lr": "2.98e-05", "gnorm": "32.407", "loss_scale": "128", "train_wall": "549", "gb_free": "6", "wall": "644"}
[2025-01-30 00:36:11,353][train_inner][INFO] - {"epoch": 1, "update": 0.498, "loss": "101.718", "nll_loss": "7.725", "total": "717.53", "n_correct": "89.775", "ppl": "211.56", "accuracy": "12.512", "wps": "270.6", "ups": "0.38", "wpb": "717.5", "bsz": "56.9", "num_updates": "400", "lr": "4.96e-05", "gnorm": "24.506", "loss_scale": "128", "train_wall": "515", "gb_free": "7.2", "wall": "1175"}
[2025-01-30 00:45:00,287][train_inner][INFO] - {"epoch": 1, "update": 0.746, "loss": "95.297", "nll_loss": "7.21", "total": "705.65", "n_correct": "127.505", "ppl": "148.1", "accuracy": "18.069", "wps": "266.8", "ups": "0.38", "wpb": "705.6", "bsz": "56.5", "num_updates": "600", "lr": "6.94e-05", "gnorm": "26.707", "loss_scale": "128", "train_wall": "515", "gb_free": "6.2", "wall": "1704"}
[2025-01-30 00:53:24,425][train_inner][INFO] - {"epoch": 1, "update": 0.995, "loss": "89.029", "nll_loss": "6.642", "total": "714.165", "n_correct": "157.87", "ppl": "99.9", "accuracy": "22.106", "wps": "283.3", "ups": "0.4", "wpb": "714.2", "bsz": "57.3", "num_updates": "800", "lr": "8.92e-05", "gnorm": "31.156", "loss_scale": "128", "train_wall": "490", "gb_free": "6.5", "wall": "2208"}
[2025-01-30 00:53:26,810][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2025-01-30 00:53:26,820][train][INFO] - {"epoch": 1, "train_loss": "97.683", "train_nll_loss": "7.443", "train_total": "711.575", "train_n_correct": "111.404", "train_ppl": "174", "train_accuracy": "15.656", "train_wps": "271.9", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "804", "train_lr": "8.9596e-05", "train_gnorm": "28.769", "train_loss_scale": "128", "train_train_wall": "2070", "train_gb_free": "6.2", "train_wall": "2210"}
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2025-01-30 00:53:30,534][fairseq.trainer][INFO] - begin training epoch 2
[2025-01-30 00:53:30,536][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2025-01-30 01:02:44,284][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2025-01-30 01:02:46,182][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2025-01-30 01:03:10,357][train_inner][INFO] - {"epoch": 2, "update": 1.246, "loss": "84.639", "nll_loss": "6.136", "total": "708.17", "n_correct": "171.92", "ppl": "70.33", "accuracy": "24.277", "wps": "241.7", "ups": "0.34", "wpb": "708.2", "bsz": "56.1", "num_updates": "1000", "lr": "0.000109", "gnorm": "36.176", "loss_scale": "32", "train_wall": "491", "gb_free": "6.6", "wall": "2794"}
[2025-01-30 01:12:18,372][train_inner][INFO] - {"epoch": 2, "update": 1.495, "loss": "71.534", "nll_loss": "5.238", "total": "726.155", "n_correct": "215.835", "ppl": "37.75", "accuracy": "29.723", "wps": "265", "ups": "0.37", "wpb": "726.2", "bsz": "60.3", "num_updates": "1200", "lr": "0.0001288", "gnorm": "40.091", "loss_scale": "32", "train_wall": "532", "gb_free": "6.9", "wall": "3342"}
[2025-01-30 01:21:08,412][train_inner][INFO] - {"epoch": 2, "update": 1.744, "loss": "70.353", "nll_loss": "4.877", "total": "707.39", "n_correct": "219.785", "ppl": "29.39", "accuracy": "31.07", "wps": "266.9", "ups": "0.38", "wpb": "707.4", "bsz": "56.7", "num_updates": "1400", "lr": "0.0001486", "gnorm": "39.782", "loss_scale": "32", "train_wall": "516", "gb_free": "6.4", "wall": "3872"}
[2025-01-30 01:29:19,659][train_inner][INFO] - {"epoch": 2, "update": 1.993, "loss": "70.917", "nll_loss": "4.706", "total": "705.475", "n_correct": "222.745", "ppl": "26.1", "accuracy": "31.574", "wps": "287.2", "ups": "0.41", "wpb": "705.5", "bsz": "54.8", "num_updates": "1600", "lr": "0.0001684", "gnorm": "40.458", "loss_scale": "32", "train_wall": "479", "gb_free": "6.2", "wall": "4363"}
[2025-01-30 01:29:23,223][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 01:31:05,492][valid][INFO] - {"epoch": 2, "valid_loss": "63.335", "valid_nll_loss": "4.132", "valid_total": "678.4", "valid_n_correct": "248.2", "valid_ppl": "17.54", "valid_accuracy": "36.586", "valid_wps": "399.4", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "1606"}
[2025-01-30 01:31:05,500][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 1606 updates
[2025-01-30 01:31:05,504][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 01:31:17,921][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 01:31:21,923][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 1606 updates, score 36.586) (writing took 16.42249890603125 seconds)
[2025-01-30 01:31:21,924][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2025-01-30 01:31:21,933][train][INFO] - {"epoch": 2, "train_loss": "74.148", "train_nll_loss": "5.229", "train_total": "711.52", "train_n_correct": "207.944", "train_ppl": "37.5", "train_accuracy": "29.225", "train_wps": "250.8", "train_ups": "0.35", "train_wpb": "711.5", "train_bsz": "57", "train_num_updates": "1606", "train_lr": "0.000168994", "train_gnorm": "39.042", "train_loss_scale": "32", "train_train_wall": "2020", "train_gb_free": "6", "train_wall": "4485"}
[2025-01-30 01:31:23,892][fairseq.trainer][INFO] - begin training epoch 3
[2025-01-30 01:31:23,893][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 01:41:26,125][train_inner][INFO] - {"epoch": 3, "update": 2.241, "loss": "63.552", "nll_loss": "4.194", "total": "707.23", "n_correct": "252.72", "ppl": "18.3", "accuracy": "35.734", "wps": "194.7", "ups": "0.28", "wpb": "707.2", "bsz": "56.5", "num_updates": "1800", "lr": "0.0001882", "gnorm": "37.688", "loss_scale": "32", "train_wall": "499", "gb_free": "6.6", "wall": "5090"}
[2025-01-30 01:50:24,490][train_inner][INFO] - {"epoch": 3, "update": 2.49, "loss": "64.46", "nll_loss": "4.158", "total": "707.755", "n_correct": "257.555", "ppl": "17.86", "accuracy": "36.39", "wps": "262.9", "ups": "0.37", "wpb": "707.8", "bsz": "55.5", "num_updates": "2000", "lr": "0.000208", "gnorm": "39.994", "loss_scale": "32", "train_wall": "525", "gb_free": "6", "wall": "5628"}
[2025-01-30 01:59:38,450][train_inner][INFO] - {"epoch": 3, "update": 2.739, "loss": "59.525", "nll_loss": "3.875", "total": "712.605", "n_correct": "286.37", "ppl": "14.67", "accuracy": "40.186", "wps": "257.3", "ups": "0.36", "wpb": "712.6", "bsz": "57.6", "num_updates": "2200", "lr": "0.0002278", "gnorm": "38.129", "loss_scale": "32", "train_wall": "540", "gb_free": "5.9", "wall": "6182"}
[2025-01-30 02:08:08,165][train_inner][INFO] - {"epoch": 3, "update": 2.988, "loss": "55.696", "nll_loss": "3.571", "total": "716.25", "n_correct": "318.44", "ppl": "11.88", "accuracy": "44.459", "wps": "281", "ups": "0.39", "wpb": "716.2", "bsz": "58.5", "num_updates": "2400", "lr": "0.0002476", "gnorm": "38.624", "loss_scale": "32", "train_wall": "496", "gb_free": "6.3", "wall": "6692"}
[2025-01-30 02:08:13,739][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2025-01-30 02:08:13,744][train][INFO] - {"epoch": 3, "train_loss": "60.689", "train_nll_loss": "3.94", "train_total": "711.575", "train_n_correct": "279.796", "train_ppl": "15.35", "train_accuracy": "39.321", "train_wps": "258.7", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "2410", "train_lr": "0.00024859", "train_gnorm": "38.822", "train_loss_scale": "32", "train_train_wall": "2062", "train_gb_free": "6.4", "train_wall": "6697"}
[2025-01-30 02:08:16,143][fairseq.trainer][INFO] - begin training epoch 4
[2025-01-30 02:08:16,144][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 02:17:31,797][train_inner][INFO] - {"epoch": 4, "update": 3.236, "loss": "52.577", "nll_loss": "3.144", "total": "710.555", "n_correct": "355.52", "ppl": "8.84", "accuracy": "50.034", "wps": "252.2", "ups": "0.35", "wpb": "710.6", "bsz": "56.6", "num_updates": "2600", "lr": "0.0002674", "gnorm": "42.76", "loss_scale": "32", "train_wall": "498", "gb_free": "6.7", "wall": "7255"}
[2025-01-30 02:26:25,207][train_inner][INFO] - {"epoch": 4, "update": 3.485, "loss": "50.194", "nll_loss": "3.009", "total": "716.995", "n_correct": "378.115", "ppl": "8.05", "accuracy": "52.736", "wps": "268.8", "ups": "0.37", "wpb": "717", "bsz": "58.1", "num_updates": "2800", "lr": "0.0002872", "gnorm": "43.413", "loss_scale": "32", "train_wall": "519", "gb_free": "6.2", "wall": "7789"}
[2025-01-30 02:35:08,644][train_inner][INFO] - {"epoch": 4, "update": 3.734, "loss": "51.011", "nll_loss": "2.902", "total": "704.85", "n_correct": "386.71", "ppl": "7.47", "accuracy": "54.864", "wps": "269.3", "ups": "0.38", "wpb": "704.9", "bsz": "55", "num_updates": "3000", "lr": "0.000307", "gnorm": "45.627", "loss_scale": "32", "train_wall": "510", "gb_free": "6.5", "wall": "8312"}
[2025-01-30 02:43:24,123][train_inner][INFO] - {"epoch": 4, "update": 3.983, "loss": "46.735", "nll_loss": "2.698", "total": "715.255", "n_correct": "417.655", "ppl": "6.49", "accuracy": "58.392", "wps": "288.7", "ups": "0.4", "wpb": "715.3", "bsz": "58.2", "num_updates": "3200", "lr": "0.0003268", "gnorm": "42.847", "loss_scale": "32", "train_wall": "481", "gb_free": "6.4", "wall": "8808"}
[2025-01-30 02:43:32,807][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 02:45:15,449][valid][INFO] - {"epoch": 4, "valid_loss": "45.185", "valid_nll_loss": "2.41", "valid_total": "678.4", "valid_n_correct": "419.95", "valid_ppl": "5.32", "valid_accuracy": "61.903", "valid_wps": "319.7", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "3214", "valid_best_accuracy": "61.903"}
[2025-01-30 02:45:15,457][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 3214 updates
[2025-01-30 02:45:15,460][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 02:45:30,269][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 02:45:35,749][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 3214 updates, score 61.903) (writing took 20.292146326974034 seconds)
[2025-01-30 02:45:35,750][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2025-01-30 02:45:35,760][train][INFO] - {"epoch": 4, "train_loss": "49.912", "train_nll_loss": "2.927", "train_total": "711.575", "train_n_correct": "385.551", "train_ppl": "7.61", "train_accuracy": "54.183", "train_wps": "255.2", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "3214", "train_lr": "0.000328186", "train_gnorm": "43.581", "train_loss_scale": "32", "train_train_wall": "2010", "train_gb_free": "6.2", "train_wall": "8939"}
[2025-01-30 02:45:37,981][fairseq.trainer][INFO] - begin training epoch 5
[2025-01-30 02:45:37,982][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 02:55:19,540][train_inner][INFO] - {"epoch": 5, "update": 4.231, "loss": "44.427", "nll_loss": "2.358", "total": "704.25", "n_correct": "444.705", "ppl": "5.13", "accuracy": "63.146", "wps": "196.9", "ups": "0.28", "wpb": "704.2", "bsz": "55.6", "num_updates": "3400", "lr": "0.0003466", "gnorm": "39.807", "loss_scale": "32", "train_wall": "486", "gb_free": "6.4", "wall": "9523"}
[2025-01-30 03:04:14,163][train_inner][INFO] - {"epoch": 5, "update": 4.48, "loss": "42.568", "nll_loss": "2.281", "total": "715.925", "n_correct": "464.78", "ppl": "4.86", "accuracy": "64.92", "wps": "267.8", "ups": "0.37", "wpb": "715.9", "bsz": "57.8", "num_updates": "3600", "lr": "0.0003664", "gnorm": "37.544", "loss_scale": "32", "train_wall": "519", "gb_free": "6", "wall": "10058"}
[2025-01-30 03:13:13,280][train_inner][INFO] - {"epoch": 5, "update": 4.729, "loss": "40.475", "nll_loss": "2.172", "total": "717.24", "n_correct": "479.36", "ppl": "4.51", "accuracy": "66.834", "wps": "266.1", "ups": "0.37", "wpb": "717.2", "bsz": "59.2", "num_updates": "3800", "lr": "0.0003862", "gnorm": "34.262", "loss_scale": "32", "train_wall": "525", "gb_free": "6.2", "wall": "10597"}
[2025-01-30 03:21:00,690][train_inner][INFO] - {"epoch": 5, "update": 4.978, "loss": "42.805", "nll_loss": "2.182", "total": "709.37", "n_correct": "475.835", "ppl": "4.54", "accuracy": "67.079", "wps": "303.6", "ups": "0.43", "wpb": "709.4", "bsz": "55.5", "num_updates": "4000", "lr": "0.000406", "gnorm": "36.484", "loss_scale": "32", "train_wall": "456", "gb_free": "6.8", "wall": "11064"}
[2025-01-30 03:21:11,865][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2025-01-30 03:21:11,872][train][INFO] - {"epoch": 5, "train_loss": "42.485", "train_nll_loss": "2.242", "train_total": "711.575", "train_n_correct": "466.953", "train_ppl": "4.73", "train_accuracy": "65.622", "train_wps": "267.8", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "4018", "train_lr": "0.000407782", "train_gnorm": "36.873", "train_loss_scale": "32", "train_train_wall": "1987", "train_gb_free": "6.7", "train_wall": "11075"}
[2025-01-30 03:21:15,628][fairseq.trainer][INFO] - begin training epoch 6
[2025-01-30 03:21:15,631][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 03:30:54,961][train_inner][INFO] - {"epoch": 6, "update": 5.226, "loss": "38.686", "nll_loss": "1.877", "total": "705.68", "n_correct": "505.29", "ppl": "3.67", "accuracy": "71.603", "wps": "237.5", "ups": "0.34", "wpb": "705.7", "bsz": "56.3", "num_updates": "4200", "lr": "0.0004258", "gnorm": "30.334", "loss_scale": "32", "train_wall": "524", "gb_free": "6.3", "wall": "11658"}
[2025-01-30 03:39:38,450][train_inner][INFO] - {"epoch": 6, "update": 5.475, "loss": "38.592", "nll_loss": "1.834", "total": "708.585", "n_correct": "511.84", "ppl": "3.56", "accuracy": "72.234", "wps": "270.7", "ups": "0.38", "wpb": "708.6", "bsz": "55.9", "num_updates": "4400", "lr": "0.0004456", "gnorm": "31.826", "loss_scale": "32", "train_wall": "508", "gb_free": "5.8", "wall": "12182"}
[2025-01-30 03:48:38,144][train_inner][INFO] - {"epoch": 6, "update": 5.724, "loss": "37.68", "nll_loss": "1.822", "total": "724.21", "n_correct": "525.725", "ppl": "3.54", "accuracy": "72.593", "wps": "268.4", "ups": "0.37", "wpb": "724.2", "bsz": "58.3", "num_updates": "4600", "lr": "0.0004654", "gnorm": "28.326", "loss_scale": "32", "train_wall": "526", "gb_free": "7.1", "wall": "12722"}
[2025-01-30 03:57:10,014][train_inner][INFO] - {"epoch": 6, "update": 5.973, "loss": "36.628", "nll_loss": "1.765", "total": "706.21", "n_correct": "521.39", "ppl": "3.4", "accuracy": "73.829", "wps": "275.9", "ups": "0.39", "wpb": "706.2", "bsz": "57.5", "num_updates": "4800", "lr": "0.0004852", "gnorm": "26.629", "loss_scale": "32", "train_wall": "500", "gb_free": "5.9", "wall": "13233"}
[2025-01-30 03:57:25,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 03:59:08,946][valid][INFO] - {"epoch": 6, "valid_loss": "37.657", "valid_nll_loss": "1.76", "valid_total": "678.4", "valid_n_correct": "503.95", "valid_ppl": "3.39", "valid_accuracy": "74.285", "valid_wps": "331", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "4822", "valid_best_accuracy": "74.285"}
[2025-01-30 03:59:08,952][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 4822 updates
[2025-01-30 03:59:08,954][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 03:59:24,957][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 03:59:30,053][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 4822 updates, score 74.285) (writing took 21.100962669588625 seconds)
[2025-01-30 03:59:30,055][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2025-01-30 03:59:30,070][train][INFO] - {"epoch": 6, "train_loss": "37.781", "train_nll_loss": "1.813", "train_total": "711.575", "train_n_correct": "517.613", "train_ppl": "3.51", "train_accuracy": "72.742", "train_wps": "248.9", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "4822", "train_lr": "0.000487378", "train_gnorm": "28.993", "train_loss_scale": "32", "train_train_wall": "2062", "train_gb_free": "5.8", "train_wall": "13373"}
[2025-01-30 03:59:32,307][fairseq.trainer][INFO] - begin training epoch 7
[2025-01-30 03:59:32,311][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 04:09:11,010][train_inner][INFO] - {"epoch": 7, "update": 6.221, "loss": "34.168", "nll_loss": "1.541", "total": "712.1", "n_correct": "547.97", "ppl": "2.91", "accuracy": "76.951", "wps": "197.5", "ups": "0.28", "wpb": "712.1", "bsz": "58.1", "num_updates": "5000", "lr": "0.000505", "gnorm": "24.609", "loss_scale": "32", "train_wall": "483", "gb_free": "6.6", "wall": "13954"}
[2025-01-30 04:18:18,076][train_inner][INFO] - {"epoch": 7, "update": 6.47, "loss": "34.286", "nll_loss": "1.527", "total": "711.485", "n_correct": "550.71", "ppl": "2.88", "accuracy": "77.403", "wps": "260.1", "ups": "0.37", "wpb": "711.5", "bsz": "57.5", "num_updates": "5200", "lr": "0.0005248", "gnorm": "24.1", "loss_scale": "64", "train_wall": "531", "gb_free": "5.9", "wall": "14501"}
[2025-01-30 04:26:26,437][train_inner][INFO] - {"epoch": 7, "update": 6.719, "loss": "35.253", "nll_loss": "1.595", "total": "720.97", "n_correct": "550.795", "ppl": "3.02", "accuracy": "76.396", "wps": "295.4", "ups": "0.41", "wpb": "721", "bsz": "57.9", "num_updates": "5400", "lr": "0.0005446", "gnorm": "24.614", "loss_scale": "64", "train_wall": "474", "gb_free": "6.1", "wall": "14990"}
[2025-01-30 04:35:13,116][train_inner][INFO] - {"epoch": 7, "update": 6.968, "loss": "35.789", "nll_loss": "1.577", "total": "706.44", "n_correct": "543.5", "ppl": "2.98", "accuracy": "76.935", "wps": "268.3", "ups": "0.38", "wpb": "706.4", "bsz": "55.5", "num_updates": "5600", "lr": "0.0005644", "gnorm": "23.424", "loss_scale": "64", "train_wall": "513", "gb_free": "6.6", "wall": "15516"}
[2025-01-30 04:35:36,159][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2025-01-30 04:35:36,167][train][INFO] - {"epoch": 7, "train_loss": "34.92", "train_nll_loss": "1.556", "train_total": "711.575", "train_n_correct": "547.806", "train_ppl": "2.94", "train_accuracy": "76.985", "train_wps": "264.1", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "5626", "train_lr": "0.000566974", "train_gnorm": "24.235", "train_loss_scale": "64", "train_train_wall": "2010", "train_gb_free": "6.2", "train_wall": "15540"}
[2025-01-30 04:35:39,607][fairseq.trainer][INFO] - begin training epoch 8
[2025-01-30 04:35:39,608][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 04:44:59,227][train_inner][INFO] - {"epoch": 8, "update": 7.216, "loss": "32.947", "nll_loss": "1.359", "total": "709.535", "n_correct": "567.34", "ppl": "2.57", "accuracy": "79.959", "wps": "242.1", "ups": "0.34", "wpb": "709.5", "bsz": "56.5", "num_updates": "5800", "lr": "0.0005842", "gnorm": "21.068", "loss_scale": "64", "train_wall": "500", "gb_free": "7.2", "wall": "16103"}
[2025-01-30 04:54:08,296][train_inner][INFO] - {"epoch": 8, "update": 7.465, "loss": "33.178", "nll_loss": "1.414", "total": "713.99", "n_correct": "565.28", "ppl": "2.66", "accuracy": "79.172", "wps": "260.1", "ups": "0.36", "wpb": "714", "bsz": "57.5", "num_updates": "6000", "lr": "0.000604", "gnorm": "22.449", "loss_scale": "64", "train_wall": "535", "gb_free": "6.6", "wall": "16652"}
[2025-01-30 05:02:39,429][train_inner][INFO] - {"epoch": 8, "update": 7.714, "loss": "34.185", "nll_loss": "1.441", "total": "708.64", "n_correct": "557.97", "ppl": "2.72", "accuracy": "78.738", "wps": "277.3", "ups": "0.39", "wpb": "708.6", "bsz": "55.8", "num_updates": "6200", "lr": "0.0006238", "gnorm": "21.317", "loss_scale": "64", "train_wall": "498", "gb_free": "6.3", "wall": "17163"}
[2025-01-30 05:05:45,812][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2025-01-30 05:11:46,986][train_inner][INFO] - {"epoch": 8, "update": 7.964, "loss": "33.397", "nll_loss": "1.452", "total": "709.29", "n_correct": "559.345", "ppl": "2.74", "accuracy": "78.86", "wps": "259.1", "ups": "0.37", "wpb": "709.3", "bsz": "57.3", "num_updates": "6400", "lr": "0.0006436", "gnorm": "22.048", "loss_scale": "32", "train_wall": "535", "gb_free": "6", "wall": "17710"}
[2025-01-30 05:12:21,255][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 05:13:59,315][valid][INFO] - {"epoch": 8, "valid_loss": "35.722", "valid_nll_loss": "1.598", "valid_total": "678.4", "valid_n_correct": "523.05", "valid_ppl": "3.03", "valid_accuracy": "77.101", "valid_wps": "301.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "6429", "valid_best_accuracy": "77.101"}
[2025-01-30 05:13:59,319][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 6429 updates
[2025-01-30 05:13:59,320][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 05:14:14,433][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 05:14:20,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 6429 updates, score 77.101) (writing took 21.639707665890455 seconds)
[2025-01-30 05:14:20,960][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2025-01-30 05:14:20,976][train][INFO] - {"epoch": 8, "train_loss": "33.276", "train_nll_loss": "1.41", "train_total": "711.624", "train_n_correct": "564.052", "train_ppl": "2.66", "train_accuracy": "79.263", "train_wps": "245.8", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "6429", "train_lr": "0.000646471", "train_gnorm": "21.623", "train_loss_scale": "32", "train_train_wall": "2079", "train_gb_free": "5.9", "train_wall": "17864"}
[2025-01-30 05:14:23,064][fairseq.trainer][INFO] - begin training epoch 9
[2025-01-30 05:14:23,065][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 05:23:30,539][train_inner][INFO] - {"epoch": 9, "update": 8.213, "loss": "32.342", "nll_loss": "1.257", "total": "709.65", "n_correct": "578.575", "ppl": "2.39", "accuracy": "81.53", "wps": "201.7", "ups": "0.28", "wpb": "709.6", "bsz": "55.6", "num_updates": "6600", "lr": "0.0006634", "gnorm": "20.192", "loss_scale": "32", "train_wall": "478", "gb_free": "6.7", "wall": "18414"}
[2025-01-30 05:31:55,529][train_inner][INFO] - {"epoch": 9, "update": 8.461, "loss": "31.437", "nll_loss": "1.293", "total": "716.79", "n_correct": "581.35", "ppl": "2.45", "accuracy": "81.105", "wps": "283.9", "ups": "0.4", "wpb": "716.8", "bsz": "58.4", "num_updates": "6800", "lr": "0.0006832", "gnorm": "18.737", "loss_scale": "32", "train_wall": "492", "gb_free": "6.3", "wall": "18919"}
[2025-01-30 05:40:39,564][train_inner][INFO] - {"epoch": 9, "update": 8.71, "loss": "32.212", "nll_loss": "1.337", "total": "716.995", "n_correct": "577.275", "ppl": "2.53", "accuracy": "80.513", "wps": "273.7", "ups": "0.38", "wpb": "717", "bsz": "57.8", "num_updates": "7000", "lr": "0.000703", "gnorm": "19.411", "loss_scale": "32", "train_wall": "511", "gb_free": "6.5", "wall": "19443"}
[2025-01-30 05:49:27,342][train_inner][INFO] - {"epoch": 9, "update": 8.959, "loss": "32.15", "nll_loss": "1.34", "total": "709.46", "n_correct": "569.705", "ppl": "2.53", "accuracy": "80.301", "wps": "268.9", "ups": "0.38", "wpb": "709.5", "bsz": "57.4", "num_updates": "7200", "lr": "0.0007228", "gnorm": "19.029", "loss_scale": "32", "train_wall": "514", "gb_free": "5.9", "wall": "19971"}
[2025-01-30 05:50:06,204][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2025-01-30 05:50:06,210][train][INFO] - {"epoch": 9, "train_loss": "32.129", "train_nll_loss": "1.309", "train_total": "711.575", "train_n_correct": "575.305", "train_ppl": "2.48", "train_accuracy": "80.85", "train_wps": "266.7", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "7233", "train_lr": "0.000726067", "train_gnorm": "19.43", "train_loss_scale": "32", "train_train_wall": "2000", "train_gb_free": "6.9", "train_wall": "20010"}
[2025-01-30 05:50:09,940][fairseq.trainer][INFO] - begin training epoch 10
[2025-01-30 05:50:09,941][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 05:59:04,073][train_inner][INFO] - {"epoch": 10, "update": 9.208, "loss": "31.247", "nll_loss": "1.166", "total": "703.67", "n_correct": "584.575", "ppl": "2.24", "accuracy": "83.075", "wps": "244", "ups": "0.35", "wpb": "703.7", "bsz": "55.2", "num_updates": "7400", "lr": "0.0007426", "gnorm": "17.93", "loss_scale": "32", "train_wall": "505", "gb_free": "6.7", "wall": "20547"}
[2025-01-30 06:07:29,080][train_inner][INFO] - {"epoch": 10, "update": 9.456, "loss": "31.585", "nll_loss": "1.233", "total": "705.65", "n_correct": "579.36", "ppl": "2.35", "accuracy": "82.103", "wps": "279.5", "ups": "0.4", "wpb": "705.6", "bsz": "56", "num_updates": "7600", "lr": "0.0007624", "gnorm": "18.707", "loss_scale": "32", "train_wall": "490", "gb_free": "6.6", "wall": "21052"}
[2025-01-30 06:16:20,633][train_inner][INFO] - {"epoch": 10, "update": 9.705, "loss": "31.277", "nll_loss": "1.244", "total": "719.03", "n_correct": "588.94", "ppl": "2.37", "accuracy": "81.908", "wps": "270.5", "ups": "0.38", "wpb": "719", "bsz": "57.8", "num_updates": "7800", "lr": "0.0007822", "gnorm": "17.894", "loss_scale": "32", "train_wall": "518", "gb_free": "6.1", "wall": "21584"}
[2025-01-30 06:25:13,422][train_inner][INFO] - {"epoch": 10, "update": 9.954, "loss": "31.855", "nll_loss": "1.315", "total": "711.23", "n_correct": "574.775", "ppl": "2.49", "accuracy": "80.814", "wps": "267", "ups": "0.38", "wpb": "711.2", "bsz": "57.5", "num_updates": "8000", "lr": "0.000802", "gnorm": "18.352", "loss_scale": "32", "train_wall": "519", "gb_free": "6.7", "wall": "22117"}
[2025-01-30 06:26:09,054][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 06:27:52,837][valid][INFO] - {"epoch": 10, "valid_loss": "35.7", "valid_nll_loss": "1.564", "valid_total": "678.4", "valid_n_correct": "525", "valid_ppl": "2.96", "valid_accuracy": "77.388", "valid_wps": "286", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "8037", "valid_best_accuracy": "77.388"}
[2025-01-30 06:27:52,841][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 8037 updates
[2025-01-30 06:27:52,842][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 06:28:09,530][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 06:28:14,638][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 8037 updates, score 77.388) (writing took 21.797550682909787 seconds)
[2025-01-30 06:28:14,640][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2025-01-30 06:28:14,651][train][INFO] - {"epoch": 10, "train_loss": "31.265", "train_nll_loss": "1.233", "train_total": "711.575", "train_n_correct": "584.117", "train_ppl": "2.35", "train_accuracy": "82.088", "train_wps": "250", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "8037", "train_lr": "0.000805663", "train_gnorm": "17.921", "train_loss_scale": "32", "train_train_wall": "2048", "train_gb_free": "6.9", "train_wall": "22298"}
[2025-01-30 06:28:16,759][fairseq.trainer][INFO] - begin training epoch 11
[2025-01-30 06:28:16,759][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 06:37:10,987][train_inner][INFO] - {"epoch": 11, "update": 10.203, "loss": "29.743", "nll_loss": "1.126", "total": "718.87", "n_correct": "601.545", "ppl": "2.18", "accuracy": "83.679", "wps": "200.4", "ups": "0.28", "wpb": "718.9", "bsz": "58.3", "num_updates": "8200", "lr": "0.0008218", "gnorm": "16.558", "loss_scale": "32", "train_wall": "478", "gb_free": "7.1", "wall": "22834"}
[2025-01-30 06:45:17,252][train_inner][INFO] - {"epoch": 11, "update": 10.451, "loss": "30.964", "nll_loss": "1.17", "total": "709.605", "n_correct": "587.99", "ppl": "2.25", "accuracy": "82.862", "wps": "291.9", "ups": "0.41", "wpb": "709.6", "bsz": "56.1", "num_updates": "8400", "lr": "0.0008416", "gnorm": "17.009", "loss_scale": "32", "train_wall": "474", "gb_free": "7.1", "wall": "23321"}
[2025-01-30 06:54:14,830][train_inner][INFO] - {"epoch": 11, "update": 10.7, "loss": "30.901", "nll_loss": "1.216", "total": "708.605", "n_correct": "583.425", "ppl": "2.32", "accuracy": "82.334", "wps": "263.6", "ups": "0.37", "wpb": "708.6", "bsz": "57", "num_updates": "8600", "lr": "0.0008614", "gnorm": "17.104", "loss_scale": "32", "train_wall": "524", "gb_free": "7.2", "wall": "23858"}
[2025-01-30 07:03:12,371][train_inner][INFO] - {"epoch": 11, "update": 10.949, "loss": "31.716", "nll_loss": "1.268", "total": "709.71", "n_correct": "578.915", "ppl": "2.41", "accuracy": "81.571", "wps": "264.1", "ups": "0.37", "wpb": "709.7", "bsz": "56.7", "num_updates": "8800", "lr": "0.0008812", "gnorm": "17.699", "loss_scale": "32", "train_wall": "524", "gb_free": "7.1", "wall": "24396"}
[2025-01-30 07:04:21,930][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2025-01-30 07:04:21,942][train][INFO] - {"epoch": 11, "train_loss": "30.794", "train_nll_loss": "1.191", "train_total": "711.575", "train_n_correct": "588.102", "train_ppl": "2.28", "train_accuracy": "82.648", "train_wps": "264", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "8841", "train_lr": "0.000885259", "train_gnorm": "17.035", "train_loss_scale": "32", "train_train_wall": "2014", "train_gb_free": "6.6", "train_wall": "24465"}
[2025-01-30 07:04:25,332][fairseq.trainer][INFO] - begin training epoch 12
[2025-01-30 07:04:25,332][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 07:13:01,815][train_inner][INFO] - {"epoch": 12, "update": 11.198, "loss": "28.805", "nll_loss": "1.096", "total": "724.4", "n_correct": "609.165", "ppl": "2.14", "accuracy": "84.092", "wps": "245.8", "ups": "0.34", "wpb": "724.4", "bsz": "60", "num_updates": "9000", "lr": "0.000901", "gnorm": "15.48", "loss_scale": "32", "train_wall": "517", "gb_free": "6.6", "wall": "24985"}
[2025-01-30 07:21:42,501][train_inner][INFO] - {"epoch": 12, "update": 11.447, "loss": "31.432", "nll_loss": "1.166", "total": "704.78", "n_correct": "584.975", "ppl": "2.24", "accuracy": "83.001", "wps": "270.7", "ups": "0.38", "wpb": "704.8", "bsz": "54.8", "num_updates": "9200", "lr": "0.0009208", "gnorm": "17.68", "loss_scale": "32", "train_wall": "506", "gb_free": "6.1", "wall": "25506"}
[2025-01-30 07:30:28,627][train_inner][INFO] - {"epoch": 12, "update": 11.695, "loss": "30.412", "nll_loss": "1.17", "total": "703.455", "n_correct": "584.205", "ppl": "2.25", "accuracy": "83.048", "wps": "267.4", "ups": "0.38", "wpb": "703.5", "bsz": "56.6", "num_updates": "9400", "lr": "0.0009406", "gnorm": "16.095", "loss_scale": "32", "train_wall": "513", "gb_free": "7.1", "wall": "26032"}
[2025-01-30 07:39:20,501][train_inner][INFO] - {"epoch": 12, "update": 11.944, "loss": "30.931", "nll_loss": "1.234", "total": "711.635", "n_correct": "583.815", "ppl": "2.35", "accuracy": "82.039", "wps": "267.7", "ups": "0.38", "wpb": "711.6", "bsz": "57.5", "num_updates": "9600", "lr": "0.0009604", "gnorm": "16.537", "loss_scale": "32", "train_wall": "519", "gb_free": "6.4", "wall": "26564"}
[2025-01-30 07:40:34,795][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 07:42:18,054][valid][INFO] - {"epoch": 12, "valid_loss": "36.62", "valid_nll_loss": "1.661", "valid_total": "678.4", "valid_n_correct": "519.2", "valid_ppl": "3.16", "valid_accuracy": "76.533", "valid_wps": "304.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "9645", "valid_best_accuracy": "77.388"}
[2025-01-30 07:42:18,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 9645 updates
[2025-01-30 07:42:18,065][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 07:42:32,725][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 07:42:32,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 12 @ 9645 updates, score 76.533) (writing took 14.913996445015073 seconds)
[2025-01-30 07:42:32,978][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2025-01-30 07:42:32,986][train][INFO] - {"epoch": 12, "train_loss": "30.568", "train_nll_loss": "1.172", "train_total": "711.575", "train_n_correct": "590.282", "train_ppl": "2.25", "train_accuracy": "82.954", "train_wps": "249.7", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "9645", "train_lr": "0.000964855", "train_gnorm": "16.545", "train_loss_scale": "32", "train_train_wall": "2060", "train_gb_free": "6.4", "train_wall": "26756"}
[2025-01-30 07:42:35,126][fairseq.trainer][INFO] - begin training epoch 13
[2025-01-30 07:42:35,127][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 07:50:16,987][train_inner][INFO] - {"epoch": 13, "update": 12.193, "loss": "31.204", "nll_loss": "1.117", "total": "716.695", "n_correct": "599.485", "ppl": "2.17", "accuracy": "83.646", "wps": "218.4", "ups": "0.3", "wpb": "716.7", "bsz": "55.2", "num_updates": "9800", "lr": "0.0009802", "gnorm": "16.184", "loss_scale": "32", "train_wall": "432", "gb_free": "6.3", "wall": "27220"}
[2025-01-30 07:59:09,848][train_inner][INFO] - {"epoch": 13, "update": 12.442, "loss": "30.299", "nll_loss": "1.136", "total": "702.855", "n_correct": "586.575", "ppl": "2.2", "accuracy": "83.456", "wps": "263.8", "ups": "0.38", "wpb": "702.9", "bsz": "56.1", "num_updates": "10000", "lr": "0.001", "gnorm": "15.649", "loss_scale": "32", "train_wall": "518", "gb_free": "7.2", "wall": "27753"}
[2025-01-30 08:08:04,522][train_inner][INFO] - {"epoch": 13, "update": 12.69, "loss": "29.45", "nll_loss": "1.133", "total": "712.425", "n_correct": "595.16", "ppl": "2.19", "accuracy": "83.54", "wps": "266.5", "ups": "0.37", "wpb": "712.4", "bsz": "58.4", "num_updates": "10200", "lr": "0.000970487", "gnorm": "15.539", "loss_scale": "32", "train_wall": "520", "gb_free": "6.3", "wall": "28288"}
[2025-01-30 08:17:06,197][train_inner][INFO] - {"epoch": 13, "update": 12.939, "loss": "30.019", "nll_loss": "1.155", "total": "715.49", "n_correct": "594.59", "ppl": "2.23", "accuracy": "83.102", "wps": "264.2", "ups": "0.37", "wpb": "715.5", "bsz": "57.9", "num_updates": "10400", "lr": "0.000941845", "gnorm": "15.547", "loss_scale": "64", "train_wall": "529", "gb_free": "6.5", "wall": "28830"}
[2025-01-30 08:18:30,754][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2025-01-30 08:18:30,764][train][INFO] - {"epoch": 13, "train_loss": "30.063", "train_nll_loss": "1.127", "train_total": "711.575", "train_n_correct": "594.772", "train_ppl": "2.18", "train_accuracy": "83.585", "train_wps": "265.1", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "10449", "train_lr": "0.000934958", "train_gnorm": "15.658", "train_loss_scale": "64", "train_train_wall": "2009", "train_gb_free": "7.1", "train_wall": "28914"}
[2025-01-30 08:18:34,077][fairseq.trainer][INFO] - begin training epoch 14
[2025-01-30 08:18:34,078][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 08:26:31,071][train_inner][INFO] - {"epoch": 14, "update": 13.188, "loss": "29.376", "nll_loss": "1.019", "total": "717.24", "n_correct": "611.64", "ppl": "2.03", "accuracy": "85.277", "wps": "254", "ups": "0.35", "wpb": "717.2", "bsz": "56.5", "num_updates": "10600", "lr": "0.000914048", "gnorm": "15.058", "loss_scale": "64", "train_wall": "480", "gb_free": "6.5", "wall": "29394"}
[2025-01-30 08:35:37,513][train_inner][INFO] - {"epoch": 14, "update": 13.437, "loss": "28.467", "nll_loss": "0.973", "total": "706.04", "n_correct": "607.575", "ppl": "1.96", "accuracy": "86.054", "wps": "258.4", "ups": "0.37", "wpb": "706", "bsz": "56.4", "num_updates": "10800", "lr": "0.000887072", "gnorm": "14.045", "loss_scale": "64", "train_wall": "533", "gb_free": "6.8", "wall": "29941"}
[2025-01-30 08:44:39,069][train_inner][INFO] - {"epoch": 14, "update": 13.685, "loss": "29.23", "nll_loss": "0.997", "total": "710.835", "n_correct": "609.52", "ppl": "2", "accuracy": "85.747", "wps": "262.5", "ups": "0.37", "wpb": "710.8", "bsz": "55.7", "num_updates": "11000", "lr": "0.000860892", "gnorm": "14.571", "loss_scale": "64", "train_wall": "527", "gb_free": "6.9", "wall": "30482"}
[2025-01-30 08:53:37,534][train_inner][INFO] - {"epoch": 14, "update": 13.934, "loss": "27.915", "nll_loss": "0.99", "total": "716.98", "n_correct": "614.58", "ppl": "1.99", "accuracy": "85.718", "wps": "266.3", "ups": "0.37", "wpb": "717", "bsz": "58.6", "num_updates": "11200", "lr": "0.000835484", "gnorm": "13.482", "loss_scale": "64", "train_wall": "524", "gb_free": "6.2", "wall": "31021"}
[2025-01-30 08:55:05,909][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 08:56:18,276][valid][INFO] - {"epoch": 14, "valid_loss": "34.995", "valid_nll_loss": "1.545", "valid_total": "678.4", "valid_n_correct": "530.65", "valid_ppl": "2.92", "valid_accuracy": "78.221", "valid_wps": "477", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "11253", "valid_best_accuracy": "78.221"}
[2025-01-30 08:56:18,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 11253 updates
[2025-01-30 08:56:18,279][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 08:56:29,450][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 08:56:37,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 14 @ 11253 updates, score 78.221) (writing took 18.93115876056254 seconds)
[2025-01-30 08:56:37,214][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2025-01-30 08:56:37,227][train][INFO] - {"epoch": 14, "train_loss": "28.474", "train_nll_loss": "0.984", "train_total": "711.575", "train_n_correct": "610.896", "train_ppl": "1.98", "train_accuracy": "85.851", "train_wps": "250.2", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "11253", "train_lr": "0.000828878", "train_gnorm": "14.072", "train_loss_scale": "64", "train_train_wall": "2068", "train_gb_free": "6.2", "train_wall": "31201"}
[2025-01-30 08:56:39,564][fairseq.trainer][INFO] - begin training epoch 15
[2025-01-30 08:56:39,567][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 09:04:44,762][train_inner][INFO] - {"epoch": 15, "update": 14.183, "loss": "26.316", "nll_loss": "0.854", "total": "705.92", "n_correct": "621.22", "ppl": "1.81", "accuracy": "88.001", "wps": "211.6", "ups": "0.3", "wpb": "705.9", "bsz": "58.1", "num_updates": "11400", "lr": "0.000810826", "gnorm": "12.303", "loss_scale": "64", "train_wall": "465", "gb_free": "6.2", "wall": "31688"}
[2025-01-30 09:13:36,884][train_inner][INFO] - {"epoch": 15, "update": 14.432, "loss": "26.889", "nll_loss": "0.83", "total": "710.66", "n_correct": "627.765", "ppl": "1.78", "accuracy": "88.335", "wps": "267.2", "ups": "0.38", "wpb": "710.7", "bsz": "56.7", "num_updates": "11600", "lr": "0.000786896", "gnorm": "12.586", "loss_scale": "64", "train_wall": "519", "gb_free": "7.2", "wall": "32220"}
[2025-01-30 09:22:32,082][train_inner][INFO] - {"epoch": 15, "update": 14.68, "loss": "26.926", "nll_loss": "0.866", "total": "716.555", "n_correct": "628.91", "ppl": "1.82", "accuracy": "87.769", "wps": "267.8", "ups": "0.37", "wpb": "716.6", "bsz": "57.9", "num_updates": "11800", "lr": "0.000763673", "gnorm": "12.717", "loss_scale": "64", "train_wall": "522", "gb_free": "5.9", "wall": "32755"}
[2025-01-30 09:30:53,068][train_inner][INFO] - {"epoch": 15, "update": 14.929, "loss": "26.951", "nll_loss": "0.835", "total": "717.005", "n_correct": "632.575", "ppl": "1.78", "accuracy": "88.225", "wps": "286.2", "ups": "0.4", "wpb": "717", "bsz": "57.1", "num_updates": "12000", "lr": "0.000741134", "gnorm": "12.484", "loss_scale": "64", "train_wall": "488", "gb_free": "6.1", "wall": "33256"}
[2025-01-30 09:32:38,623][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2025-01-30 09:32:38,633][train][INFO] - {"epoch": 15, "train_loss": "26.832", "train_nll_loss": "0.837", "train_total": "711.575", "train_n_correct": "627.703", "train_ppl": "1.79", "train_accuracy": "88.213", "train_wps": "264.7", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "12057", "train_lr": "0.000734834", "train_gnorm": "12.486", "train_loss_scale": "64", "train_train_wall": "2011", "train_gb_free": "6.2", "train_wall": "33362"}
[2025-01-30 09:32:42,234][fairseq.trainer][INFO] - begin training epoch 16
[2025-01-30 09:32:42,235][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 09:40:35,981][train_inner][INFO] - {"epoch": 16, "update": 15.178, "loss": "25.762", "nll_loss": "0.73", "total": "701.525", "n_correct": "630.885", "ppl": "1.66", "accuracy": "89.931", "wps": "240.7", "ups": "0.34", "wpb": "701.5", "bsz": "55.9", "num_updates": "12200", "lr": "0.000719261", "gnorm": "11.361", "loss_scale": "64", "train_wall": "499", "gb_free": "6.8", "wall": "33839"}
[2025-01-30 09:49:22,438][train_inner][INFO] - {"epoch": 16, "update": 15.427, "loss": "25.183", "nll_loss": "0.7", "total": "716.645", "n_correct": "648.065", "ppl": "1.62", "accuracy": "90.43", "wps": "272.3", "ups": "0.38", "wpb": "716.6", "bsz": "57.7", "num_updates": "12400", "lr": "0.000698034", "gnorm": "11.545", "loss_scale": "64", "train_wall": "513", "gb_free": "6.4", "wall": "34366"}
[2025-01-30 09:58:04,466][train_inner][INFO] - {"epoch": 16, "update": 15.675, "loss": "25.021", "nll_loss": "0.693", "total": "706.68", "n_correct": "640.285", "ppl": "1.62", "accuracy": "90.605", "wps": "270.8", "ups": "0.38", "wpb": "706.7", "bsz": "57.1", "num_updates": "12600", "lr": "0.000677433", "gnorm": "10.923", "loss_scale": "64", "train_wall": "509", "gb_free": "6.7", "wall": "34888"}
[2025-01-30 10:06:00,846][train_inner][INFO] - {"epoch": 16, "update": 15.924, "loss": "25.722", "nll_loss": "0.727", "total": "711.49", "n_correct": "640.11", "ppl": "1.65", "accuracy": "89.968", "wps": "298.7", "ups": "0.42", "wpb": "711.5", "bsz": "56.6", "num_updates": "12800", "lr": "0.00065744", "gnorm": "11.324", "loss_scale": "64", "train_wall": "464", "gb_free": "7.2", "wall": "35364"}
[2025-01-30 10:07:58,592][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 10:09:41,351][valid][INFO] - {"epoch": 16, "valid_loss": "34.045", "valid_nll_loss": "1.458", "valid_total": "678.4", "valid_n_correct": "541.3", "valid_ppl": "2.75", "valid_accuracy": "79.791", "valid_wps": "288.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "12861", "valid_best_accuracy": "79.791"}
[2025-01-30 10:09:41,358][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 12861 updates
[2025-01-30 10:09:41,361][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 10:09:55,630][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 10:10:02,768][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 16 @ 12861 updates, score 79.791) (writing took 21.409227228723466 seconds)
[2025-01-30 10:10:02,772][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2025-01-30 10:10:02,788][train][INFO] - {"epoch": 16, "train_loss": "25.33", "train_nll_loss": "0.704", "train_total": "711.575", "train_n_correct": "643.16", "train_ppl": "1.63", "train_accuracy": "90.386", "train_wps": "254.9", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "12861", "train_lr": "0.00065146", "train_gnorm": "11.22", "train_loss_scale": "64", "train_train_wall": "1996", "train_gb_free": "6", "train_wall": "35606"}
[2025-01-30 10:10:04,910][fairseq.trainer][INFO] - begin training epoch 17
[2025-01-30 10:10:04,914][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 10:17:45,653][train_inner][INFO] - {"epoch": 17, "update": 16.173, "loss": "24.824", "nll_loss": "0.626", "total": "704.915", "n_correct": "646.525", "ppl": "1.54", "accuracy": "91.717", "wps": "200", "ups": "0.28", "wpb": "704.9", "bsz": "55.7", "num_updates": "13000", "lr": "0.000638036", "gnorm": "10.489", "loss_scale": "64", "train_wall": "472", "gb_free": "7.2", "wall": "36069"}
[2025-01-30 10:26:35,507][train_inner][INFO] - {"epoch": 17, "update": 16.422, "loss": "23.789", "nll_loss": "0.575", "total": "715.325", "n_correct": "662.11", "ppl": "1.49", "accuracy": "92.561", "wps": "270", "ups": "0.38", "wpb": "715.3", "bsz": "57.6", "num_updates": "13200", "lr": "0.000619206", "gnorm": "9.348", "loss_scale": "64", "train_wall": "516", "gb_free": "6.2", "wall": "36599"}
[2025-01-30 10:35:18,878][train_inner][INFO] - {"epoch": 17, "update": 16.67, "loss": "24.218", "nll_loss": "0.603", "total": "707.19", "n_correct": "651.655", "ppl": "1.52", "accuracy": "92.147", "wps": "270.3", "ups": "0.38", "wpb": "707.2", "bsz": "56.6", "num_updates": "13400", "lr": "0.000600931", "gnorm": "10.36", "loss_scale": "64", "train_wall": "509", "gb_free": "7.2", "wall": "37122"}
[2025-01-30 10:43:50,968][train_inner][INFO] - {"epoch": 17, "update": 16.919, "loss": "24.506", "nll_loss": "0.624", "total": "721.405", "n_correct": "662.03", "ppl": "1.54", "accuracy": "91.77", "wps": "281.8", "ups": "0.39", "wpb": "721.4", "bsz": "57.5", "num_updates": "13600", "lr": "0.000583196", "gnorm": "10.27", "loss_scale": "64", "train_wall": "498", "gb_free": "7.2", "wall": "37634"}
[2025-01-30 10:46:03,482][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2025-01-30 10:46:03,489][train][INFO] - {"epoch": 17, "train_loss": "24.112", "train_nll_loss": "0.596", "train_total": "711.575", "train_n_correct": "656.356", "train_ppl": "1.51", "train_accuracy": "92.24", "train_wps": "264.8", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "13665", "train_lr": "0.000577546", "train_gnorm": "9.931", "train_loss_scale": "64", "train_train_wall": "2010", "train_gb_free": "6.1", "train_wall": "37767"}
[2025-01-30 10:46:07,272][fairseq.trainer][INFO] - begin training epoch 18
[2025-01-30 10:46:07,273][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 10:53:42,107][train_inner][INFO] - {"epoch": 18, "update": 17.168, "loss": "23.224", "nll_loss": "0.543", "total": "711.735", "n_correct": "663.26", "ppl": "1.46", "accuracy": "93.189", "wps": "240.8", "ups": "0.34", "wpb": "711.7", "bsz": "57.7", "num_updates": "13800", "lr": "0.000565984", "gnorm": "9.33", "loss_scale": "64", "train_wall": "517", "gb_free": "6.9", "wall": "38226"}
[2025-01-30 11:02:14,921][train_inner][INFO] - {"epoch": 18, "update": 17.417, "loss": "23.965", "nll_loss": "0.51", "total": "708.665", "n_correct": "664.145", "ppl": "1.42", "accuracy": "93.718", "wps": "276.4", "ups": "0.39", "wpb": "708.7", "bsz": "54.9", "num_updates": "14000", "lr": "0.00054928", "gnorm": "9.258", "loss_scale": "64", "train_wall": "500", "gb_free": "6.8", "wall": "38738"}
[2025-01-30 11:10:19,930][train_inner][INFO] - {"epoch": 18, "update": 17.665, "loss": "22.993", "nll_loss": "0.518", "total": "710.18", "n_correct": "664.775", "ppl": "1.43", "accuracy": "93.607", "wps": "292.9", "ups": "0.41", "wpb": "710.2", "bsz": "57.5", "num_updates": "14200", "lr": "0.000533069", "gnorm": "9.017", "loss_scale": "64", "train_wall": "473", "gb_free": "7.1", "wall": "39223"}
[2025-01-30 11:19:13,269][train_inner][INFO] - {"epoch": 18, "update": 17.914, "loss": "22.877", "nll_loss": "0.516", "total": "712.57", "n_correct": "667.49", "ppl": "1.43", "accuracy": "93.674", "wps": "267.2", "ups": "0.38", "wpb": "712.6", "bsz": "57.8", "num_updates": "14400", "lr": "0.000517337", "gnorm": "8.912", "loss_scale": "64", "train_wall": "519", "gb_free": "6.5", "wall": "39757"}
[2025-01-30 11:21:36,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 11:23:18,854][valid][INFO] - {"epoch": 18, "valid_loss": "33.922", "valid_nll_loss": "1.452", "valid_total": "678.4", "valid_n_correct": "546.6", "valid_ppl": "2.74", "valid_accuracy": "80.572", "valid_wps": "293.3", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "14469", "valid_best_accuracy": "80.572"}
[2025-01-30 11:23:18,860][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 14469 updates
[2025-01-30 11:23:18,862][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 11:23:35,473][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 11:23:44,596][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 18 @ 14469 updates, score 80.572) (writing took 25.735387774184346 seconds)
[2025-01-30 11:23:44,597][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2025-01-30 11:23:44,614][train][INFO] - {"epoch": 18, "train_loss": "23.208", "train_nll_loss": "0.517", "train_total": "711.575", "train_n_correct": "666.225", "train_ppl": "1.43", "train_accuracy": "93.627", "train_wps": "253", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "14469", "train_lr": "0.000512018", "train_gnorm": "9.087", "train_loss_scale": "128", "train_train_wall": "2020", "train_gb_free": "6", "train_wall": "40028"}
[2025-01-30 11:23:46,988][fairseq.trainer][INFO] - begin training epoch 19
[2025-01-30 11:23:47,000][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 11:31:03,940][train_inner][INFO] - {"epoch": 19, "update": 18.163, "loss": "22.909", "nll_loss": "0.454", "total": "712.585", "n_correct": "674.78", "ppl": "1.37", "accuracy": "94.695", "wps": "200.5", "ups": "0.28", "wpb": "712.6", "bsz": "56.1", "num_updates": "14600", "lr": "0.000502069", "gnorm": "8.333", "loss_scale": "128", "train_wall": "475", "gb_free": "6.1", "wall": "40467"}
[2025-01-30 11:40:00,291][train_inner][INFO] - {"epoch": 19, "update": 18.412, "loss": "22.481", "nll_loss": "0.468", "total": "713.015", "n_correct": "674.29", "ppl": "1.38", "accuracy": "94.569", "wps": "265.9", "ups": "0.37", "wpb": "713", "bsz": "57.5", "num_updates": "14800", "lr": "0.000487251", "gnorm": "8.321", "loss_scale": "128", "train_wall": "523", "gb_free": "6.4", "wall": "41004"}
[2025-01-30 11:48:46,990][train_inner][INFO] - {"epoch": 19, "update": 18.66, "loss": "21.598", "nll_loss": "0.425", "total": "713.405", "n_correct": "679.82", "ppl": "1.34", "accuracy": "95.292", "wps": "270.9", "ups": "0.38", "wpb": "713.4", "bsz": "58.6", "num_updates": "15000", "lr": "0.000472871", "gnorm": "7.562", "loss_scale": "128", "train_wall": "514", "gb_free": "6.3", "wall": "41530"}
[2025-01-30 11:57:37,727][train_inner][INFO] - {"epoch": 19, "update": 18.909, "loss": "22.624", "nll_loss": "0.451", "total": "714.395", "n_correct": "677.335", "ppl": "1.37", "accuracy": "94.812", "wps": "269.2", "ups": "0.38", "wpb": "714.4", "bsz": "56.7", "num_updates": "15200", "lr": "0.000458915", "gnorm": "8.41", "loss_scale": "128", "train_wall": "520", "gb_free": "7", "wall": "42061"}
[2025-01-30 12:00:08,960][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2025-01-30 12:00:08,969][train][INFO] - {"epoch": 19, "train_loss": "22.378", "train_nll_loss": "0.446", "train_total": "711.575", "train_n_correct": "675.43", "train_ppl": "1.36", "train_accuracy": "94.921", "train_wps": "261.9", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "15273", "train_lr": "0.000453924", "train_gnorm": "8.18", "train_loss_scale": "128", "train_train_wall": "2039", "train_gb_free": "6.7", "train_wall": "42212"}
[2025-01-30 12:00:12,469][fairseq.trainer][INFO] - begin training epoch 20
[2025-01-30 12:00:12,470][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 12:07:38,863][train_inner][INFO] - {"epoch": 20, "update": 19.158, "loss": "22.005", "nll_loss": "0.413", "total": "702.165", "n_correct": "670.925", "ppl": "1.33", "accuracy": "95.551", "wps": "233.6", "ups": "0.33", "wpb": "702.2", "bsz": "56.3", "num_updates": "15400", "lr": "0.000445371", "gnorm": "8.114", "loss_scale": "128", "train_wall": "530", "gb_free": "6.8", "wall": "42662"}
[2025-01-30 12:16:27,179][train_inner][INFO] - {"epoch": 20, "update": 19.407, "loss": "20.847", "nll_loss": "0.373", "total": "713.78", "n_correct": "687.005", "ppl": "1.3", "accuracy": "96.249", "wps": "270.2", "ups": "0.38", "wpb": "713.8", "bsz": "59.1", "num_updates": "15600", "lr": "0.000432227", "gnorm": "6.851", "loss_scale": "128", "train_wall": "515", "gb_free": "6.8", "wall": "43191"}
[2025-01-30 12:24:59,505][train_inner][INFO] - {"epoch": 20, "update": 19.655, "loss": "21.381", "nll_loss": "0.37", "total": "706.74", "n_correct": "680.305", "ppl": "1.29", "accuracy": "96.26", "wps": "275.9", "ups": "0.39", "wpb": "706.7", "bsz": "56.9", "num_updates": "15800", "lr": "0.00041947", "gnorm": "6.922", "loss_scale": "128", "train_wall": "498", "gb_free": "5.8", "wall": "43703"}
[2025-01-30 12:33:51,432][train_inner][INFO] - {"epoch": 20, "update": 19.904, "loss": "22.734", "nll_loss": "0.413", "total": "716.495", "n_correct": "684.31", "ppl": "1.33", "accuracy": "95.508", "wps": "269.4", "ups": "0.38", "wpb": "716.5", "bsz": "55.5", "num_updates": "16000", "lr": "0.000407091", "gnorm": "8.363", "loss_scale": "128", "train_wall": "517", "gb_free": "6.2", "wall": "44235"}
[2025-01-30 12:36:34,085][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 12:38:14,328][valid][INFO] - {"epoch": 20, "valid_loss": "34.287", "valid_nll_loss": "1.47", "valid_total": "678.4", "valid_n_correct": "551.4", "valid_ppl": "2.77", "valid_accuracy": "81.279", "valid_wps": "330.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "16077", "valid_best_accuracy": "81.279"}
[2025-01-30 12:38:14,332][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 16077 updates
[2025-01-30 12:38:14,333][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 12:38:29,359][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 12:38:35,298][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 20 @ 16077 updates, score 81.279) (writing took 20.96594849973917 seconds)
[2025-01-30 12:38:35,300][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2025-01-30 12:38:35,315][train][INFO] - {"epoch": 20, "train_loss": "21.675", "train_nll_loss": "0.386", "train_total": "711.575", "train_n_correct": "683.117", "train_ppl": "1.31", "train_accuracy": "96.001", "train_wps": "248.1", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "16077", "train_lr": "0.000402422", "train_gnorm": "7.495", "train_loss_scale": "128", "train_train_wall": "2070", "train_gb_free": "6.8", "train_wall": "44519"}
[2025-01-30 12:38:37,640][fairseq.trainer][INFO] - begin training epoch 21
[2025-01-30 12:38:37,641][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 12:45:34,449][train_inner][INFO] - {"epoch": 21, "update": 20.153, "loss": "21.563", "nll_loss": "0.345", "total": "702.945", "n_correct": "680.265", "ppl": "1.27", "accuracy": "96.774", "wps": "200", "ups": "0.28", "wpb": "702.9", "bsz": "55.4", "num_updates": "16200", "lr": "0.000395076", "gnorm": "6.928", "loss_scale": "128", "train_wall": "474", "gb_free": "6.9", "wall": "44938"}
[2025-01-30 12:54:11,816][train_inner][INFO] - {"epoch": 21, "update": 20.402, "loss": "21.032", "nll_loss": "0.34", "total": "709.44", "n_correct": "687.55", "ppl": "1.27", "accuracy": "96.914", "wps": "274.3", "ups": "0.39", "wpb": "709.4", "bsz": "57.1", "num_updates": "16400", "lr": "0.000383416", "gnorm": "6.561", "loss_scale": "128", "train_wall": "503", "gb_free": "6.5", "wall": "45455"}
[2025-01-30 13:03:02,751][train_inner][INFO] - {"epoch": 21, "update": 20.65, "loss": "21.448", "nll_loss": "0.33", "total": "714.08", "n_correct": "692.75", "ppl": "1.26", "accuracy": "97.013", "wps": "269", "ups": "0.38", "wpb": "714.1", "bsz": "56", "num_updates": "16600", "lr": "0.0003721", "gnorm": "6.473", "loss_scale": "128", "train_wall": "518", "gb_free": "7.1", "wall": "45986"}
[2025-01-30 13:12:15,110][train_inner][INFO] - {"epoch": 21, "update": 20.899, "loss": "20.695", "nll_loss": "0.34", "total": "720.405", "n_correct": "697.93", "ppl": "1.27", "accuracy": "96.88", "wps": "260.8", "ups": "0.36", "wpb": "720.4", "bsz": "58.9", "num_updates": "16800", "lr": "0.000361119", "gnorm": "6.152", "loss_scale": "128", "train_wall": "538", "gb_free": "7", "wall": "46539"}
[2025-01-30 13:15:13,828][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2025-01-30 13:15:13,835][train][INFO] - {"epoch": 21, "train_loss": "21.043", "train_nll_loss": "0.333", "train_total": "711.575", "train_n_correct": "690.257", "train_ppl": "1.26", "train_accuracy": "97.004", "train_wps": "260.2", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "16881", "train_lr": "0.000356764", "train_gnorm": "6.323", "train_loss_scale": "128", "train_train_wall": "2049", "train_gb_free": "6.4", "train_wall": "46717"}
[2025-01-30 13:15:17,523][fairseq.trainer][INFO] - begin training epoch 22
[2025-01-30 13:15:17,525][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 13:22:16,123][train_inner][INFO] - {"epoch": 22, "update": 21.148, "loss": "20.357", "nll_loss": "0.314", "total": "715.035", "n_correct": "696.08", "ppl": "1.24", "accuracy": "97.349", "wps": "238", "ups": "0.33", "wpb": "715", "bsz": "58.5", "num_updates": "17000", "lr": "0.000350461", "gnorm": "5.729", "loss_scale": "128", "train_wall": "528", "gb_free": "6.1", "wall": "47140"}
[2025-01-30 13:30:19,619][train_inner][INFO] - {"epoch": 22, "update": 21.397, "loss": "20.745", "nll_loss": "0.311", "total": "718.125", "n_correct": "699.99", "ppl": "1.24", "accuracy": "97.475", "wps": "297.1", "ups": "0.41", "wpb": "718.1", "bsz": "57.6", "num_updates": "17200", "lr": "0.000340118", "gnorm": "6.091", "loss_scale": "128", "train_wall": "470", "gb_free": "6.1", "wall": "47623"}
[2025-01-30 13:38:59,339][train_inner][INFO] - {"epoch": 22, "update": 21.646, "loss": "20.663", "nll_loss": "0.309", "total": "704.685", "n_correct": "687.17", "ppl": "1.24", "accuracy": "97.514", "wps": "271.2", "ups": "0.38", "wpb": "704.7", "bsz": "56.6", "num_updates": "17400", "lr": "0.00033008", "gnorm": "5.935", "loss_scale": "128", "train_wall": "507", "gb_free": "6", "wall": "48143"}
[2025-01-30 13:47:38,628][train_inner][INFO] - {"epoch": 22, "update": 21.894, "loss": "21.217", "nll_loss": "0.315", "total": "710.66", "n_correct": "691.87", "ppl": "1.24", "accuracy": "97.356", "wps": "273.7", "ups": "0.39", "wpb": "710.7", "bsz": "55.9", "num_updates": "17600", "lr": "0.000320338", "gnorm": "6.379", "loss_scale": "128", "train_wall": "506", "gb_free": "6.6", "wall": "48662"}
[2025-01-30 13:50:36,910][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 13:52:16,233][valid][INFO] - {"epoch": 22, "valid_loss": "33.913", "valid_nll_loss": "1.467", "valid_total": "678.4", "valid_n_correct": "556.3", "valid_ppl": "2.76", "valid_accuracy": "82.002", "valid_wps": "396.8", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "17685", "valid_best_accuracy": "82.002"}
[2025-01-30 13:52:16,237][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 17685 updates
[2025-01-30 13:52:16,239][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 13:52:30,969][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 13:52:36,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 22 @ 17685 updates, score 82.002) (writing took 20.22216509655118 seconds)
[2025-01-30 13:52:36,461][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2025-01-30 13:52:36,472][train][INFO] - {"epoch": 22, "train_loss": "20.766", "train_nll_loss": "0.311", "train_total": "711.575", "train_n_correct": "693.419", "train_ppl": "1.24", "train_accuracy": "97.449", "train_wps": "255.1", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "17685", "train_lr": "0.000316285", "train_gnorm": "6.042", "train_loss_scale": "128", "train_train_wall": "2011", "train_gb_free": "5.9", "train_wall": "48960"}
[2025-01-30 13:52:38,584][fairseq.trainer][INFO] - begin training epoch 23
[2025-01-30 13:52:38,585][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 13:59:16,662][train_inner][INFO] - {"epoch": 23, "update": 22.143, "loss": "20.487", "nll_loss": "0.296", "total": "705.17", "n_correct": "689.48", "ppl": "1.23", "accuracy": "97.775", "wps": "202", "ups": "0.29", "wpb": "705.2", "bsz": "56.7", "num_updates": "17800", "lr": "0.000310884", "gnorm": "5.656", "loss_scale": "128", "train_wall": "471", "gb_free": "6.4", "wall": "49360"}
[2025-01-30 14:07:36,749][train_inner][INFO] - {"epoch": 23, "update": 22.392, "loss": "20.373", "nll_loss": "0.274", "total": "710.82", "n_correct": "697.41", "ppl": "1.21", "accuracy": "98.113", "wps": "284.3", "ups": "0.4", "wpb": "710.8", "bsz": "56.8", "num_updates": "18000", "lr": "0.000301709", "gnorm": "5.053", "loss_scale": "128", "train_wall": "486", "gb_free": "6.1", "wall": "49860"}
[2025-01-30 14:16:19,831][train_inner][INFO] - {"epoch": 23, "update": 22.641, "loss": "20.352", "nll_loss": "0.288", "total": "720.165", "n_correct": "704.71", "ppl": "1.22", "accuracy": "97.854", "wps": "275.4", "ups": "0.38", "wpb": "720.2", "bsz": "58", "num_updates": "18200", "lr": "0.000292804", "gnorm": "5.625", "loss_scale": "128", "train_wall": "510", "gb_free": "6.8", "wall": "50383"}
[2025-01-30 14:25:02,427][train_inner][INFO] - {"epoch": 23, "update": 22.889, "loss": "20.566", "nll_loss": "0.288", "total": "711.635", "n_correct": "696.25", "ppl": "1.22", "accuracy": "97.838", "wps": "272.4", "ups": "0.38", "wpb": "711.6", "bsz": "56.7", "num_updates": "18400", "lr": "0.000284163", "gnorm": "5.329", "loss_scale": "128", "train_wall": "509", "gb_free": "6.7", "wall": "50906"}
[2025-01-30 14:28:12,331][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2025-01-30 14:28:12,337][train][INFO] - {"epoch": 23, "train_loss": "20.399", "train_nll_loss": "0.282", "train_total": "711.575", "train_n_correct": "697.083", "train_ppl": "1.22", "train_accuracy": "97.963", "train_wps": "267.9", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "18489", "train_lr": "0.0002804", "train_gnorm": "5.33", "train_loss_scale": "128", "train_train_wall": "1986", "train_gb_free": "6.2", "train_wall": "51096"}
[2025-01-30 14:28:16,114][fairseq.trainer][INFO] - begin training epoch 24
[2025-01-30 14:28:16,129][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 14:34:44,942][train_inner][INFO] - {"epoch": 24, "update": 23.138, "loss": "20.147", "nll_loss": "0.265", "total": "707.095", "n_correct": "695.045", "ppl": "1.2", "accuracy": "98.296", "wps": "242.8", "ups": "0.34", "wpb": "707.1", "bsz": "56.7", "num_updates": "18600", "lr": "0.000275776", "gnorm": "4.857", "loss_scale": "256", "train_wall": "499", "gb_free": "7.1", "wall": "51488"}
[2025-01-30 14:37:26,941][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2025-01-30 14:42:33,571][train_inner][INFO] - {"epoch": 24, "update": 23.388, "loss": "20.129", "nll_loss": "0.275", "total": "716.46", "n_correct": "702.695", "ppl": "1.21", "accuracy": "98.079", "wps": "305.8", "ups": "0.43", "wpb": "716.5", "bsz": "57.9", "num_updates": "18800", "lr": "0.000267637", "gnorm": "5.386", "loss_scale": "128", "train_wall": "457", "gb_free": "6.9", "wall": "51957"}
[2025-01-30 14:50:06,142][train_inner][INFO] - {"epoch": 24, "update": 23.637, "loss": "20.559", "nll_loss": "0.27", "total": "705.555", "n_correct": "692.965", "ppl": "1.21", "accuracy": "98.216", "wps": "311.8", "ups": "0.44", "wpb": "705.6", "bsz": "55.6", "num_updates": "19000", "lr": "0.000259739", "gnorm": "5.224", "loss_scale": "128", "train_wall": "441", "gb_free": "7.2", "wall": "52410"}
[2025-01-30 14:58:51,446][train_inner][INFO] - {"epoch": 24, "update": 23.886, "loss": "20.092", "nll_loss": "0.258", "total": "714.885", "n_correct": "703.54", "ppl": "1.2", "accuracy": "98.413", "wps": "272.2", "ups": "0.38", "wpb": "714.9", "bsz": "57.2", "num_updates": "19200", "lr": "0.000252073", "gnorm": "5.16", "loss_scale": "128", "train_wall": "513", "gb_free": "6.2", "wall": "52935"}
[2025-01-30 15:02:10,973][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 15:03:52,455][valid][INFO] - {"epoch": 24, "valid_loss": "33.52", "valid_nll_loss": "1.449", "valid_total": "678.4", "valid_n_correct": "557.35", "valid_ppl": "2.73", "valid_accuracy": "82.157", "valid_wps": "330", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "19292", "valid_best_accuracy": "82.157"}
[2025-01-30 15:03:52,461][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 19292 updates
[2025-01-30 15:03:52,463][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 15:04:07,457][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 15:04:12,794][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 24 @ 19292 updates, score 82.157) (writing took 20.333107402548194 seconds)
[2025-01-30 15:04:12,796][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2025-01-30 15:04:12,807][train][INFO] - {"epoch": 24, "train_loss": "20.16", "train_nll_loss": "0.265", "train_total": "711.547", "train_n_correct": "699.366", "train_ppl": "1.2", "train_accuracy": "98.288", "train_wps": "264.5", "train_ups": "0.37", "train_wpb": "711.5", "train_bsz": "57", "train_num_updates": "19292", "train_lr": "0.000248623", "train_gnorm": "5.111", "train_loss_scale": "128", "train_train_wall": "1919", "train_gb_free": "6.2", "train_wall": "53256"}
[2025-01-30 15:04:15,220][fairseq.trainer][INFO] - begin training epoch 25
[2025-01-30 15:04:15,221][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 15:10:41,059][train_inner][INFO] - {"epoch": 25, "update": 24.134, "loss": "19.967", "nll_loss": "0.262", "total": "713.365", "n_correct": "701.775", "ppl": "1.2", "accuracy": "98.375", "wps": "201.1", "ups": "0.28", "wpb": "713.4", "bsz": "57.6", "num_updates": "19400", "lr": "0.000244633", "gnorm": "4.735", "loss_scale": "128", "train_wall": "478", "gb_free": "7", "wall": "53644"}
[2025-01-30 15:19:11,849][train_inner][INFO] - {"epoch": 25, "update": 24.383, "loss": "19.611", "nll_loss": "0.257", "total": "717.86", "n_correct": "706.805", "ppl": "1.19", "accuracy": "98.46", "wps": "281.1", "ups": "0.39", "wpb": "717.9", "bsz": "58.8", "num_updates": "19600", "lr": "0.000237414", "gnorm": "4.674", "loss_scale": "128", "train_wall": "496", "gb_free": "6.7", "wall": "54155"}
[2025-01-30 15:27:48,436][train_inner][INFO] - {"epoch": 25, "update": 24.632, "loss": "20.068", "nll_loss": "0.253", "total": "706.13", "n_correct": "695.7", "ppl": "1.19", "accuracy": "98.523", "wps": "273.4", "ups": "0.39", "wpb": "706.1", "bsz": "56.4", "num_updates": "19800", "lr": "0.000230407", "gnorm": "4.766", "loss_scale": "128", "train_wall": "503", "gb_free": "5.8", "wall": "54672"}
[2025-01-30 15:36:38,104][train_inner][INFO] - {"epoch": 25, "update": 24.881, "loss": "20.348", "nll_loss": "0.243", "total": "706.885", "n_correct": "697.755", "ppl": "1.18", "accuracy": "98.708", "wps": "266.9", "ups": "0.38", "wpb": "706.9", "bsz": "55.3", "num_updates": "20000", "lr": "0.000223607", "gnorm": "4.545", "loss_scale": "128", "train_wall": "518", "gb_free": "7.2", "wall": "55202"}
[2025-01-30 15:40:10,671][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2025-01-30 15:40:10,685][train][INFO] - {"epoch": 25, "train_loss": "19.961", "train_nll_loss": "0.25", "train_total": "711.575", "train_n_correct": "701.474", "train_ppl": "1.19", "train_accuracy": "98.581", "train_wps": "265.1", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "20096", "train_lr": "0.000220414", "train_gnorm": "4.61", "train_loss_scale": "128", "train_train_wall": "2007", "train_gb_free": "6.1", "train_wall": "55414"}
[2025-01-30 15:40:14,188][fairseq.trainer][INFO] - begin training epoch 26
[2025-01-30 15:40:14,206][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 15:46:17,987][train_inner][INFO] - {"epoch": 26, "update": 25.129, "loss": "19.433", "nll_loss": "0.227", "total": "715.31", "n_correct": "708.125", "ppl": "1.17", "accuracy": "98.996", "wps": "246.7", "ups": "0.34", "wpb": "715.3", "bsz": "58.1", "num_updates": "20200", "lr": "0.000217007", "gnorm": "3.853", "loss_scale": "128", "train_wall": "501", "gb_free": "6.1", "wall": "55781"}
[2025-01-30 15:54:21,137][train_inner][INFO] - {"epoch": 26, "update": 25.378, "loss": "20.366", "nll_loss": "0.237", "total": "709.56", "n_correct": "701.115", "ppl": "1.18", "accuracy": "98.81", "wps": "293.7", "ups": "0.41", "wpb": "709.6", "bsz": "55.3", "num_updates": "20400", "lr": "0.000210603", "gnorm": "4.39", "loss_scale": "128", "train_wall": "471", "gb_free": "6.6", "wall": "56265"}
[2025-01-30 16:02:55,205][train_inner][INFO] - {"epoch": 26, "update": 25.627, "loss": "19.997", "nll_loss": "0.247", "total": "712.255", "n_correct": "702.68", "ppl": "1.19", "accuracy": "98.656", "wps": "277.1", "ups": "0.39", "wpb": "712.3", "bsz": "56.8", "num_updates": "20600", "lr": "0.000204387", "gnorm": "4.584", "loss_scale": "128", "train_wall": "500", "gb_free": "7", "wall": "56779"}
[2025-01-30 16:11:44,087][train_inner][INFO] - {"epoch": 26, "update": 25.876, "loss": "19.435", "nll_loss": "0.232", "total": "713.94", "n_correct": "706", "ppl": "1.17", "accuracy": "98.888", "wps": "270", "ups": "0.38", "wpb": "713.9", "bsz": "58", "num_updates": "20800", "lr": "0.000198355", "gnorm": "3.815", "loss_scale": "128", "train_wall": "516", "gb_free": "6.2", "wall": "57307"}
[2025-01-30 16:15:24,932][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 16:17:06,407][valid][INFO] - {"epoch": 26, "valid_loss": "33.054", "valid_nll_loss": "1.41", "valid_total": "678.4", "valid_n_correct": "561.15", "valid_ppl": "2.66", "valid_accuracy": "82.717", "valid_wps": "273.6", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "20900", "valid_best_accuracy": "82.717"}
[2025-01-30 16:17:06,415][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 20900 updates
[2025-01-30 16:17:06,418][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 16:17:21,304][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 16:17:26,467][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 26 @ 20900 updates, score 82.717) (writing took 20.051642700098455 seconds)
[2025-01-30 16:17:26,468][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2025-01-30 16:17:26,477][train][INFO] - {"epoch": 26, "train_loss": "19.781", "train_nll_loss": "0.237", "train_total": "711.575", "train_n_correct": "703.15", "train_ppl": "1.18", "train_accuracy": "98.816", "train_wps": "255.9", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "20900", "train_lr": "0.000195406", "train_gnorm": "4.152", "train_loss_scale": "128", "train_train_wall": "1997", "train_gb_free": "7.8", "train_wall": "57650"}
[2025-01-30 16:17:28,797][fairseq.trainer][INFO] - begin training epoch 27
[2025-01-30 16:17:28,798][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 16:23:30,186][train_inner][INFO] - {"epoch": 27, "update": 26.124, "loss": "19.56", "nll_loss": "0.23", "total": "708.89", "n_correct": "701.2", "ppl": "1.17", "accuracy": "98.915", "wps": "200.8", "ups": "0.28", "wpb": "708.9", "bsz": "57.2", "num_updates": "21000", "lr": "0.000192501", "gnorm": "3.937", "loss_scale": "128", "train_wall": "476", "gb_free": "6.2", "wall": "58014"}
[2025-01-30 16:31:41,591][train_inner][INFO] - {"epoch": 27, "update": 26.373, "loss": "19.751", "nll_loss": "0.219", "total": "707.62", "n_correct": "701.54", "ppl": "1.16", "accuracy": "99.141", "wps": "288", "ups": "0.41", "wpb": "707.6", "bsz": "56.2", "num_updates": "21200", "lr": "0.00018682", "gnorm": "3.794", "loss_scale": "128", "train_wall": "480", "gb_free": "6.9", "wall": "58505"}
[2025-01-30 16:40:26,616][train_inner][INFO] - {"epoch": 27, "update": 26.622, "loss": "19.346", "nll_loss": "0.23", "total": "717.345", "n_correct": "709.91", "ppl": "1.17", "accuracy": "98.964", "wps": "273.3", "ups": "0.38", "wpb": "717.3", "bsz": "58.4", "num_updates": "21400", "lr": "0.000181306", "gnorm": "3.74", "loss_scale": "128", "train_wall": "510", "gb_free": "6.3", "wall": "59030"}
[2025-01-30 16:49:17,523][train_inner][INFO] - {"epoch": 27, "update": 26.871, "loss": "19.599", "nll_loss": "0.236", "total": "715.22", "n_correct": "706.755", "ppl": "1.18", "accuracy": "98.816", "wps": "269.4", "ups": "0.38", "wpb": "715.2", "bsz": "57.7", "num_updates": "21600", "lr": "0.000175955", "gnorm": "4.213", "loss_scale": "128", "train_wall": "517", "gb_free": "6.4", "wall": "59561"}
[2025-01-30 16:52:59,211][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2025-01-30 16:52:59,220][train][INFO] - {"epoch": 27, "train_loss": "19.638", "train_nll_loss": "0.227", "train_total": "711.575", "train_n_correct": "704.44", "train_ppl": "1.17", "train_accuracy": "98.997", "train_wps": "268.2", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "21704", "train_lr": "0.000173236", "train_gnorm": "3.95", "train_loss_scale": "128", "train_train_wall": "1984", "train_gb_free": "6.4", "train_wall": "59783"}
[2025-01-30 16:53:02,777][fairseq.trainer][INFO] - begin training epoch 28
[2025-01-30 16:53:02,794][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 16:59:02,730][train_inner][INFO] - {"epoch": 28, "update": 27.119, "loss": "19.363", "nll_loss": "0.216", "total": "708.715", "n_correct": "702.99", "ppl": "1.16", "accuracy": "99.192", "wps": "242.2", "ups": "0.34", "wpb": "708.7", "bsz": "57.2", "num_updates": "21800", "lr": "0.000170762", "gnorm": "3.676", "loss_scale": "128", "train_wall": "519", "gb_free": "6.6", "wall": "60146"}
[2025-01-30 17:06:54,113][train_inner][INFO] - {"epoch": 28, "update": 27.368, "loss": "19.883", "nll_loss": "0.207", "total": "705.75", "n_correct": "700.875", "ppl": "1.15", "accuracy": "99.309", "wps": "299.4", "ups": "0.42", "wpb": "705.8", "bsz": "55.1", "num_updates": "22000", "lr": "0.000165723", "gnorm": "3.336", "loss_scale": "128", "train_wall": "459", "gb_free": "6.5", "wall": "60618"}
[2025-01-30 17:15:41,189][train_inner][INFO] - {"epoch": 28, "update": 27.617, "loss": "19.348", "nll_loss": "0.219", "total": "711.115", "n_correct": "705.11", "ppl": "1.16", "accuracy": "99.156", "wps": "269.9", "ups": "0.38", "wpb": "711.1", "bsz": "57.5", "num_updates": "22200", "lr": "0.000160832", "gnorm": "3.548", "loss_scale": "128", "train_wall": "512", "gb_free": "5.8", "wall": "61145"}
[2025-01-30 17:24:43,364][train_inner][INFO] - {"epoch": 28, "update": 27.866, "loss": "19.385", "nll_loss": "0.216", "total": "721.325", "n_correct": "715.545", "ppl": "1.16", "accuracy": "99.199", "wps": "266.1", "ups": "0.37", "wpb": "721.3", "bsz": "58.1", "num_updates": "22400", "lr": "0.000156085", "gnorm": "3.517", "loss_scale": "128", "train_wall": "529", "gb_free": "6", "wall": "61687"}
[2025-01-30 17:28:45,060][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 17:30:25,205][valid][INFO] - {"epoch": 28, "valid_loss": "32.883", "valid_nll_loss": "1.406", "valid_total": "678.4", "valid_n_correct": "563.05", "valid_ppl": "2.65", "valid_accuracy": "82.997", "valid_wps": "258.5", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "22508", "valid_best_accuracy": "82.997"}
[2025-01-30 17:30:25,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 22508 updates
[2025-01-30 17:30:25,215][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 17:30:41,395][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 17:30:46,807][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 28 @ 22508 updates, score 82.997) (writing took 21.593693195842206 seconds)
[2025-01-30 17:30:46,808][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2025-01-30 17:30:46,820][train][INFO] - {"epoch": 28, "train_loss": "19.454", "train_nll_loss": "0.213", "train_total": "711.575", "train_n_correct": "706.16", "train_ppl": "1.16", "train_accuracy": "99.239", "train_wps": "252.3", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "22508", "train_lr": "0.00015358", "train_gnorm": "3.402", "train_loss_scale": "128", "train_train_wall": "2038", "train_gb_free": "7", "train_wall": "62050"}
[2025-01-30 17:30:48,904][fairseq.trainer][INFO] - begin training epoch 29
[2025-01-30 17:30:48,904][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 17:36:16,321][train_inner][INFO] - {"epoch": 29, "update": 28.114, "loss": "19.325", "nll_loss": "0.207", "total": "706.5", "n_correct": "701.91", "ppl": "1.15", "accuracy": "99.35", "wps": "203.9", "ups": "0.29", "wpb": "706.5", "bsz": "56.7", "num_updates": "22600", "lr": "0.000151479", "gnorm": "3.112", "loss_scale": "128", "train_wall": "464", "gb_free": "6.4", "wall": "62380"}
[2025-01-30 17:36:58,943][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2025-01-30 17:44:45,223][train_inner][INFO] - {"epoch": 29, "update": 28.364, "loss": "19.426", "nll_loss": "0.202", "total": "709.445", "n_correct": "705.295", "ppl": "1.15", "accuracy": "99.415", "wps": "278.9", "ups": "0.39", "wpb": "709.4", "bsz": "56.5", "num_updates": "22800", "lr": "0.000147008", "gnorm": "3.124", "loss_scale": "64", "train_wall": "495", "gb_free": "5.8", "wall": "62889"}
[2025-01-30 17:53:31,196][train_inner][INFO] - {"epoch": 29, "update": 28.613, "loss": "19.153", "nll_loss": "0.215", "total": "711.415", "n_correct": "705.75", "ppl": "1.16", "accuracy": "99.204", "wps": "270.5", "ups": "0.38", "wpb": "711.4", "bsz": "57.9", "num_updates": "23000", "lr": "0.000142669", "gnorm": "3.417", "loss_scale": "64", "train_wall": "512", "gb_free": "6", "wall": "63415"}
[2025-01-30 18:02:20,669][train_inner][INFO] - {"epoch": 29, "update": 28.862, "loss": "19.85", "nll_loss": "0.214", "total": "707.035", "n_correct": "701.355", "ppl": "1.16", "accuracy": "99.197", "wps": "267.2", "ups": "0.38", "wpb": "707", "bsz": "55.5", "num_updates": "23200", "lr": "0.000138459", "gnorm": "3.26", "loss_scale": "64", "train_wall": "515", "gb_free": "6", "wall": "63944"}
[2025-01-30 18:06:31,730][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2025-01-30 18:06:31,737][train][INFO] - {"epoch": 29, "train_loss": "19.369", "train_nll_loss": "0.209", "train_total": "711.472", "train_n_correct": "706.492", "train_ppl": "1.16", "train_accuracy": "99.3", "train_wps": "266.4", "train_ups": "0.37", "train_wpb": "711.5", "train_bsz": "57", "train_num_updates": "23311", "train_lr": "0.000136176", "train_gnorm": "3.208", "train_loss_scale": "64", "train_train_wall": "1997", "train_gb_free": "6", "train_wall": "64195"}
[2025-01-30 18:06:35,201][fairseq.trainer][INFO] - begin training epoch 30
[2025-01-30 18:06:35,201][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 18:11:35,913][train_inner][INFO] - {"epoch": 30, "update": 29.111, "loss": "19.219", "nll_loss": "0.205", "total": "715.805", "n_correct": "711.285", "ppl": "1.15", "accuracy": "99.369", "wps": "257.8", "ups": "0.36", "wpb": "715.8", "bsz": "57.7", "num_updates": "23400", "lr": "0.000134372", "gnorm": "3.057", "loss_scale": "64", "train_wall": "486", "gb_free": "6", "wall": "64499"}
[2025-01-30 18:20:21,679][train_inner][INFO] - {"epoch": 30, "update": 29.359, "loss": "18.992", "nll_loss": "0.204", "total": "717.96", "n_correct": "713.595", "ppl": "1.15", "accuracy": "99.392", "wps": "273.1", "ups": "0.38", "wpb": "718", "bsz": "58.5", "num_updates": "23600", "lr": "0.000130407", "gnorm": "3.193", "loss_scale": "64", "train_wall": "511", "gb_free": "6.4", "wall": "65025"}
[2025-01-30 18:29:01,244][train_inner][INFO] - {"epoch": 30, "update": 29.608, "loss": "19.847", "nll_loss": "0.202", "total": "708.79", "n_correct": "704.62", "ppl": "1.15", "accuracy": "99.412", "wps": "272.9", "ups": "0.38", "wpb": "708.8", "bsz": "55.2", "num_updates": "23800", "lr": "0.000126558", "gnorm": "3.175", "loss_scale": "64", "train_wall": "505", "gb_free": "6.9", "wall": "65545"}
[2025-01-30 18:37:49,447][train_inner][INFO] - {"epoch": 30, "update": 29.857, "loss": "19.35", "nll_loss": "0.208", "total": "711.465", "n_correct": "706.58", "ppl": "1.16", "accuracy": "99.313", "wps": "269.4", "ups": "0.38", "wpb": "711.5", "bsz": "57", "num_updates": "24000", "lr": "0.000122823", "gnorm": "3.172", "loss_scale": "64", "train_wall": "515", "gb_free": "6.5", "wall": "66073"}
[2025-01-30 18:42:12,625][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 18:43:53,353][valid][INFO] - {"epoch": 30, "valid_loss": "32.786", "valid_nll_loss": "1.407", "valid_total": "678.4", "valid_n_correct": "562.9", "valid_ppl": "2.65", "valid_accuracy": "82.975", "valid_wps": "413.2", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "24115", "valid_best_accuracy": "82.997"}
[2025-01-30 18:43:53,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 24115 updates
[2025-01-30 18:43:53,361][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 18:44:08,917][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 18:44:09,171][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 30 @ 24115 updates, score 82.975) (writing took 15.8119408916682 seconds)
[2025-01-30 18:44:09,172][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2025-01-30 18:44:09,178][train][INFO] - {"epoch": 30, "train_loss": "19.307", "train_nll_loss": "0.204", "train_total": "711.575", "train_n_correct": "707.16", "train_ppl": "1.15", "train_accuracy": "99.38", "train_wps": "253.4", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "24115", "train_lr": "0.000120725", "train_gnorm": "3.136", "train_loss_scale": "64", "train_train_wall": "2030", "train_gb_free": "6.1", "train_wall": "66453"}
[2025-01-30 18:44:11,039][fairseq.trainer][INFO] - begin training epoch 31
[2025-01-30 18:44:11,040][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 18:49:01,288][train_inner][INFO] - {"epoch": 31, "update": 30.106, "loss": "18.812", "nll_loss": "0.199", "total": "711.44", "n_correct": "707.48", "ppl": "1.15", "accuracy": "99.443", "wps": "211.8", "ups": "0.3", "wpb": "711.4", "bsz": "58.3", "num_updates": "24200", "lr": "0.000119198", "gnorm": "2.915", "loss_scale": "64", "train_wall": "478", "gb_free": "6.3", "wall": "66745"}
[2025-01-30 18:57:49,466][train_inner][INFO] - {"epoch": 31, "update": 30.354, "loss": "19.018", "nll_loss": "0.197", "total": "709.575", "n_correct": "706.165", "ppl": "1.15", "accuracy": "99.519", "wps": "268.7", "ups": "0.38", "wpb": "709.6", "bsz": "57.4", "num_updates": "24400", "lr": "0.00011568", "gnorm": "2.826", "loss_scale": "64", "train_wall": "514", "gb_free": "6.4", "wall": "67273"}
[2025-01-30 19:06:32,350][train_inner][INFO] - {"epoch": 31, "update": 30.603, "loss": "19.225", "nll_loss": "0.201", "total": "711.56", "n_correct": "707.5", "ppl": "1.15", "accuracy": "99.429", "wps": "272.2", "ups": "0.38", "wpb": "711.6", "bsz": "57.1", "num_updates": "24600", "lr": "0.000112266", "gnorm": "3.204", "loss_scale": "64", "train_wall": "510", "gb_free": "7.2", "wall": "67796"}
[2025-01-30 19:15:06,756][train_inner][INFO] - {"epoch": 31, "update": 30.852, "loss": "20", "nll_loss": "0.196", "total": "706.425", "n_correct": "702.945", "ppl": "1.15", "accuracy": "99.507", "wps": "274.7", "ups": "0.39", "wpb": "706.4", "bsz": "54.3", "num_updates": "24800", "lr": "0.000108953", "gnorm": "3.002", "loss_scale": "64", "train_wall": "502", "gb_free": "7", "wall": "68310"}
[2025-01-30 19:19:20,104][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2025-01-30 19:19:20,108][train][INFO] - {"epoch": 31, "train_loss": "19.193", "train_nll_loss": "0.196", "train_total": "711.575", "train_n_correct": "708.16", "train_ppl": "1.15", "train_accuracy": "99.52", "train_wps": "271", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "24919", "train_lr": "0.000107028", "train_gnorm": "2.891", "train_loss_scale": "64", "train_train_wall": "1994", "train_gb_free": "6.1", "train_wall": "68564"}
[2025-01-30 19:19:22,702][fairseq.trainer][INFO] - begin training epoch 32
[2025-01-30 19:19:22,703][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 19:23:49,158][train_inner][INFO] - {"epoch": 32, "update": 31.101, "loss": "18.84", "nll_loss": "0.194", "total": "715.085", "n_correct": "711.895", "ppl": "1.14", "accuracy": "99.554", "wps": "273.8", "ups": "0.38", "wpb": "715.1", "bsz": "58.3", "num_updates": "25000", "lr": "0.000105737", "gnorm": "2.663", "loss_scale": "64", "train_wall": "457", "gb_free": "6.4", "wall": "68833"}
[2025-01-30 19:32:28,642][train_inner][INFO] - {"epoch": 32, "update": 31.35, "loss": "19.244", "nll_loss": "0.199", "total": "705.97", "n_correct": "701.835", "ppl": "1.15", "accuracy": "99.414", "wps": "271.8", "ups": "0.39", "wpb": "706", "bsz": "56.5", "num_updates": "25200", "lr": "0.000102617", "gnorm": "3.142", "loss_scale": "64", "train_wall": "506", "gb_free": "6", "wall": "69352"}
[2025-01-30 19:41:12,979][train_inner][INFO] - {"epoch": 32, "update": 31.598, "loss": "19.415", "nll_loss": "0.196", "total": "715.775", "n_correct": "712.195", "ppl": "1.15", "accuracy": "99.5", "wps": "273", "ups": "0.38", "wpb": "715.8", "bsz": "56.6", "num_updates": "25400", "lr": "9.9588e-05", "gnorm": "2.821", "loss_scale": "64", "train_wall": "511", "gb_free": "6.4", "wall": "69876"}
[2025-01-30 19:50:06,033][train_inner][INFO] - {"epoch": 32, "update": 31.847, "loss": "18.842", "nll_loss": "0.199", "total": "716.065", "n_correct": "712.18", "ppl": "1.15", "accuracy": "99.457", "wps": "268.7", "ups": "0.38", "wpb": "716.1", "bsz": "58.5", "num_updates": "25600", "lr": "9.66488e-05", "gnorm": "2.61", "loss_scale": "64", "train_wall": "519", "gb_free": "6.1", "wall": "70409"}
[2025-01-30 19:54:27,381][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 19:56:06,397][valid][INFO] - {"epoch": 32, "valid_loss": "32.891", "valid_nll_loss": "1.423", "valid_total": "678.4", "valid_n_correct": "564.65", "valid_ppl": "2.68", "valid_accuracy": "83.233", "valid_wps": "333.6", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "25723", "valid_best_accuracy": "83.233"}
[2025-01-30 19:56:06,404][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 25723 updates
[2025-01-30 19:56:06,406][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 19:56:21,292][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 19:56:26,284][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 32 @ 25723 updates, score 83.233) (writing took 19.87981638778001 seconds)
[2025-01-30 19:56:26,285][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2025-01-30 19:56:26,296][train][INFO] - {"epoch": 32, "train_loss": "19.194", "train_nll_loss": "0.197", "train_total": "711.575", "train_n_correct": "707.84", "train_ppl": "1.15", "train_accuracy": "99.475", "train_wps": "257", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "25723", "train_lr": "9.48845e-05", "train_gnorm": "2.838", "train_loss_scale": "64", "train_train_wall": "1999", "train_gb_free": "6.2", "train_wall": "70790"}
[2025-01-30 19:56:28,269][fairseq.trainer][INFO] - begin training epoch 33
[2025-01-30 19:56:28,274][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 20:01:38,621][train_inner][INFO] - {"epoch": 33, "update": 32.096, "loss": "19.347", "nll_loss": "0.203", "total": "711.325", "n_correct": "707.145", "ppl": "1.15", "accuracy": "99.412", "wps": "205.4", "ups": "0.29", "wpb": "711.3", "bsz": "56.7", "num_updates": "25800", "lr": "9.37964e-05", "gnorm": "2.81", "loss_scale": "64", "train_wall": "459", "gb_free": "6.1", "wall": "71102"}
[2025-01-30 20:10:35,272][train_inner][INFO] - {"epoch": 33, "update": 32.345, "loss": "18.664", "nll_loss": "0.189", "total": "712.845", "n_correct": "710.105", "ppl": "1.14", "accuracy": "99.616", "wps": "265.7", "ups": "0.37", "wpb": "712.8", "bsz": "58.4", "num_updates": "26000", "lr": "9.10282e-05", "gnorm": "2.429", "loss_scale": "64", "train_wall": "523", "gb_free": "5.9", "wall": "71639"}
[2025-01-30 20:19:21,086][train_inner][INFO] - {"epoch": 33, "update": 32.593, "loss": "19.295", "nll_loss": "0.187", "total": "707.6", "n_correct": "705.23", "ppl": "1.14", "accuracy": "99.665", "wps": "269.2", "ups": "0.38", "wpb": "707.6", "bsz": "56", "num_updates": "26200", "lr": "8.83417e-05", "gnorm": "2.586", "loss_scale": "64", "train_wall": "512", "gb_free": "6.6", "wall": "72164"}
[2025-01-30 20:27:40,669][train_inner][INFO] - {"epoch": 33, "update": 32.842, "loss": "19.14", "nll_loss": "0.194", "total": "714.315", "n_correct": "711", "ppl": "1.14", "accuracy": "99.536", "wps": "286", "ups": "0.4", "wpb": "714.3", "bsz": "57.2", "num_updates": "26400", "lr": "8.57345e-05", "gnorm": "2.468", "loss_scale": "64", "train_wall": "485", "gb_free": "7", "wall": "72664"}
[2025-01-30 20:32:11,888][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2025-01-30 20:32:11,893][train][INFO] - {"epoch": 33, "train_loss": "19.114", "train_nll_loss": "0.192", "train_total": "711.575", "train_n_correct": "708.596", "train_ppl": "1.14", "train_accuracy": "99.581", "train_wps": "266.6", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "26527", "train_lr": "8.4119e-05", "train_gnorm": "2.532", "train_loss_scale": "64", "train_train_wall": "1988", "train_gb_free": "5.9", "train_wall": "72935"}
[2025-01-30 20:32:15,215][fairseq.trainer][INFO] - begin training epoch 34
[2025-01-30 20:32:15,216][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 20:37:09,620][train_inner][INFO] - {"epoch": 34, "update": 33.091, "loss": "19.118", "nll_loss": "0.186", "total": "710.6", "n_correct": "708.21", "ppl": "1.14", "accuracy": "99.664", "wps": "249.8", "ups": "0.35", "wpb": "710.6", "bsz": "56.7", "num_updates": "26600", "lr": "8.32042e-05", "gnorm": "2.47", "loss_scale": "64", "train_wall": "486", "gb_free": "6.1", "wall": "73233"}
[2025-01-30 20:46:01,439][train_inner][INFO] - {"epoch": 34, "update": 33.34, "loss": "19.104", "nll_loss": "0.201", "total": "707.8", "n_correct": "703.785", "ppl": "1.15", "accuracy": "99.433", "wps": "266.2", "ups": "0.38", "wpb": "707.8", "bsz": "57", "num_updates": "26800", "lr": "8.07486e-05", "gnorm": "2.707", "loss_scale": "128", "train_wall": "517", "gb_free": "7.1", "wall": "73765"}
[2025-01-30 20:54:39,296][train_inner][INFO] - {"epoch": 34, "update": 33.588, "loss": "19.435", "nll_loss": "0.189", "total": "711.1", "n_correct": "708.38", "ppl": "1.14", "accuracy": "99.617", "wps": "274.6", "ups": "0.39", "wpb": "711.1", "bsz": "55.9", "num_updates": "27000", "lr": "7.83654e-05", "gnorm": "2.483", "loss_scale": "128", "train_wall": "503", "gb_free": "5.9", "wall": "74283"}
[2025-01-30 21:03:07,026][train_inner][INFO] - {"epoch": 34, "update": 33.837, "loss": "18.832", "nll_loss": "0.19", "total": "717.135", "n_correct": "714.27", "ppl": "1.14", "accuracy": "99.6", "wps": "282.5", "ups": "0.39", "wpb": "717.1", "bsz": "58.2", "num_updates": "27200", "lr": "7.60526e-05", "gnorm": "2.457", "loss_scale": "128", "train_wall": "494", "gb_free": "5.8", "wall": "74790"}
[2025-01-30 21:08:03,217][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 21:09:46,262][valid][INFO] - {"epoch": 34, "valid_loss": "32.903", "valid_nll_loss": "1.425", "valid_total": "678.4", "valid_n_correct": "565.7", "valid_ppl": "2.69", "valid_accuracy": "83.387", "valid_wps": "430.1", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "27331", "valid_best_accuracy": "83.387"}
[2025-01-30 21:09:46,269][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 27331 updates
[2025-01-30 21:09:46,272][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 21:10:01,021][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2025-01-30 21:10:06,295][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 34 @ 27331 updates, score 83.387) (writing took 20.025890346616507 seconds)
[2025-01-30 21:10:06,296][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2025-01-30 21:10:06,306][train][INFO] - {"epoch": 34, "train_loss": "19.122", "train_nll_loss": "0.193", "train_total": "711.575", "train_n_correct": "708.377", "train_ppl": "1.14", "train_accuracy": "99.551", "train_wps": "251.5", "train_ups": "0.35", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "27331", "train_lr": "7.45749e-05", "train_gnorm": "2.575", "train_loss_scale": "128", "train_train_wall": "2026", "train_gb_free": "6", "train_wall": "75210"}
[2025-01-30 21:10:08,404][fairseq.trainer][INFO] - begin training epoch 35
[2025-01-30 21:10:08,405][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 21:14:40,608][train_inner][INFO] - {"epoch": 35, "update": 34.086, "loss": "19.396", "nll_loss": "0.195", "total": "705.075", "n_correct": "701.62", "ppl": "1.14", "accuracy": "99.51", "wps": "203.3", "ups": "0.29", "wpb": "705.1", "bsz": "55.8", "num_updates": "27400", "lr": "7.38081e-05", "gnorm": "2.875", "loss_scale": "128", "train_wall": "464", "gb_free": "6.9", "wall": "75484"}
[2025-01-30 21:23:21,375][train_inner][INFO] - {"epoch": 35, "update": 34.335, "loss": "19.089", "nll_loss": "0.187", "total": "710.94", "n_correct": "708.43", "ppl": "1.14", "accuracy": "99.647", "wps": "273", "ups": "0.38", "wpb": "710.9", "bsz": "56.9", "num_updates": "27600", "lr": "7.16298e-05", "gnorm": "2.421", "loss_scale": "128", "train_wall": "507", "gb_free": "6.7", "wall": "76005"}
[2025-01-30 21:32:04,920][train_inner][INFO] - {"epoch": 35, "update": 34.583, "loss": "19.504", "nll_loss": "0.19", "total": "712.43", "n_correct": "709.62", "ppl": "1.14", "accuracy": "99.606", "wps": "272.2", "ups": "0.38", "wpb": "712.4", "bsz": "55.8", "num_updates": "27800", "lr": "6.95158e-05", "gnorm": "2.369", "loss_scale": "128", "train_wall": "508", "gb_free": "6.4", "wall": "76528"}
[2025-01-30 21:40:09,656][train_inner][INFO] - {"epoch": 35, "update": 34.832, "loss": "18.943", "nll_loss": "0.197", "total": "712.215", "n_correct": "708.445", "ppl": "1.15", "accuracy": "99.471", "wps": "293.9", "ups": "0.41", "wpb": "712.2", "bsz": "57.7", "num_updates": "28000", "lr": "6.74641e-05", "gnorm": "2.593", "loss_scale": "128", "train_wall": "473", "gb_free": "6.2", "wall": "77013"}
[2025-01-30 21:45:27,495][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2025-01-30 21:45:27,501][train][INFO] - {"epoch": 35, "train_loss": "19.076", "train_nll_loss": "0.19", "train_total": "711.575", "train_n_correct": "708.687", "train_ppl": "1.14", "train_accuracy": "99.594", "train_wps": "269.7", "train_ups": "0.38", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "28135", "train_lr": "6.61136e-05", "train_gnorm": "2.501", "train_loss_scale": "128", "train_train_wall": "1974", "train_gb_free": "7", "train_wall": "77331"}
[2025-01-30 21:45:31,052][fairseq.trainer][INFO] - begin training epoch 36
[2025-01-30 21:45:31,053][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 21:50:00,312][train_inner][INFO] - {"epoch": 36, "update": 35.081, "loss": "18.474", "nll_loss": "0.183", "total": "714.445", "n_correct": "712.395", "ppl": "1.14", "accuracy": "99.713", "wps": "241.9", "ups": "0.34", "wpb": "714.4", "bsz": "58.8", "num_updates": "28200", "lr": "6.54731e-05", "gnorm": "2.376", "loss_scale": "128", "train_wall": "519", "gb_free": "6.2", "wall": "77604"}
[2025-01-30 21:58:39,102][train_inner][INFO] - {"epoch": 36, "update": 35.33, "loss": "19.158", "nll_loss": "0.186", "total": "713.2", "n_correct": "710.63", "ppl": "1.14", "accuracy": "99.64", "wps": "275", "ups": "0.39", "wpb": "713.2", "bsz": "56.7", "num_updates": "28400", "lr": "6.35408e-05", "gnorm": "2.257", "loss_scale": "128", "train_wall": "506", "gb_free": "6.8", "wall": "78123"}
[2025-01-30 22:07:28,127][train_inner][INFO] - {"epoch": 36, "update": 35.578, "loss": "18.944", "nll_loss": "0.185", "total": "713.56", "n_correct": "711.285", "ppl": "1.14", "accuracy": "99.681", "wps": "269.8", "ups": "0.38", "wpb": "713.6", "bsz": "57.4", "num_updates": "28600", "lr": "6.16655e-05", "gnorm": "2.408", "loss_scale": "128", "train_wall": "516", "gb_free": "5.9", "wall": "78652"}
[2025-01-30 22:15:47,387][train_inner][INFO] - {"epoch": 36, "update": 35.827, "loss": "19.204", "nll_loss": "0.187", "total": "714.13", "n_correct": "711.755", "ppl": "1.14", "accuracy": "99.667", "wps": "286.1", "ups": "0.4", "wpb": "714.1", "bsz": "56.7", "num_updates": "28800", "lr": "5.98455e-05", "gnorm": "2.247", "loss_scale": "128", "train_wall": "487", "gb_free": "6.9", "wall": "79151"}
[2025-01-30 22:21:12,242][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 22:22:52,198][valid][INFO] - {"epoch": 36, "valid_loss": "32.893", "valid_nll_loss": "1.427", "valid_total": "678.4", "valid_n_correct": "564.75", "valid_ppl": "2.69", "valid_accuracy": "83.247", "valid_wps": "471.4", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "28939", "valid_best_accuracy": "83.387"}
[2025-01-30 22:22:52,202][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 28939 updates
[2025-01-30 22:22:52,203][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 22:23:06,109][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 22:23:06,504][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 36 @ 28939 updates, score 83.247) (writing took 14.302270297892392 seconds)
[2025-01-30 22:23:06,506][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2025-01-30 22:23:06,514][train][INFO] - {"epoch": 36, "train_loss": "18.998", "train_nll_loss": "0.184", "train_total": "711.575", "train_n_correct": "709.362", "train_ppl": "1.14", "train_accuracy": "99.689", "train_wps": "253.3", "train_ups": "0.36", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "28939", "train_lr": "5.86124e-05", "train_gnorm": "2.245", "train_loss_scale": "128", "train_train_wall": "2035", "train_gb_free": "6", "train_wall": "79590"}
[2025-01-30 22:23:08,369][fairseq.trainer][INFO] - begin training epoch 37
[2025-01-30 22:23:08,370][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 22:27:19,471][train_inner][INFO] - {"epoch": 37, "update": 36.076, "loss": "19.218", "nll_loss": "0.181", "total": "706.265", "n_correct": "704.505", "ppl": "1.13", "accuracy": "99.751", "wps": "204.1", "ups": "0.29", "wpb": "706.3", "bsz": "55.8", "num_updates": "29000", "lr": "5.80793e-05", "gnorm": "2.228", "loss_scale": "128", "train_wall": "472", "gb_free": "6.4", "wall": "79843"}
[2025-01-30 22:36:30,938][train_inner][INFO] - {"epoch": 37, "update": 36.325, "loss": "18.112", "nll_loss": "0.181", "total": "715.8", "n_correct": "713.865", "ppl": "1.13", "accuracy": "99.73", "wps": "259.6", "ups": "0.36", "wpb": "715.8", "bsz": "60", "num_updates": "29200", "lr": "5.63652e-05", "gnorm": "2.001", "loss_scale": "128", "train_wall": "537", "gb_free": "7.2", "wall": "80394"}
[2025-01-30 22:44:58,555][train_inner][INFO] - {"epoch": 37, "update": 36.573, "loss": "18.845", "nll_loss": "0.181", "total": "716.92", "n_correct": "714.935", "ppl": "1.13", "accuracy": "99.723", "wps": "282.5", "ups": "0.39", "wpb": "716.9", "bsz": "57.8", "num_updates": "29400", "lr": "5.47017e-05", "gnorm": "2.176", "loss_scale": "128", "train_wall": "494", "gb_free": "7.1", "wall": "80902"}
[2025-01-30 22:53:24,776][train_inner][INFO] - {"epoch": 37, "update": 36.822, "loss": "19.326", "nll_loss": "0.185", "total": "710.47", "n_correct": "708.075", "ppl": "1.14", "accuracy": "99.663", "wps": "280.7", "ups": "0.4", "wpb": "710.5", "bsz": "56", "num_updates": "29600", "lr": "5.30873e-05", "gnorm": "2.072", "loss_scale": "128", "train_wall": "493", "gb_free": "5.8", "wall": "81408"}
[2025-01-30 22:58:54,928][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2025-01-30 22:58:54,932][train][INFO] - {"epoch": 37, "train_loss": "18.993", "train_nll_loss": "0.184", "train_total": "711.575", "train_n_correct": "709.29", "train_ppl": "1.14", "train_accuracy": "99.679", "train_wps": "266.3", "train_ups": "0.37", "train_wpb": "711.6", "train_bsz": "57", "train_num_updates": "29743", "train_lr": "5.19623e-05", "train_gnorm": "2.188", "train_loss_scale": "128", "train_train_wall": "2001", "train_gb_free": "6.1", "train_wall": "81738"}
[2025-01-30 22:58:58,487][fairseq.trainer][INFO] - begin training epoch 38
[2025-01-30 22:58:58,489][fairseq_cli.train][INFO] - Start iterating over samples
[2025-01-30 23:03:03,495][train_inner][INFO] - {"epoch": 38, "update": 37.071, "loss": "19.271", "nll_loss": "0.189", "total": "703.64", "n_correct": "700.885", "ppl": "1.14", "accuracy": "99.608", "wps": "243.2", "ups": "0.35", "wpb": "703.6", "bsz": "55.7", "num_updates": "29800", "lr": "5.15205e-05", "gnorm": "2.375", "loss_scale": "128", "train_wall": "511", "gb_free": "6", "wall": "81987"}
[2025-01-30 23:11:58,075][train_inner][INFO] - {"epoch": 38, "update": 37.32, "loss": "18.659", "nll_loss": "0.185", "total": "712.62", "n_correct": "710.19", "ppl": "1.14", "accuracy": "99.659", "wps": "266.6", "ups": "0.37", "wpb": "712.6", "bsz": "58.1", "num_updates": "30000", "lr": "5e-05", "gnorm": "2.083", "loss_scale": "128", "train_wall": "521", "gb_free": "6.4", "wall": "82521"}
[2025-01-30 23:11:58,076][fairseq_cli.train][INFO] - Stopping training due to num_updates: 30000 >= max_update: 30000
[2025-01-30 23:11:58,077][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2025-01-30 23:13:40,256][valid][INFO] - {"epoch": 38, "valid_loss": "32.926", "valid_nll_loss": "1.433", "valid_total": "678.4", "valid_n_correct": "564.3", "valid_ppl": "2.7", "valid_accuracy": "83.181", "valid_wps": "315.1", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "30000", "valid_best_accuracy": "83.387"}
[2025-01-30 23:13:40,264][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 30000 updates
[2025-01-30 23:13:40,266][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 23:13:53,238][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_last.pt
[2025-01-30 23:13:53,470][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 30000 updates, score 83.181) (writing took 13.206318066455424 seconds)
[2025-01-30 23:13:53,472][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2025-01-30 23:13:53,476][train][INFO] - {"epoch": 38, "train_loss": "18.653", "train_nll_loss": "0.185", "train_total": "713.136", "train_n_correct": "710.658", "train_ppl": "1.14", "train_accuracy": "99.652", "train_wps": "204", "train_ups": "0.29", "train_wpb": "713.1", "train_bsz": "58.2", "train_num_updates": "30000", "train_lr": "5e-05", "train_gnorm": "2.154", "train_loss_scale": "128", "train_train_wall": "710", "train_gb_free": "6.4", "train_wall": "82637"}
[2025-01-30 23:13:53,476][fairseq_cli.train][INFO] - done training in 82630.7 seconds
