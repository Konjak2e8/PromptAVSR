2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19523
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19523
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19523
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 1
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 2
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19523
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 3
2024-12-10 16:29:15 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 0
[2024-12-10 16:29:16,540][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/workspace/av_hubert/avhubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19523', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 45000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/workspace/AV_HuBERT_pretrained/base_vox_iter5.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 22500, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/workspace/lrs2/433h_data', 'label_dir': '/workspace/lrs2/433h_data', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'fine_tuning': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video', 'audio'], 'image_aug': True, 'pad_audio': True, 'random_crop': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 15000, 'hold_steps': 0, 'decay_steps': 30000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 45000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-12-10 16:29:16,547][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune_prompt
[2024-12-10 16:29:16,547][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['wrd'], 'label_dir': '/workspace/lrs2/433h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video', 'audio'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}
[2024-12-10 16:29:17,516][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune_prompt
[2024-12-10 16:29:17,516][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['km'], 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'label_rate': 25, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 2000, 'min_sample_size': 5, 'max_trim_sample_size': 400, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': False}
[2024-12-10 16:29:17,526][avhubert.hubert][INFO] - HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2024-12-10 16:29:24,888][fairseq_cli.train][INFO] - AVHubertSeq2Seq(
  (encoder): HubertEncoderWrapper(
    (w2v_model): AVHubertModel(
      (feature_extractor_audio): SubModel(
        (proj): Linear(in_features=104, out_features=768, bias=True)
      )
      (feature_extractor_video): SubModel(
        (resnet): ResEncoder(
          (frontend3D): Sequential(
            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): PReLU(num_parameters=64)
            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
          )
          (trunk): ResNet(
            (layer1): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer2): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer3): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer4): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (avgpool): AdaptiveAvgPool2d(output_size=1)
          )
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (modal_prompt_learner): MultiModalPromptLearner(
        (compound_prompt_projections_audio): ModuleList(
          (0-11): 12 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_audio): ModuleList(
          (0-11): 12 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (compound_prompt_projections_video): ModuleList(
          (0-11): 12 x Sequential(
            (0): Linear(in_features=1536, out_features=96, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=96, out_features=768, bias=True)
          )
        )
        (layernorm_video): ModuleList(
          (0-11): 12 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (common_prompt_projection_video): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
        (common_prompt_projection_audio): Sequential(
          (0): Linear(in_features=768, out_features=48, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=48, out_features=768, bias=True)
        )
      )
      (video_encoder): TransformerEncoder_prompt(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (audio_encoder): TransformerEncoder_prompt(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2024-12-10 16:29:24,895][fairseq_cli.train][INFO] - task: AVHubertPretrainingTask
[2024-12-10 16:29:24,895][fairseq_cli.train][INFO] - model: AVHubertSeq2Seq
[2024-12-10 16:29:24,895][fairseq_cli.train][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2024-12-10 16:29:24,901][fairseq_cli.train][INFO] - num. shared model params: 345,845,576 (num. trained: 345,845,576)
[2024-12-10 16:29:24,905][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-12-10 16:29:24,906][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2024-12-10 16:29:24,916][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 1082, skipped 0 short and 0 long and 0 unaligned, longest-loaded=153, shortest-loaded=14
[2024-12-10 16:29:24,917][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/valid.wrd is sequence label. skipped
[2024-12-10 16:29:24,917][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <avhubert.utils.CenterCrop object at 0x7f3788e5f250>
    Normalize(mean=0.421, std=0.165)
)
[2024-12-10 16:29:24,917][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-12-10 16:29:24,917][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2024-12-10 16:29:25,164][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv1.bias
[2024-12-10 16:29:25,164][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv2.bias
[2024-12-10 16:29:25,164][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv1.bias
[2024-12-10 16:29:25,164][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv2.bias
[2024-12-10 16:29:25,164][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv2.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.downsample.0.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv2.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv2.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.downsample.0.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv2.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv2.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.downsample.0.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv1.bias
[2024-12-10 16:29:25,165][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv2.bias
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-10 16:29:28,350][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-12-10 16:29:28,350][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-12-10 16:29:28,351][fairseq_cli.train][INFO] - max tokens per device = 1000 and max sentences per device = None
[2024-12-10 16:29:28,351][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2024-12-10 16:29:54,777][fairseq.trainer][INFO] - Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 115 @ 0 updates)
[2024-12-10 16:29:54,777][fairseq.trainer][INFO] - loading train data for epoch 115
[2024-12-10 16:29:54,778][avhubert.hubert_pretraining][INFO] - Using tokenizer
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
[2024-12-10 16:29:55,953][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 163822, skipped 0 short and 292 long and 0 unaligned, longest-loaded=500, shortest-loaded=0
[2024-12-10 16:29:56,048][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/train.wrd is sequence label. skipped
[2024-12-10 16:29:56,049][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <avhubert.utils.HorizontalFlip object at 0x7f3830179ac0>
    Normalize(mean=0.421, std=0.165)
)
[2024-12-10 16:29:56,049][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-12-10 16:29:56,049][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2024-12-10 16:29:56,831][fairseq.trainer][INFO] - begin training epoch 115
[2024-12-10 16:29:56,831][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
[2024-12-10 16:35:31,640][train_inner][INFO] - {"epoch": 115, "update": 114.034, "loss": "155.252", "nll_loss": "6.004", "total": "668.485", "n_correct": "141.645", "ppl": "64.19", "accuracy": "21.189", "wps": "464.4", "ups": "0.69", "wpb": "668.5", "bsz": "28.5", "num_updates": "200", "lr": "2.32e-05", "gnorm": "18.997", "loss_scale": "128", "train_wall": "301", "gb_free": "3.8", "wall": "363"}
[2024-12-10 16:40:00,032][train_inner][INFO] - {"epoch": 115, "update": 114.068, "loss": "159.852", "nll_loss": "5.963", "total": "665.065", "n_correct": "143.395", "ppl": "62.4", "accuracy": "21.561", "wps": "495.6", "ups": "0.75", "wpb": "665.1", "bsz": "27.4", "num_updates": "400", "lr": "3.64e-05", "gnorm": "19.904", "loss_scale": "128", "train_wall": "262", "gb_free": "3.8", "wall": "632"}
[2024-12-10 16:43:54,171][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-12-10 16:44:36,941][train_inner][INFO] - {"epoch": 115, "update": 114.103, "loss": "153.838", "nll_loss": "5.898", "total": "668.26", "n_correct": "148.135", "ppl": "59.62", "accuracy": "22.167", "wps": "482.7", "ups": "0.72", "wpb": "668.3", "bsz": "28.3", "num_updates": "600", "lr": "4.96e-05", "gnorm": "19.171", "loss_scale": "64", "train_wall": "270", "gb_free": "3.8", "wall": "909"}
[2024-12-10 16:49:10,250][train_inner][INFO] - {"epoch": 115, "update": 114.137, "loss": "148.921", "nll_loss": "5.871", "total": "662.75", "n_correct": "149.58", "ppl": "58.51", "accuracy": "22.57", "wps": "485", "ups": "0.73", "wpb": "662.8", "bsz": "28.9", "num_updates": "800", "lr": "6.28e-05", "gnorm": "17.921", "loss_scale": "64", "train_wall": "267", "gb_free": "3.8", "wall": "1182"}
[2024-12-10 16:53:42,199][train_inner][INFO] - {"epoch": 115, "update": 114.171, "loss": "156.575", "nll_loss": "5.854", "total": "665.03", "n_correct": "150.595", "ppl": "57.85", "accuracy": "22.645", "wps": "489.1", "ups": "0.74", "wpb": "665", "bsz": "27.6", "num_updates": "1000", "lr": "7.6e-05", "gnorm": "19.531", "loss_scale": "64", "train_wall": "266", "gb_free": "3.8", "wall": "1454"}
[2024-12-10 16:58:12,010][train_inner][INFO] - {"epoch": 115, "update": 114.205, "loss": "154.211", "nll_loss": "5.834", "total": "666.565", "n_correct": "152.15", "ppl": "57.05", "accuracy": "22.826", "wps": "494.1", "ups": "0.74", "wpb": "666.6", "bsz": "28", "num_updates": "1200", "lr": "8.92e-05", "gnorm": "18.258", "loss_scale": "64", "train_wall": "264", "gb_free": "3.8", "wall": "1724"}
[2024-12-10 17:02:40,883][train_inner][INFO] - {"epoch": 115, "update": 114.239, "loss": "158.507", "nll_loss": "5.829", "total": "670.47", "n_correct": "153.345", "ppl": "56.83", "accuracy": "22.871", "wps": "498.7", "ups": "0.74", "wpb": "670.5", "bsz": "27.4", "num_updates": "1400", "lr": "0.0001024", "gnorm": "21.803", "loss_scale": "64", "train_wall": "263", "gb_free": "3.8", "wall": "1993"}
[2024-12-10 17:07:11,108][train_inner][INFO] - {"epoch": 115, "update": 114.273, "loss": "154.703", "nll_loss": "5.829", "total": "671.97", "n_correct": "154.455", "ppl": "56.86", "accuracy": "22.985", "wps": "497.4", "ups": "0.74", "wpb": "672", "bsz": "28.1", "num_updates": "1600", "lr": "0.0001156", "gnorm": "18.923", "loss_scale": "64", "train_wall": "263", "gb_free": "3.8", "wall": "2263"}
[2024-12-10 17:11:31,546][train_inner][INFO] - {"epoch": 115, "update": 114.307, "loss": "162.648", "nll_loss": "5.823", "total": "662.75", "n_correct": "152.81", "ppl": "56.6", "accuracy": "23.057", "wps": "509", "ups": "0.77", "wpb": "662.8", "bsz": "26.3", "num_updates": "1800", "lr": "0.0001288", "gnorm": "20.593", "loss_scale": "64", "train_wall": "254", "gb_free": "3.8", "wall": "2523"}
[2024-12-10 17:16:06,123][train_inner][INFO] - {"epoch": 115, "update": 114.341, "loss": "151.454", "nll_loss": "5.797", "total": "673.3", "n_correct": "157", "ppl": "55.61", "accuracy": "23.318", "wps": "490.5", "ups": "0.73", "wpb": "673.3", "bsz": "28.6", "num_updates": "2000", "lr": "0.000142", "gnorm": "19.091", "loss_scale": "64", "train_wall": "268", "gb_free": "3.8", "wall": "2798"}
[2024-12-10 17:20:34,757][train_inner][INFO] - {"epoch": 115, "update": 114.375, "loss": "157.719", "nll_loss": "5.809", "total": "656.585", "n_correct": "152.26", "ppl": "56.07", "accuracy": "23.19", "wps": "488.9", "ups": "0.74", "wpb": "656.6", "bsz": "26.9", "num_updates": "2200", "lr": "0.0001552", "gnorm": "19.237", "loss_scale": "64", "train_wall": "261", "gb_free": "3.8", "wall": "3066"}
[2024-12-10 17:25:12,587][train_inner][INFO] - {"epoch": 115, "update": 114.41, "loss": "147.488", "nll_loss": "5.773", "total": "658.62", "n_correct": "154.905", "ppl": "54.68", "accuracy": "23.52", "wps": "474.1", "ups": "0.72", "wpb": "658.6", "bsz": "28.7", "num_updates": "2400", "lr": "0.0001684", "gnorm": "20.84", "loss_scale": "64", "train_wall": "270", "gb_free": "3.8", "wall": "3344"}
[2024-12-10 17:30:01,465][train_inner][INFO] - {"epoch": 115, "update": 114.444, "loss": "148.727", "nll_loss": "5.794", "total": "660.855", "n_correct": "154.35", "ppl": "55.49", "accuracy": "23.356", "wps": "457.5", "ups": "0.69", "wpb": "660.9", "bsz": "28.6", "num_updates": "2600", "lr": "0.0001816", "gnorm": "19.587", "loss_scale": "64", "train_wall": "283", "gb_free": "3.8", "wall": "3633"}
[2024-12-10 17:34:46,060][train_inner][INFO] - {"epoch": 115, "update": 114.478, "loss": "154.353", "nll_loss": "5.799", "total": "667.79", "n_correct": "156.26", "ppl": "55.69", "accuracy": "23.4", "wps": "469.3", "ups": "0.7", "wpb": "667.8", "bsz": "27.9", "num_updates": "2800", "lr": "0.0001948", "gnorm": "18.83", "loss_scale": "64", "train_wall": "279", "gb_free": "3.8", "wall": "3918"}
[2024-12-10 17:39:27,871][train_inner][INFO] - {"epoch": 115, "update": 114.512, "loss": "151.283", "nll_loss": "5.767", "total": "667.73", "n_correct": "158.15", "ppl": "54.45", "accuracy": "23.685", "wps": "473.9", "ups": "0.71", "wpb": "667.7", "bsz": "28.3", "num_updates": "3000", "lr": "0.000208", "gnorm": "17.976", "loss_scale": "64", "train_wall": "276", "gb_free": "3.8", "wall": "4200"}
[2024-12-10 17:44:08,416][train_inner][INFO] - {"epoch": 115, "update": 114.546, "loss": "151.864", "nll_loss": "5.747", "total": "667.235", "n_correct": "159.91", "ppl": "53.72", "accuracy": "23.966", "wps": "475.7", "ups": "0.71", "wpb": "667.2", "bsz": "28.1", "num_updates": "3200", "lr": "0.0002212", "gnorm": "17.932", "loss_scale": "64", "train_wall": "275", "gb_free": "3.8", "wall": "4480"}
[2024-12-10 17:48:59,287][train_inner][INFO] - {"epoch": 115, "update": 114.58, "loss": "155.008", "nll_loss": "5.783", "total": "658.785", "n_correct": "155.345", "ppl": "55.05", "accuracy": "23.581", "wps": "453", "ups": "0.69", "wpb": "658.8", "bsz": "27.3", "num_updates": "3400", "lr": "0.0002344", "gnorm": "19.178", "loss_scale": "64", "train_wall": "284", "gb_free": "3.8", "wall": "4771"}
[2024-12-10 17:53:22,244][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-12-10 17:54:02,369][train_inner][INFO] - {"epoch": 115, "update": 114.614, "loss": "148.82", "nll_loss": "5.77", "total": "674.26", "n_correct": "159.055", "ppl": "54.57", "accuracy": "23.59", "wps": "444.9", "ups": "0.66", "wpb": "674.3", "bsz": "29.1", "num_updates": "3600", "lr": "0.0002476", "gnorm": "20.936", "loss_scale": "32", "train_wall": "297", "gb_free": "3.8", "wall": "5074"}
[2024-12-10 17:58:42,660][train_inner][INFO] - {"epoch": 115, "update": 114.649, "loss": "155.324", "nll_loss": "5.772", "total": "662.575", "n_correct": "155.645", "ppl": "54.64", "accuracy": "23.491", "wps": "472.8", "ups": "0.71", "wpb": "662.6", "bsz": "27.4", "num_updates": "3800", "lr": "0.0002608", "gnorm": "18.695", "loss_scale": "32", "train_wall": "274", "gb_free": "3.8", "wall": "5354"}
[2024-12-10 18:03:40,729][train_inner][INFO] - {"epoch": 115, "update": 114.683, "loss": "156.713", "nll_loss": "5.767", "total": "668.61", "n_correct": "157.555", "ppl": "54.45", "accuracy": "23.565", "wps": "448.6", "ups": "0.67", "wpb": "668.6", "bsz": "27.4", "num_updates": "4000", "lr": "0.000274", "gnorm": "19.147", "loss_scale": "32", "train_wall": "291", "gb_free": "3.8", "wall": "5652"}
[2024-12-10 18:08:27,230][train_inner][INFO] - {"epoch": 115, "update": 114.717, "loss": "155.015", "nll_loss": "5.77", "total": "663.905", "n_correct": "156.46", "ppl": "54.56", "accuracy": "23.567", "wps": "463.5", "ups": "0.7", "wpb": "663.9", "bsz": "27.5", "num_updates": "4200", "lr": "0.0002872", "gnorm": "18.577", "loss_scale": "32", "train_wall": "281", "gb_free": "3.8", "wall": "5939"}
[2024-12-10 18:13:29,640][train_inner][INFO] - {"epoch": 115, "update": 114.751, "loss": "144.152", "nll_loss": "5.73", "total": "668.225", "n_correct": "159.215", "ppl": "53.07", "accuracy": "23.827", "wps": "441.9", "ups": "0.66", "wpb": "668.2", "bsz": "29.6", "num_updates": "4400", "lr": "0.0003004", "gnorm": "17.574", "loss_scale": "32", "train_wall": "296", "gb_free": "3.8", "wall": "6241"}
[2024-12-10 18:18:28,262][train_inner][INFO] - {"epoch": 115, "update": 114.785, "loss": "149.481", "nll_loss": "5.741", "total": "669.705", "n_correct": "160.465", "ppl": "53.49", "accuracy": "23.961", "wps": "448.5", "ups": "0.67", "wpb": "669.7", "bsz": "28.6", "num_updates": "4600", "lr": "0.0003136", "gnorm": "17.529", "loss_scale": "32", "train_wall": "292", "gb_free": "3.8", "wall": "6540"}
[2024-12-10 18:23:26,717][train_inner][INFO] - {"epoch": 115, "update": 114.819, "loss": "148.865", "nll_loss": "5.759", "total": "665.82", "n_correct": "158.295", "ppl": "54.15", "accuracy": "23.774", "wps": "446.2", "ups": "0.67", "wpb": "665.8", "bsz": "28.6", "num_updates": "4800", "lr": "0.0003268", "gnorm": "17.644", "loss_scale": "32", "train_wall": "292", "gb_free": "3.8", "wall": "6838"}
[2024-12-10 18:28:18,425][train_inner][INFO] - {"epoch": 115, "update": 114.853, "loss": "157.024", "nll_loss": "5.79", "total": "665.865", "n_correct": "156.41", "ppl": "55.34", "accuracy": "23.49", "wps": "456.5", "ups": "0.69", "wpb": "665.9", "bsz": "27.3", "num_updates": "5000", "lr": "0.00034", "gnorm": "19.57", "loss_scale": "32", "train_wall": "286", "gb_free": "3.8", "wall": "7130"}
[2024-12-10 18:33:04,426][train_inner][INFO] - {"epoch": 115, "update": 114.887, "loss": "153.756", "nll_loss": "5.76", "total": "662.21", "n_correct": "157.3", "ppl": "54.2", "accuracy": "23.754", "wps": "463.1", "ups": "0.7", "wpb": "662.2", "bsz": "27.6", "num_updates": "5200", "lr": "0.0003532", "gnorm": "17.623", "loss_scale": "32", "train_wall": "280", "gb_free": "3.8", "wall": "7416"}
[2024-12-10 18:37:59,476][train_inner][INFO] - {"epoch": 115, "update": 114.922, "loss": "152.468", "nll_loss": "5.751", "total": "670.875", "n_correct": "158.525", "ppl": "53.84", "accuracy": "23.63", "wps": "454.8", "ups": "0.68", "wpb": "670.9", "bsz": "28.2", "num_updates": "5400", "lr": "0.0003664", "gnorm": "18.374", "loss_scale": "32", "train_wall": "289", "gb_free": "3.8", "wall": "7711"}
[2024-12-10 18:42:43,151][train_inner][INFO] - {"epoch": 115, "update": 114.956, "loss": "155.841", "nll_loss": "5.77", "total": "665.765", "n_correct": "157.715", "ppl": "54.58", "accuracy": "23.689", "wps": "469.4", "ups": "0.71", "wpb": "665.8", "bsz": "27.4", "num_updates": "5600", "lr": "0.0003796", "gnorm": "19.391", "loss_scale": "32", "train_wall": "278", "gb_free": "3.8", "wall": "7995"}
[2024-12-10 18:47:33,287][train_inner][INFO] - {"epoch": 115, "update": 114.99, "loss": "155.866", "nll_loss": "5.782", "total": "658", "n_correct": "154.63", "ppl": "55.02", "accuracy": "23.5", "wps": "453.6", "ups": "0.69", "wpb": "658", "bsz": "27.1", "num_updates": "5800", "lr": "0.0003928", "gnorm": "20.304", "loss_scale": "32", "train_wall": "284", "gb_free": "3.9", "wall": "8285"}
[2024-12-10 18:48:56,976][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-12-10 18:48:56,981][train][INFO] - {"epoch": 115, "train_loss": "153.546", "train_nll_loss": "5.804", "train_total": "665.811", "train_n_correct": "154.703", "train_ppl": "55.89", "train_accuracy": "23.235", "train_wps": "470.5", "train_ups": "0.71", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "5860", "train_lr": "0.00039676", "train_gnorm": "19.07", "train_loss_scale": "32", "train_train_wall": "8130", "train_gb_free": "3.8", "train_wall": "8369"}
[2024-12-10 18:48:58,139][fairseq.trainer][INFO] - begin training epoch 116
[2024-12-10 18:48:58,140][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2024-12-10 18:53:06,442][train_inner][INFO] - {"epoch": 116, "update": 115.024, "loss": "154.619", "nll_loss": "5.762", "total": "668.12", "n_correct": "157.11", "ppl": "54.27", "accuracy": "23.515", "wps": "401.1", "ups": "0.6", "wpb": "668.1", "bsz": "27.7", "num_updates": "6000", "lr": "0.000406", "gnorm": "21.779", "loss_scale": "32", "train_wall": "297", "gb_free": "3.9", "wall": "8618"}
[2024-12-10 18:57:57,077][train_inner][INFO] - {"epoch": 116, "update": 115.058, "loss": "152.866", "nll_loss": "5.762", "total": "662.005", "n_correct": "156.22", "ppl": "54.27", "accuracy": "23.598", "wps": "455.6", "ups": "0.69", "wpb": "662", "bsz": "27.8", "num_updates": "6200", "lr": "0.0004192", "gnorm": "19.879", "loss_scale": "32", "train_wall": "285", "gb_free": "3.8", "wall": "8909"}
[2024-12-10 19:02:42,368][train_inner][INFO] - {"epoch": 116, "update": 115.092, "loss": "156.997", "nll_loss": "5.789", "total": "660.655", "n_correct": "153.605", "ppl": "55.3", "accuracy": "23.25", "wps": "463.2", "ups": "0.7", "wpb": "660.7", "bsz": "27.1", "num_updates": "6400", "lr": "0.0004324", "gnorm": "20.115", "loss_scale": "32", "train_wall": "279", "gb_free": "3.8", "wall": "9194"}
[2024-12-10 19:07:34,413][train_inner][INFO] - {"epoch": 116, "update": 115.126, "loss": "150.415", "nll_loss": "5.747", "total": "663.165", "n_correct": "157.07", "ppl": "53.7", "accuracy": "23.685", "wps": "454.2", "ups": "0.68", "wpb": "663.2", "bsz": "28.2", "num_updates": "6600", "lr": "0.0004456", "gnorm": "19.488", "loss_scale": "32", "train_wall": "287", "gb_free": "3.8", "wall": "9486"}
[2024-12-10 19:12:03,202][train_inner][INFO] - {"epoch": 116, "update": 115.16, "loss": "161.664", "nll_loss": "5.774", "total": "666.055", "n_correct": "156.76", "ppl": "54.73", "accuracy": "23.536", "wps": "495.6", "ups": "0.74", "wpb": "666.1", "bsz": "26.4", "num_updates": "6800", "lr": "0.0004588", "gnorm": "19.86", "loss_scale": "32", "train_wall": "263", "gb_free": "3.9", "wall": "9755"}
[2024-12-10 19:16:52,638][train_inner][INFO] - {"epoch": 116, "update": 115.194, "loss": "148.687", "nll_loss": "5.778", "total": "655.24", "n_correct": "154.775", "ppl": "54.85", "accuracy": "23.621", "wps": "452.8", "ups": "0.69", "wpb": "655.2", "bsz": "28.3", "num_updates": "7000", "lr": "0.000472", "gnorm": "18.852", "loss_scale": "32", "train_wall": "284", "gb_free": "3.8", "wall": "10044"}
[2024-12-10 19:21:41,863][train_inner][INFO] - {"epoch": 116, "update": 115.229, "loss": "152.221", "nll_loss": "5.738", "total": "667.93", "n_correct": "159.675", "ppl": "53.38", "accuracy": "23.906", "wps": "461.9", "ups": "0.69", "wpb": "667.9", "bsz": "28", "num_updates": "7200", "lr": "0.0004852", "gnorm": "19.481", "loss_scale": "32", "train_wall": "284", "gb_free": "3.8", "wall": "10334"}
[2024-12-10 19:26:19,568][train_inner][INFO] - {"epoch": 116, "update": 115.263, "loss": "158.027", "nll_loss": "5.769", "total": "672.67", "n_correct": "158.785", "ppl": "54.54", "accuracy": "23.605", "wps": "484.5", "ups": "0.72", "wpb": "672.7", "bsz": "27.3", "num_updates": "7400", "lr": "0.0004984", "gnorm": "21.862", "loss_scale": "32", "train_wall": "272", "gb_free": "3.8", "wall": "10611"}
[2024-12-10 19:31:05,748][train_inner][INFO] - {"epoch": 116, "update": 115.297, "loss": "154.46", "nll_loss": "5.764", "total": "666.01", "n_correct": "157.43", "ppl": "54.34", "accuracy": "23.638", "wps": "465.5", "ups": "0.7", "wpb": "666", "bsz": "27.6", "num_updates": "7600", "lr": "0.0005116", "gnorm": "20.743", "loss_scale": "32", "train_wall": "281", "gb_free": "3.8", "wall": "10897"}
[2024-12-10 19:33:37,388][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-12-10 19:35:52,416][train_inner][INFO] - {"epoch": 116, "update": 115.331, "loss": "156.807", "nll_loss": "5.782", "total": "669.605", "n_correct": "156.935", "ppl": "55.02", "accuracy": "23.437", "wps": "467.2", "ups": "0.7", "wpb": "669.6", "bsz": "27.4", "num_updates": "7800", "lr": "0.0005248", "gnorm": "22.128", "loss_scale": "32", "train_wall": "282", "gb_free": "3.8", "wall": "11184"}
[2024-12-10 19:40:29,105][train_inner][INFO] - {"epoch": 116, "update": 115.365, "loss": "154.598", "nll_loss": "5.756", "total": "662.285", "n_correct": "157.025", "ppl": "54.03", "accuracy": "23.71", "wps": "478.7", "ups": "0.72", "wpb": "662.3", "bsz": "27.4", "num_updates": "8000", "lr": "0.000538", "gnorm": "21.378", "loss_scale": "32", "train_wall": "271", "gb_free": "3.8", "wall": "11461"}
[2024-12-10 19:45:04,624][train_inner][INFO] - {"epoch": 116, "update": 115.399, "loss": "149.481", "nll_loss": "5.785", "total": "669.48", "n_correct": "158.055", "ppl": "55.15", "accuracy": "23.609", "wps": "486", "ups": "0.73", "wpb": "669.5", "bsz": "28.8", "num_updates": "8200", "lr": "0.0005512", "gnorm": "19.312", "loss_scale": "32", "train_wall": "269", "gb_free": "3.8", "wall": "11736"}
[2024-12-10 19:49:42,356][train_inner][INFO] - {"epoch": 116, "update": 115.433, "loss": "159.49", "nll_loss": "5.788", "total": "667.175", "n_correct": "157.045", "ppl": "55.24", "accuracy": "23.539", "wps": "480.5", "ups": "0.72", "wpb": "667.2", "bsz": "26.9", "num_updates": "8400", "lr": "0.0005644", "gnorm": "21.463", "loss_scale": "32", "train_wall": "272", "gb_free": "3.8", "wall": "12014"}
[2024-12-10 19:54:23,646][train_inner][INFO] - {"epoch": 116, "update": 115.468, "loss": "149.828", "nll_loss": "5.778", "total": "656.555", "n_correct": "153.625", "ppl": "54.87", "accuracy": "23.399", "wps": "466.8", "ups": "0.71", "wpb": "656.6", "bsz": "28.1", "num_updates": "8600", "lr": "0.0005776", "gnorm": "19.464", "loss_scale": "32", "train_wall": "276", "gb_free": "3.8", "wall": "12295"}
[2024-12-10 19:59:18,011][train_inner][INFO] - {"epoch": 116, "update": 115.502, "loss": "152.348", "nll_loss": "5.796", "total": "665.365", "n_correct": "155.315", "ppl": "55.55", "accuracy": "23.343", "wps": "452.1", "ups": "0.68", "wpb": "665.4", "bsz": "28.1", "num_updates": "8800", "lr": "0.0005908", "gnorm": "24.523", "loss_scale": "32", "train_wall": "289", "gb_free": "3.8", "wall": "12590"}
[2024-12-10 20:04:01,334][train_inner][INFO] - {"epoch": 116, "update": 115.536, "loss": "154.812", "nll_loss": "5.807", "total": "662.385", "n_correct": "153.705", "ppl": "55.99", "accuracy": "23.205", "wps": "467.6", "ups": "0.71", "wpb": "662.4", "bsz": "27.6", "num_updates": "9000", "lr": "0.000604", "gnorm": "20.701", "loss_scale": "32", "train_wall": "278", "gb_free": "3.8", "wall": "12873"}
[2024-12-10 20:08:39,920][train_inner][INFO] - {"epoch": 116, "update": 115.57, "loss": "153.507", "nll_loss": "5.799", "total": "673.08", "n_correct": "156.215", "ppl": "55.67", "accuracy": "23.209", "wps": "483.2", "ups": "0.72", "wpb": "673.1", "bsz": "28.2", "num_updates": "9200", "lr": "0.0006172", "gnorm": "23.592", "loss_scale": "32", "train_wall": "272", "gb_free": "3.8", "wall": "13152"}
[2024-12-10 20:13:29,857][train_inner][INFO] - {"epoch": 116, "update": 115.604, "loss": "150.989", "nll_loss": "5.796", "total": "661.71", "n_correct": "154.61", "ppl": "55.56", "accuracy": "23.365", "wps": "456.5", "ups": "0.69", "wpb": "661.7", "bsz": "28.2", "num_updates": "9400", "lr": "0.0006304", "gnorm": "21.219", "loss_scale": "32", "train_wall": "283", "gb_free": "3.8", "wall": "13442"}
[2024-12-10 20:18:13,157][train_inner][INFO] - {"epoch": 116, "update": 115.638, "loss": "156.226", "nll_loss": "5.802", "total": "670.76", "n_correct": "155.05", "ppl": "55.78", "accuracy": "23.116", "wps": "473.5", "ups": "0.71", "wpb": "670.8", "bsz": "27.7", "num_updates": "9600", "lr": "0.0006436", "gnorm": "23.987", "loss_scale": "32", "train_wall": "277", "gb_free": "3.8", "wall": "13725"}
[2024-12-10 20:23:02,979][train_inner][INFO] - {"epoch": 116, "update": 115.672, "loss": "153.996", "nll_loss": "5.801", "total": "664.295", "n_correct": "155.775", "ppl": "55.74", "accuracy": "23.45", "wps": "458.4", "ups": "0.69", "wpb": "664.3", "bsz": "27.8", "num_updates": "9800", "lr": "0.0006568", "gnorm": "25.164", "loss_scale": "32", "train_wall": "284", "gb_free": "3.8", "wall": "14015"}
[2024-12-10 20:27:48,456][train_inner][INFO] - {"epoch": 116, "update": 115.706, "loss": "152.641", "nll_loss": "5.804", "total": "663.81", "n_correct": "154.76", "ppl": "55.89", "accuracy": "23.314", "wps": "465.1", "ups": "0.7", "wpb": "663.8", "bsz": "28", "num_updates": "10000", "lr": "0.00067", "gnorm": "22.147", "loss_scale": "32", "train_wall": "280", "gb_free": "3.8", "wall": "14300"}
[2024-12-10 20:32:33,721][train_inner][INFO] - {"epoch": 116, "update": 115.741, "loss": "149.821", "nll_loss": "5.812", "total": "671.565", "n_correct": "155.795", "ppl": "56.17", "accuracy": "23.199", "wps": "470.8", "ups": "0.7", "wpb": "671.6", "bsz": "28.9", "num_updates": "10200", "lr": "0.0006832", "gnorm": "20.858", "loss_scale": "32", "train_wall": "280", "gb_free": "3.8", "wall": "14585"}
[2024-12-10 20:37:07,305][train_inner][INFO] - {"epoch": 116, "update": 115.775, "loss": "154.905", "nll_loss": "5.838", "total": "667.615", "n_correct": "153.525", "ppl": "57.21", "accuracy": "22.996", "wps": "488.1", "ups": "0.73", "wpb": "667.6", "bsz": "27.9", "num_updates": "10400", "lr": "0.0006964", "gnorm": "25.339", "loss_scale": "32", "train_wall": "268", "gb_free": "3.8", "wall": "14859"}
[2024-12-10 20:41:45,054][train_inner][INFO] - {"epoch": 116, "update": 115.809, "loss": "154.113", "nll_loss": "5.816", "total": "669.86", "n_correct": "154.76", "ppl": "56.32", "accuracy": "23.103", "wps": "482.4", "ups": "0.72", "wpb": "669.9", "bsz": "28.1", "num_updates": "10600", "lr": "0.0007096", "gnorm": "22.689", "loss_scale": "32", "train_wall": "272", "gb_free": "3.8", "wall": "15137"}
[2024-12-10 20:46:15,185][train_inner][INFO] - {"epoch": 116, "update": 115.843, "loss": "154.333", "nll_loss": "5.831", "total": "670.395", "n_correct": "155.285", "ppl": "56.92", "accuracy": "23.163", "wps": "496.4", "ups": "0.74", "wpb": "670.4", "bsz": "28.1", "num_updates": "10800", "lr": "0.0007228", "gnorm": "23.296", "loss_scale": "32", "train_wall": "264", "gb_free": "3.8", "wall": "15407"}
[2024-12-10 20:50:51,808][train_inner][INFO] - {"epoch": 116, "update": 115.877, "loss": "150.673", "nll_loss": "5.853", "total": "666.175", "n_correct": "150.93", "ppl": "57.79", "accuracy": "22.656", "wps": "481.7", "ups": "0.72", "wpb": "666.2", "bsz": "28.7", "num_updates": "11000", "lr": "0.000736", "gnorm": "28", "loss_scale": "32", "train_wall": "271", "gb_free": "3.9", "wall": "15683"}
[2024-12-10 20:54:09,202][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-12-10 20:55:33,549][train_inner][INFO] - {"epoch": 116, "update": 115.911, "loss": "147.753", "nll_loss": "5.843", "total": "668.4", "n_correct": "152.405", "ppl": "57.42", "accuracy": "22.801", "wps": "474.5", "ups": "0.71", "wpb": "668.4", "bsz": "29.3", "num_updates": "11200", "lr": "0.0007492", "gnorm": "23.799", "loss_scale": "16", "train_wall": "276", "gb_free": "3.8", "wall": "15965"}
[2024-12-10 20:59:59,778][train_inner][INFO] - {"epoch": 116, "update": 115.945, "loss": "153.257", "nll_loss": "5.857", "total": "668.885", "n_correct": "150.77", "ppl": "57.97", "accuracy": "22.54", "wps": "502.5", "ups": "0.75", "wpb": "668.9", "bsz": "28.3", "num_updates": "11400", "lr": "0.0007624", "gnorm": "24.815", "loss_scale": "16", "train_wall": "261", "gb_free": "3.8", "wall": "16231"}
[2024-12-10 21:04:25,966][train_inner][INFO] - {"epoch": 116, "update": 115.98, "loss": "152.261", "nll_loss": "5.847", "total": "658.795", "n_correct": "149.14", "ppl": "57.54", "accuracy": "22.638", "wps": "495.1", "ups": "0.75", "wpb": "658.8", "bsz": "28", "num_updates": "11600", "lr": "0.0007756", "gnorm": "26.021", "loss_scale": "16", "train_wall": "260", "gb_free": "3.9", "wall": "16498"}
[2024-12-10 21:06:50,277][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-12-10 21:07:41,823][valid][INFO] - {"epoch": 116, "valid_loss": "76.887", "valid_nll_loss": "5.397", "valid_total": "678.4", "valid_n_correct": "184.45", "valid_ppl": "42.14", "valid_accuracy": "27.189", "valid_wps": "491.5", "valid_wpb": "678.4", "valid_bsz": "54.1", "valid_num_updates": "11720"}
[2024-12-10 21:07:41,825][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 116 @ 11720 updates
[2024-12-10 21:07:41,826][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-12-10 21:08:01,473][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-12-10 21:08:21,667][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 116 @ 11720 updates, score 27.189) (writing took 39.84208702604519 seconds)
[2024-12-10 21:08:21,668][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-12-10 21:08:21,682][train][INFO] - {"epoch": 116, "train_loss": "153.361", "train_nll_loss": "5.797", "train_total": "665.814", "train_n_correct": "155.154", "train_ppl": "55.6", "train_accuracy": "23.303", "train_wps": "466.4", "train_ups": "0.7", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "11720", "train_lr": "0.00078352", "train_gnorm": "22.257", "train_loss_scale": "16", "train_train_wall": "8076", "train_gb_free": "3.8", "train_wall": "16733"}
[2024-12-10 21:08:24,297][fairseq.trainer][INFO] - begin training epoch 117
[2024-12-10 21:08:24,298][fairseq_cli.train][INFO] - Start iterating over samples
