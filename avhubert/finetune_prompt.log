2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17259
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17259
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 1
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17259
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 2
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17259
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 3
2024-12-16 10:46:29 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 0
[2024-12-16 10:46:30,461][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/workspace/av_hubert/avhubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17259', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 45000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/workspace/AV_HuBERT_pretrained/base_vox_iter5.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 22500, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/workspace/lrs2/433h_data', 'label_dir': '/workspace/lrs2/433h_data', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'fine_tuning': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video', 'audio'], 'image_aug': True, 'pad_audio': True, 'random_crop': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 15000, 'hold_steps': 0, 'decay_steps': 30000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 45000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-12-16 10:46:30,468][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune_prompt
[2024-12-16 10:46:30,468][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['wrd'], 'label_dir': '/workspace/lrs2/433h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video', 'audio'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}
[2024-12-16 10:46:31,548][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune_prompt
[2024-12-16 10:46:31,549][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['km'], 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'label_rate': 25, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 2000, 'min_sample_size': 5, 'max_trim_sample_size': 400, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': False}
[2024-12-16 10:46:31,558][avhubert.hubert][INFO] - HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2024-12-16 10:46:40,857][fairseq_cli.train][INFO] - AVHubertSeq2Seq(
  (encoder): HubertEncoderWrapper(
    (w2v_model): AVHubertModel(
      (feature_extractor_audio): SubModel(
        (proj): Linear(in_features=104, out_features=768, bias=True)
      )
      (feature_extractor_video): SubModel(
        (resnet): ResEncoder(
          (frontend3D): Sequential(
            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): PReLU(num_parameters=64)
            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
          )
          (trunk): ResNet(
            (layer1): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer2): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer3): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer4): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (avgpool): AdaptiveAvgPool2d(output_size=1)
          )
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (modal_prompt_learner): MultiModalPromptLearner(
        (compound_prompt_projections_audio): ModuleList(
          (0-11): 12 x Sequential(
            (0): Linear(in_features=1536, out_features=192, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=192, out_features=768, bias=True)
          )
        )
        (layernorm_audio): ModuleList(
          (0-11): 12 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (compound_prompt_projections_video): ModuleList(
          (0-11): 12 x Sequential(
            (0): Linear(in_features=1536, out_features=192, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=192, out_features=768, bias=True)
          )
        )
        (layernorm_video): ModuleList(
          (0-11): 12 x LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (common_prompt_projection_video): Sequential(
          (0): Linear(in_features=768, out_features=96, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=96, out_features=768, bias=True)
        )
        (common_prompt_projection_audio): Sequential(
          (0): Linear(in_features=768, out_features=96, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=96, out_features=768, bias=True)
        )
      )
      (video_encoder): TransformerEncoder_prompt(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (audio_encoder): TransformerEncoder_prompt(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2024-12-16 10:46:40,890][fairseq_cli.train][INFO] - task: AVHubertPretrainingTask
[2024-12-16 10:46:40,890][fairseq_cli.train][INFO] - model: AVHubertSeq2Seq
[2024-12-16 10:46:40,890][fairseq_cli.train][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2024-12-16 10:46:40,897][fairseq_cli.train][INFO] - num. shared model params: 351,303,848 (num. trained: 351,303,848)
[2024-12-16 10:46:40,902][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-12-16 10:46:40,904][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2024-12-16 10:46:40,932][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 1082, skipped 0 short and 0 long and 0 unaligned, longest-loaded=153, shortest-loaded=14
[2024-12-16 10:46:40,932][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/valid.wrd is sequence label. skipped
[2024-12-16 10:46:40,932][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <avhubert.utils.CenterCrop object at 0x7f61fc70e280>
    Normalize(mean=0.421, std=0.165)
)
[2024-12-16 10:46:40,933][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-12-16 10:46:40,933][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2024-12-16 10:46:42,666][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv1.bias
[2024-12-16 10:46:42,667][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv2.bias
[2024-12-16 10:46:42,667][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv1.bias
[2024-12-16 10:46:42,667][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv2.bias
[2024-12-16 10:46:42,667][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv1.bias
[2024-12-16 10:46:42,668][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv2.bias
[2024-12-16 10:46:42,668][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.downsample.0.bias
[2024-12-16 10:46:42,668][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv1.bias
[2024-12-16 10:46:42,668][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv2.bias
[2024-12-16 10:46:42,668][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv1.bias
[2024-12-16 10:46:42,669][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv2.bias
[2024-12-16 10:46:42,669][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.downsample.0.bias
[2024-12-16 10:46:42,669][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv1.bias
[2024-12-16 10:46:42,669][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv2.bias
[2024-12-16 10:46:42,669][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv1.bias
[2024-12-16 10:46:42,670][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv2.bias
[2024-12-16 10:46:42,670][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.downsample.0.bias
[2024-12-16 10:46:42,670][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv1.bias
[2024-12-16 10:46:42,670][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv2.bias
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-12-16 10:46:50,441][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-12-16 10:46:50,441][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-12-16 10:46:50,442][fairseq_cli.train][INFO] - max tokens per device = 1000 and max sentences per device = None
[2024-12-16 10:46:50,443][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2024-12-16 10:47:15,117][fairseq.trainer][INFO] - Loaded checkpoint checkpoints/checkpoint_last.pt (epoch 127 @ 0 updates)
[2024-12-16 10:47:15,118][fairseq.trainer][INFO] - loading train data for epoch 127
[2024-12-16 10:47:15,134][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2024-12-16 10:47:16,000][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 163822, skipped 0 short and 292 long and 0 unaligned, longest-loaded=500, shortest-loaded=0
[2024-12-16 10:47:16,109][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/train.wrd is sequence label. skipped
[2024-12-16 10:47:16,110][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <avhubert.utils.HorizontalFlip object at 0x7f62a229ed90>
    Normalize(mean=0.421, std=0.165)
)
[2024-12-16 10:47:16,110][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-12-16 10:47:16,110][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2024-12-16 10:47:16,925][fairseq.trainer][INFO] - begin training epoch 127
[2024-12-16 10:47:16,926][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/distributed/utils.py:767: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  obj = torch.load(buffer, map_location="cpu")
[2024-12-16 10:53:07,975][train_inner][INFO] - {"epoch": 127, "update": 126.034, "loss": "137.392", "nll_loss": "5.009", "total": "666.745", "n_correct": "208.71", "ppl": "32.21", "accuracy": "31.303", "wps": "438.6", "ups": "0.66", "wpb": "666.7", "bsz": "27.9", "num_updates": "200", "lr": "2.32e-05", "gnorm": "11.753", "loss_scale": "128", "train_wall": "317", "gb_free": "3.7", "wall": "378"}
[2024-12-16 10:58:09,063][train_inner][INFO] - {"epoch": 127, "update": 126.068, "loss": "133.9", "nll_loss": "4.991", "total": "663.88", "n_correct": "208.28", "ppl": "31.8", "accuracy": "31.373", "wps": "441", "ups": "0.66", "wpb": "663.9", "bsz": "28.4", "num_updates": "400", "lr": "3.64e-05", "gnorm": "10.955", "loss_scale": "128", "train_wall": "294", "gb_free": "3.7", "wall": "679"}
[2024-12-16 11:03:17,116][train_inner][INFO] - {"epoch": 127, "update": 126.102, "loss": "135.712", "nll_loss": "4.962", "total": "661.88", "n_correct": "210.425", "ppl": "31.16", "accuracy": "31.792", "wps": "429.7", "ups": "0.65", "wpb": "661.9", "bsz": "27.9", "num_updates": "600", "lr": "4.96e-05", "gnorm": "10.986", "loss_scale": "128", "train_wall": "302", "gb_free": "3.7", "wall": "987"}
[2024-12-16 11:08:24,599][train_inner][INFO] - {"epoch": 127, "update": 126.136, "loss": "137.436", "nll_loss": "4.948", "total": "668.6", "n_correct": "214.965", "ppl": "30.88", "accuracy": "32.152", "wps": "434.9", "ups": "0.65", "wpb": "668.6", "bsz": "27.7", "num_updates": "800", "lr": "6.28e-05", "gnorm": "11.136", "loss_scale": "128", "train_wall": "300", "gb_free": "3.7", "wall": "1294"}
[2024-12-16 11:13:33,145][train_inner][INFO] - {"epoch": 127, "update": 126.171, "loss": "141.605", "nll_loss": "4.949", "total": "662.705", "n_correct": "212.13", "ppl": "30.88", "accuracy": "32.01", "wps": "429.6", "ups": "0.65", "wpb": "662.7", "bsz": "26.7", "num_updates": "1000", "lr": "7.6e-05", "gnorm": "11.85", "loss_scale": "128", "train_wall": "301", "gb_free": "3.7", "wall": "1603"}
[2024-12-16 11:18:45,604][train_inner][INFO] - {"epoch": 127, "update": 126.205, "loss": "135.735", "nll_loss": "4.952", "total": "664.82", "n_correct": "212.82", "ppl": "30.95", "accuracy": "32.012", "wps": "425.5", "ups": "0.64", "wpb": "664.8", "bsz": "27.9", "num_updates": "1200", "lr": "8.92e-05", "gnorm": "11.042", "loss_scale": "128", "train_wall": "305", "gb_free": "3.7", "wall": "1915"}
[2024-12-16 11:23:46,729][train_inner][INFO] - {"epoch": 127, "update": 126.239, "loss": "133.914", "nll_loss": "4.915", "total": "675.93", "n_correct": "219.32", "ppl": "30.16", "accuracy": "32.447", "wps": "449", "ups": "0.66", "wpb": "675.9", "bsz": "28.6", "num_updates": "1400", "lr": "0.0001024", "gnorm": "11.15", "loss_scale": "128", "train_wall": "294", "gb_free": "3.7", "wall": "2216"}
[2024-12-16 11:28:43,944][train_inner][INFO] - {"epoch": 127, "update": 126.273, "loss": "136.229", "nll_loss": "4.919", "total": "669.65", "n_correct": "216.825", "ppl": "30.25", "accuracy": "32.379", "wps": "450.6", "ups": "0.67", "wpb": "669.6", "bsz": "27.9", "num_updates": "1600", "lr": "0.0001156", "gnorm": "11.451", "loss_scale": "128", "train_wall": "290", "gb_free": "3.7", "wall": "2513"}
[2024-12-16 11:33:38,111][train_inner][INFO] - {"epoch": 127, "update": 126.307, "loss": "136.521", "nll_loss": "4.895", "total": "662.74", "n_correct": "216.49", "ppl": "29.75", "accuracy": "32.666", "wps": "450.6", "ups": "0.68", "wpb": "662.7", "bsz": "27.4", "num_updates": "1800", "lr": "0.0001288", "gnorm": "11.396", "loss_scale": "128", "train_wall": "287", "gb_free": "3.7", "wall": "2808"}
[2024-12-16 11:38:38,106][train_inner][INFO] - {"epoch": 127, "update": 126.341, "loss": "135.916", "nll_loss": "4.899", "total": "662.895", "n_correct": "215.91", "ppl": "29.85", "accuracy": "32.571", "wps": "441.9", "ups": "0.67", "wpb": "662.9", "bsz": "27.6", "num_updates": "2000", "lr": "0.000142", "gnorm": "11.519", "loss_scale": "128", "train_wall": "293", "gb_free": "3.7", "wall": "3108"}
[2024-12-16 11:43:39,610][train_inner][INFO] - {"epoch": 127, "update": 126.375, "loss": "130.967", "nll_loss": "4.922", "total": "661.36", "n_correct": "213.63", "ppl": "30.31", "accuracy": "32.302", "wps": "438.8", "ups": "0.66", "wpb": "661.4", "bsz": "28.7", "num_updates": "2200", "lr": "0.0001552", "gnorm": "11.338", "loss_scale": "128", "train_wall": "295", "gb_free": "3.7", "wall": "3409"}
[2024-12-16 11:48:53,162][train_inner][INFO] - {"epoch": 127, "update": 126.409, "loss": "127.712", "nll_loss": "4.909", "total": "670.69", "n_correct": "217.73", "ppl": "30.05", "accuracy": "32.464", "wps": "427.8", "ups": "0.64", "wpb": "670.7", "bsz": "29.8", "num_updates": "2400", "lr": "0.0001684", "gnorm": "10.641", "loss_scale": "128", "train_wall": "306", "gb_free": "3.7", "wall": "3723"}
[2024-12-16 11:53:51,623][train_inner][INFO] - {"epoch": 127, "update": 126.444, "loss": "130.624", "nll_loss": "4.874", "total": "666.4", "n_correct": "218.085", "ppl": "29.33", "accuracy": "32.726", "wps": "446.6", "ups": "0.67", "wpb": "666.4", "bsz": "28.8", "num_updates": "2600", "lr": "0.0001816", "gnorm": "11.623", "loss_scale": "128", "train_wall": "291", "gb_free": "3.7", "wall": "4021"}
[2024-12-16 11:58:50,175][train_inner][INFO] - {"epoch": 127, "update": 126.478, "loss": "133.533", "nll_loss": "4.894", "total": "662.745", "n_correct": "215.935", "ppl": "29.73", "accuracy": "32.582", "wps": "444", "ups": "0.67", "wpb": "662.7", "bsz": "28.1", "num_updates": "2800", "lr": "0.0001948", "gnorm": "11.676", "loss_scale": "128", "train_wall": "292", "gb_free": "3.7", "wall": "4320"}
[2024-12-16 12:03:42,338][train_inner][INFO] - {"epoch": 127, "update": 126.512, "loss": "139.403", "nll_loss": "4.889", "total": "662.635", "n_correct": "217.49", "ppl": "29.63", "accuracy": "32.822", "wps": "453.6", "ups": "0.68", "wpb": "662.6", "bsz": "26.9", "num_updates": "3000", "lr": "0.000208", "gnorm": "11.959", "loss_scale": "128", "train_wall": "285", "gb_free": "3.7", "wall": "4612"}
[2024-12-16 12:08:48,362][train_inner][INFO] - {"epoch": 127, "update": 126.546, "loss": "130.975", "nll_loss": "4.9", "total": "669.53", "n_correct": "219.1", "ppl": "29.85", "accuracy": "32.724", "wps": "437.6", "ups": "0.65", "wpb": "669.5", "bsz": "28.9", "num_updates": "3200", "lr": "0.0002212", "gnorm": "11.336", "loss_scale": "128", "train_wall": "299", "gb_free": "3.7", "wall": "4918"}
[2024-12-16 12:13:32,746][train_inner][INFO] - {"epoch": 127, "update": 126.58, "loss": "138.172", "nll_loss": "4.889", "total": "665.84", "n_correct": "218.715", "ppl": "29.62", "accuracy": "32.848", "wps": "468.3", "ups": "0.7", "wpb": "665.8", "bsz": "27.2", "num_updates": "3400", "lr": "0.0002344", "gnorm": "12.045", "loss_scale": "128", "train_wall": "278", "gb_free": "3.7", "wall": "5202"}
[2024-12-16 12:18:25,818][train_inner][INFO] - {"epoch": 127, "update": 126.614, "loss": "128.391", "nll_loss": "4.896", "total": "664.59", "n_correct": "216.96", "ppl": "29.77", "accuracy": "32.646", "wps": "453.5", "ups": "0.68", "wpb": "664.6", "bsz": "29.3", "num_updates": "3600", "lr": "0.0002476", "gnorm": "11.361", "loss_scale": "128", "train_wall": "287", "gb_free": "3.7", "wall": "5495"}
[2024-12-16 12:23:23,565][train_inner][INFO] - {"epoch": 127, "update": 126.648, "loss": "137.945", "nll_loss": "4.895", "total": "665.77", "n_correct": "217.315", "ppl": "29.75", "accuracy": "32.641", "wps": "447.2", "ups": "0.67", "wpb": "665.8", "bsz": "27.3", "num_updates": "3800", "lr": "0.0002608", "gnorm": "12.261", "loss_scale": "128", "train_wall": "292", "gb_free": "3.7", "wall": "5793"}
[2024-12-16 12:28:37,152][train_inner][INFO] - {"epoch": 127, "update": 126.682, "loss": "131.689", "nll_loss": "4.903", "total": "668.46", "n_correct": "217.175", "ppl": "29.92", "accuracy": "32.489", "wps": "426.3", "ups": "0.64", "wpb": "668.5", "bsz": "28.7", "num_updates": "4000", "lr": "0.000274", "gnorm": "11.766", "loss_scale": "128", "train_wall": "307", "gb_free": "3.7", "wall": "6107"}
[2024-12-16 12:33:34,313][train_inner][INFO] - {"epoch": 127, "update": 126.716, "loss": "137.815", "nll_loss": "4.917", "total": "656.1", "n_correct": "212.435", "ppl": "30.21", "accuracy": "32.378", "wps": "441.6", "ups": "0.67", "wpb": "656.1", "bsz": "27", "num_updates": "4200", "lr": "0.0002872", "gnorm": "12.136", "loss_scale": "256", "train_wall": "290", "gb_free": "3.7", "wall": "6404"}
[2024-12-16 12:38:28,178][train_inner][INFO] - {"epoch": 127, "update": 126.751, "loss": "137.689", "nll_loss": "4.915", "total": "663.365", "n_correct": "214.315", "ppl": "30.18", "accuracy": "32.307", "wps": "451.5", "ups": "0.68", "wpb": "663.4", "bsz": "27.3", "num_updates": "4400", "lr": "0.0003004", "gnorm": "12.222", "loss_scale": "256", "train_wall": "287", "gb_free": "3.7", "wall": "6698"}
[2024-12-16 12:43:18,370][train_inner][INFO] - {"epoch": 127, "update": 126.785, "loss": "137.788", "nll_loss": "4.929", "total": "667.485", "n_correct": "215.44", "ppl": "30.46", "accuracy": "32.276", "wps": "460", "ups": "0.69", "wpb": "667.5", "bsz": "27.5", "num_updates": "4600", "lr": "0.0003136", "gnorm": "12.123", "loss_scale": "256", "train_wall": "283", "gb_free": "3.7", "wall": "6988"}
[2024-12-16 12:48:13,098][train_inner][INFO] - {"epoch": 127, "update": 126.819, "loss": "139.495", "nll_loss": "4.903", "total": "673.255", "n_correct": "218.255", "ppl": "29.92", "accuracy": "32.418", "wps": "456.9", "ups": "0.68", "wpb": "673.3", "bsz": "27.3", "num_updates": "4800", "lr": "0.0003268", "gnorm": "12.186", "loss_scale": "256", "train_wall": "289", "gb_free": "3.7", "wall": "7283"}
[2024-12-16 12:53:07,518][train_inner][INFO] - {"epoch": 127, "update": 126.853, "loss": "134.079", "nll_loss": "4.927", "total": "665.13", "n_correct": "214.84", "ppl": "30.41", "accuracy": "32.3", "wps": "451.8", "ups": "0.68", "wpb": "665.1", "bsz": "28.2", "num_updates": "5000", "lr": "0.00034", "gnorm": "11.943", "loss_scale": "256", "train_wall": "288", "gb_free": "3.7", "wall": "7577"}
[2024-12-16 12:58:03,628][train_inner][INFO] - {"epoch": 127, "update": 126.887, "loss": "137.175", "nll_loss": "4.932", "total": "669.615", "n_correct": "215.59", "ppl": "30.53", "accuracy": "32.196", "wps": "452.3", "ups": "0.68", "wpb": "669.6", "bsz": "27.8", "num_updates": "5200", "lr": "0.0003532", "gnorm": "11.809", "loss_scale": "256", "train_wall": "290", "gb_free": "3.7", "wall": "7873"}
[2024-12-16 13:02:58,437][train_inner][INFO] - {"epoch": 127, "update": 126.921, "loss": "135.255", "nll_loss": "4.895", "total": "662.74", "n_correct": "216.58", "ppl": "29.75", "accuracy": "32.679", "wps": "449.6", "ups": "0.68", "wpb": "662.7", "bsz": "27.7", "num_updates": "5400", "lr": "0.0003664", "gnorm": "12.089", "loss_scale": "256", "train_wall": "288", "gb_free": "3.7", "wall": "8168"}
[2024-12-16 13:07:54,007][train_inner][INFO] - {"epoch": 127, "update": 126.955, "loss": "135.637", "nll_loss": "4.919", "total": "668.155", "n_correct": "217.07", "ppl": "30.25", "accuracy": "32.488", "wps": "452.1", "ups": "0.68", "wpb": "668.2", "bsz": "27.9", "num_updates": "5600", "lr": "0.0003796", "gnorm": "12.424", "loss_scale": "256", "train_wall": "288", "gb_free": "3.7", "wall": "8464"}
[2024-12-16 13:12:47,493][train_inner][INFO] - {"epoch": 127, "update": 126.989, "loss": "135.234", "nll_loss": "4.921", "total": "663.9", "n_correct": "214.32", "ppl": "30.29", "accuracy": "32.282", "wps": "452.4", "ups": "0.68", "wpb": "663.9", "bsz": "27.9", "num_updates": "5800", "lr": "0.0003928", "gnorm": "12.175", "loss_scale": "256", "train_wall": "286", "gb_free": "3.7", "wall": "8757"}
[2024-12-16 13:14:00,975][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-12-16 13:14:00,979][train][INFO] - {"epoch": 127, "train_loss": "135.212", "train_nll_loss": "4.92", "train_total": "665.831", "train_n_correct": "215.415", "train_ppl": "30.26", "train_accuracy": "32.353", "train_wps": "445.7", "train_ups": "0.67", "train_wpb": "665.8", "train_bsz": "27.9", "train_num_updates": "5862", "train_lr": "0.000396892", "train_gnorm": "11.669", "train_loss_scale": "256", "train_train_wall": "8577", "train_gb_free": "3.7", "train_wall": "8831"}
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2024-12-16 13:14:02,357][fairseq.trainer][INFO] - begin training epoch 128
[2024-12-16 13:14:02,359][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:502: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2024-12-16 13:18:12,814][train_inner][INFO] - {"epoch": 128, "update": 127.024, "loss": "127.889", "nll_loss": "4.873", "total": "672.8", "n_correct": "220.61", "ppl": "29.3", "accuracy": "32.79", "wps": "413.6", "ups": "0.61", "wpb": "672.8", "bsz": "29.6", "num_updates": "6000", "lr": "0.000406", "gnorm": "11.897", "loss_scale": "256", "train_wall": "292", "gb_free": "3.7", "wall": "9082"}
