2024-11-11 11:20:00 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 2
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 1
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 5
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 3
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 4
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 7
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13257
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 6
2024-11-11 11:20:01 | INFO | fairseq.distributed.utils | initialized host dell-SYS-4029GP-TRT as rank 0
[2024-11-11 11:20:02,430][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/workspace/av_hubert/avhubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13257', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 45000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/workspace/AV_HuBERT_pretrained/base_vox_iter5.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 22500, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/workspace/lrs2/433h_data', 'label_dir': '/workspace/lrs2/433h_data', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'fine_tuning': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video'], 'image_aug': True, 'pad_audio': True, 'random_crop': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 15000, 'hold_steps': 0, 'decay_steps': 30000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 45000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-11-11 11:20:02,437][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune
[2024-11-11 11:20:02,437][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['wrd'], 'label_dir': '/workspace/lrs2/433h_data', 'label_rate': -1, 'sample_rate': 16000, 'normalize': True, 'enable_padding': False, 'max_sample_size': 500, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': True, 'tokenizer_bpe_name': 'sentencepiece', 'tokenizer_bpe_model': '/workspace/lrs2/spm1000/spm_unigram1000.model', 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True}
[2024-11-11 11:20:03,398][avhubert.hubert_pretraining][INFO] - current directory is /workspace/av_hubert/finetune
[2024-11-11 11:20:03,399][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'av_hubert_pretraining', 'data': '/workspace/lrs2/433h_data', 'labels': ['km'], 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'label_rate': 25, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 2000, 'min_sample_size': 5, 'max_trim_sample_size': 400, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['audio', 'video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': False}
[2024-11-11 11:20:03,407][avhubert.hubert][INFO] - HubertModel Config: {'_name': 'av_hubert', 'label_rate': 25, 'input_modality': '${task.input_modality}', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 1.0, 'mask_length_audio': 10, 'mask_prob_audio': 0.8, 'mask_length_image': 5, 'mask_prob_image': 0.3, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'resnet_relu_type': 'prelu', 'resnet_weights': None, 'sim_type': 'cosine', 'sub_encoder_layers': 0, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input', 'decoder_embed_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_layerdrop': 0.0, 'decoder_attention_heads': 4, 'decoder_learned_pos': False, 'decoder_normalize_before': False, 'no_token_positional_embeddings': False, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.1, 'decoder_activation_dropout': 0.0, 'max_target_positions': 2048, 'share_decoder_input_output_embed': False, 'no_scale_embedding': True}
[2024-11-11 11:20:14,221][fairseq_cli.train][INFO] - AVHubertSeq2Seq(
  (encoder): HubertEncoderWrapper(
    (w2v_model): AVHubertModel(
      (feature_extractor_audio): SubModel(
        (proj): Linear(in_features=104, out_features=768, bias=True)
      )
      (feature_extractor_video): SubModel(
        (resnet): ResEncoder(
          (frontend3D): Sequential(
            (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): PReLU(num_parameters=64)
            (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)
          )
          (trunk): ResNet(
            (layer1): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): BasicBlock(
                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=64)
                (relu2): PReLU(num_parameters=64)
                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer2): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=128)
                (relu2): PReLU(num_parameters=128)
                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer3): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=256)
                (relu2): PReLU(num_parameters=256)
                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (layer4): Sequential(
              (0): BasicBlock(
                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (downsample): Sequential(
                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (1): BasicBlock(
                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (relu1): PReLU(num_parameters=512)
                (relu2): PReLU(num_parameters=512)
                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (avgpool): AdaptiveAvgPool2d(output_size=1)
          )
        )
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
      (post_extract_proj): Linear(in_features=1536, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.0, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.0, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
[2024-11-11 11:20:14,227][fairseq_cli.train][INFO] - task: AVHubertPretrainingTask
[2024-11-11 11:20:14,227][fairseq_cli.train][INFO] - model: AVHubertSeq2Seq
[2024-11-11 11:20:14,227][fairseq_cli.train][INFO] - criterion: LabelSmoothedCrossEntropyCriterion
[2024-11-11 11:20:14,230][fairseq_cli.train][INFO] - num. shared model params: 160,613,608 (num. trained: 160,613,608)
[2024-11-11 11:20:14,232][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-11-11 11:20:14,234][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2024-11-11 11:20:14,248][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 1082, skipped 0 short and 0 long and 0 unaligned, longest-loaded=153, shortest-loaded=14
[2024-11-11 11:20:14,249][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/valid.wrd is sequence label. skipped
[2024-11-11 11:20:14,250][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <avhubert.utils.CenterCrop object at 0x7f5f3163e520>
    Normalize(mean=0.421, std=0.165)
)
[2024-11-11 11:20:14,250][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-11-11 11:20:14,250][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
[2024-11-11 11:20:19,173][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv1.bias
[2024-11-11 11:20:19,174][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.0.conv2.bias
[2024-11-11 11:20:19,174][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv1.bias
[2024-11-11 11:20:19,174][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer1.1.conv2.bias
[2024-11-11 11:20:19,174][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv1.bias
[2024-11-11 11:20:19,174][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.conv2.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.0.downsample.0.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv1.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer2.1.conv2.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv1.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.conv2.bias
[2024-11-11 11:20:19,175][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.0.downsample.0.bias
[2024-11-11 11:20:19,176][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv1.bias
[2024-11-11 11:20:19,176][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer3.1.conv2.bias
[2024-11-11 11:20:19,176][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv1.bias
[2024-11-11 11:20:19,176][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.conv2.bias
[2024-11-11 11:20:19,176][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.0.downsample.0.bias
[2024-11-11 11:20:19,177][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv1.bias
[2024-11-11 11:20:19,177][fairseq.trainer][INFO] - detected shared parameter: encoder.w2v_model.feature_extractor_video.resnet.frontend3D.0.bias <- encoder.w2v_model.feature_extractor_video.resnet.trunk.layer4.1.conv2.bias
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 11.762 GB ; name = NVIDIA GeForce RTX 3060                 
[2024-11-11 11:20:19,460][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-11-11 11:20:19,461][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-11-11 11:20:19,461][fairseq_cli.train][INFO] - max tokens per device = 1000 and max sentences per device = None
[2024-11-11 11:20:19,463][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2024-11-11 11:20:19,463][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2024-11-11 11:20:19,463][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-11-11 11:20:19,464][avhubert.hubert_pretraining][INFO] - Using tokenizer
[2024-11-11 11:20:20,182][avhubert.hubert_dataset][INFO] - max_keep=500, min_keep=None, loaded 163822, skipped 0 short and 292 long and 0 unaligned, longest-loaded=500, shortest-loaded=0
[2024-11-11 11:20:20,266][avhubert.hubert_dataset][INFO] - /workspace/lrs2/433h_data/train.wrd is sequence label. skipped
[2024-11-11 11:20:20,266][avhubert.hubert_dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    RandomCrop(size=(88, 88))
    <avhubert.utils.HorizontalFlip object at 0x7f5f47556e80>
    Normalize(mean=0.421, std=0.165)
)
[2024-11-11 11:20:20,266][avhubert.hubert_dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=500, seqs2seq data=True,
[2024-11-11 11:20:20,266][avhubert.hubert_dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0, Number of mixture: 1
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
[2024-11-11 11:20:21,604][fairseq.trainer][INFO] - begin training epoch 1
[2024-11-11 11:20:21,605][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
/workspace/av_hubert/fairseq/fairseq/checkpoint_utils.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/workspace/av_hubert/fairseq/fairseq/trainer.py:131: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  self._grad_norm_buf = torch.cuda.DoubleTensor(self.data_parallel_world_size)
[2024-11-11 11:22:05,480][train_inner][INFO] - {"epoch": 1, "update": 0.068, "loss": "210.947", "nll_loss": "8.507", "total": "1332.83", "n_correct": "72.66", "ppl": "363.86", "accuracy": "5.452", "wps": "3590.9", "ups": "2.69", "wpb": "1332.8", "bsz": "55.3", "num_updates": "200", "lr": "2.32e-05", "gnorm": "44.971", "loss_scale": "128", "train_wall": "79", "gb_free": "8", "wall": "106"}
[2024-11-11 11:23:19,045][train_inner][INFO] - {"epoch": 1, "update": 0.136, "loss": "202.527", "nll_loss": "8.182", "total": "1345.46", "n_correct": "94.295", "ppl": "290.36", "accuracy": "7.008", "wps": "3658.1", "ups": "2.72", "wpb": "1345.5", "bsz": "56.3", "num_updates": "400", "lr": "3.64e-05", "gnorm": "30.392", "loss_scale": "128", "train_wall": "72", "gb_free": "8", "wall": "180"}
[2024-11-11 11:24:32,794][train_inner][INFO] - {"epoch": 1, "update": 0.205, "loss": "201.251", "nll_loss": "8.097", "total": "1331.79", "n_correct": "102.51", "ppl": "273.8", "accuracy": "7.697", "wps": "3611.9", "ups": "2.71", "wpb": "1331.8", "bsz": "55.6", "num_updates": "600", "lr": "4.96e-05", "gnorm": "29.473", "loss_scale": "128", "train_wall": "72", "gb_free": "8", "wall": "253"}
[2024-11-11 11:25:43,482][train_inner][INFO] - {"epoch": 1, "update": 0.273, "loss": "198.545", "nll_loss": "8.015", "total": "1342.96", "n_correct": "111.395", "ppl": "258.63", "accuracy": "8.295", "wps": "3799.9", "ups": "2.83", "wpb": "1343", "bsz": "56.3", "num_updates": "800", "lr": "6.28e-05", "gnorm": "29.382", "loss_scale": "128", "train_wall": "69", "gb_free": "8", "wall": "324"}
[2024-11-11 11:26:54,070][train_inner][INFO] - {"epoch": 1, "update": 0.341, "loss": "188.981", "nll_loss": "7.892", "total": "1334.97", "n_correct": "123.81", "ppl": "237.48", "accuracy": "9.274", "wps": "3782.6", "ups": "2.83", "wpb": "1335", "bsz": "58.1", "num_updates": "1000", "lr": "7.6e-05", "gnorm": "34.185", "loss_scale": "128", "train_wall": "69", "gb_free": "8", "wall": "395"}
[2024-11-11 11:28:06,523][train_inner][INFO] - {"epoch": 1, "update": 0.409, "loss": "193.172", "nll_loss": "7.757", "total": "1323.59", "n_correct": "133.825", "ppl": "216.31", "accuracy": "10.111", "wps": "3653.9", "ups": "2.76", "wpb": "1323.6", "bsz": "55.5", "num_updates": "1200", "lr": "8.92e-05", "gnorm": "33.306", "loss_scale": "128", "train_wall": "71", "gb_free": "8", "wall": "467"}
[2024-11-11 11:29:16,255][train_inner][INFO] - {"epoch": 1, "update": 0.478, "loss": "192.52", "nll_loss": "7.619", "total": "1335.74", "n_correct": "145.94", "ppl": "196.64", "accuracy": "10.926", "wps": "3831.3", "ups": "2.87", "wpb": "1335.7", "bsz": "55.4", "num_updates": "1400", "lr": "0.0001024", "gnorm": "38.302", "loss_scale": "128", "train_wall": "68", "gb_free": "8", "wall": "537"}
[2024-11-11 11:30:26,928][train_inner][INFO] - {"epoch": 1, "update": 0.546, "loss": "184.609", "nll_loss": "7.404", "total": "1325", "n_correct": "160.4", "ppl": "169.37", "accuracy": "12.106", "wps": "3749.8", "ups": "2.83", "wpb": "1325", "bsz": "56", "num_updates": "1600", "lr": "0.0001156", "gnorm": "46.67", "loss_scale": "128", "train_wall": "69", "gb_free": "8", "wall": "607"}
[2024-11-11 11:31:38,339][train_inner][INFO] - {"epoch": 1, "update": 0.614, "loss": "182.771", "nll_loss": "7.104", "total": "1332.78", "n_correct": "179.595", "ppl": "137.59", "accuracy": "13.475", "wps": "3732.9", "ups": "2.8", "wpb": "1332.8", "bsz": "55.1", "num_updates": "1800", "lr": "0.0001288", "gnorm": "70.994", "loss_scale": "128", "train_wall": "70", "gb_free": "8", "wall": "679"}
[2024-11-11 11:32:47,176][train_inner][INFO] - {"epoch": 1, "update": 0.682, "loss": "173.873", "nll_loss": "6.827", "total": "1329.59", "n_correct": "199.555", "ppl": "113.57", "accuracy": "15.009", "wps": "3863.3", "ups": "2.91", "wpb": "1329.6", "bsz": "56", "num_updates": "2000", "lr": "0.000142", "gnorm": "74.806", "loss_scale": "128", "train_wall": "68", "gb_free": "8", "wall": "748"}
[2024-11-11 11:33:59,737][train_inner][INFO] - {"epoch": 1, "update": 0.751, "loss": "171.034", "nll_loss": "6.635", "total": "1327.52", "n_correct": "215.685", "ppl": "99.4", "accuracy": "16.247", "wps": "3659.3", "ups": "2.76", "wpb": "1327.5", "bsz": "55.6", "num_updates": "2200", "lr": "0.0001552", "gnorm": "78.969", "loss_scale": "256", "train_wall": "71", "gb_free": "8", "wall": "820"}
[2024-11-11 11:35:08,470][train_inner][INFO] - {"epoch": 1, "update": 0.819, "loss": "166.78", "nll_loss": "6.437", "total": "1332.49", "n_correct": "234.515", "ppl": "86.63", "accuracy": "17.6", "wps": "3877.5", "ups": "2.91", "wpb": "1332.5", "bsz": "55.9", "num_updates": "2400", "lr": "0.0001684", "gnorm": "73.606", "loss_scale": "256", "train_wall": "68", "gb_free": "8", "wall": "889"}
[2024-11-11 11:36:19,077][train_inner][INFO] - {"epoch": 1, "update": 0.887, "loss": "163.47", "nll_loss": "6.304", "total": "1331.36", "n_correct": "246.04", "ppl": "78.99", "accuracy": "18.48", "wps": "3771.5", "ups": "2.83", "wpb": "1331.4", "bsz": "56.1", "num_updates": "2600", "lr": "0.0001816", "gnorm": "76.615", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "960"}
[2024-11-11 11:37:31,430][train_inner][INFO] - {"epoch": 1, "update": 0.955, "loss": "162.316", "nll_loss": "6.171", "total": "1324.27", "n_correct": "255.805", "ppl": "72.05", "accuracy": "19.317", "wps": "3660.8", "ups": "2.76", "wpb": "1324.3", "bsz": "55.3", "num_updates": "2800", "lr": "0.0001948", "gnorm": "74.595", "loss_scale": "256", "train_wall": "71", "gb_free": "8", "wall": "1032"}
[2024-11-11 11:38:15,252][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-11-11 11:38:15,258][train][INFO] - {"epoch": 1, "train_loss": "183.954", "train_nll_loss": "7.298", "train_total": "1331.66", "train_n_correct": "167.302", "train_ppl": "157.32", "train_accuracy": "12.563", "train_wps": "3738.6", "train_ups": "2.81", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "2931", "train_lr": "0.000203446", "train_gnorm": "53.444", "train_loss_scale": "256", "train_train_wall": "1030", "train_gb_free": "8", "train_wall": "1076"}
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2024-11-11 11:38:15,829][fairseq.trainer][INFO] - begin training epoch 2
[2024-11-11 11:38:15,830][fairseq_cli.train][INFO] - Start iterating over samples
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/workspace/av_hubert/fairseq/fairseq/tasks/fairseq_task.py:501: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
[2024-11-11 11:39:09,962][train_inner][INFO] - {"epoch": 2, "update": 1.024, "loss": "156.621", "nll_loss": "6.025", "total": "1325.29", "n_correct": "271.275", "ppl": "65.1", "accuracy": "20.469", "wps": "2690.2", "ups": "2.03", "wpb": "1325.3", "bsz": "56.3", "num_updates": "3000", "lr": "0.000208", "gnorm": "69.987", "loss_scale": "256", "train_wall": "72", "gb_free": "8", "wall": "1130"}
[2024-11-11 11:40:20,572][train_inner][INFO] - {"epoch": 2, "update": 1.092, "loss": "159.461", "nll_loss": "5.925", "total": "1342.13", "n_correct": "282.9", "ppl": "60.74", "accuracy": "21.078", "wps": "3801.9", "ups": "2.83", "wpb": "1342.1", "bsz": "55.3", "num_updates": "3200", "lr": "0.0002212", "gnorm": "78.931", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1201"}
[2024-11-11 11:41:30,935][train_inner][INFO] - {"epoch": 2, "update": 1.16, "loss": "160.232", "nll_loss": "5.857", "total": "1333.18", "n_correct": "289.32", "ppl": "57.97", "accuracy": "21.701", "wps": "3789.6", "ups": "2.84", "wpb": "1333.2", "bsz": "54.2", "num_updates": "3400", "lr": "0.0002344", "gnorm": "71.469", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1271"}
[2024-11-11 11:42:41,577][train_inner][INFO] - {"epoch": 2, "update": 1.228, "loss": "152.095", "nll_loss": "5.735", "total": "1333.95", "n_correct": "305.365", "ppl": "53.26", "accuracy": "22.892", "wps": "3776.9", "ups": "2.83", "wpb": "1334", "bsz": "56.2", "num_updates": "3600", "lr": "0.0002476", "gnorm": "77.772", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1342"}
[2024-11-11 11:43:52,149][train_inner][INFO] - {"epoch": 2, "update": 1.296, "loss": "150.389", "nll_loss": "5.646", "total": "1333.48", "n_correct": "315.56", "ppl": "50.08", "accuracy": "23.664", "wps": "3779.4", "ups": "2.83", "wpb": "1333.5", "bsz": "56.1", "num_updates": "3800", "lr": "0.0002608", "gnorm": "72.011", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1413"}
[2024-11-11 11:45:02,857][train_inner][INFO] - {"epoch": 2, "update": 1.365, "loss": "143.345", "nll_loss": "5.547", "total": "1331.33", "n_correct": "328.785", "ppl": "46.77", "accuracy": "24.696", "wps": "3765.9", "ups": "2.83", "wpb": "1331.3", "bsz": "58", "num_updates": "4000", "lr": "0.000274", "gnorm": "71.728", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1483"}
[2024-11-11 11:46:13,216][train_inner][INFO] - {"epoch": 2, "update": 1.433, "loss": "145.014", "nll_loss": "5.491", "total": "1325.48", "n_correct": "333.995", "ppl": "44.97", "accuracy": "25.198", "wps": "3768", "ups": "2.84", "wpb": "1325.5", "bsz": "56.7", "num_updates": "4200", "lr": "0.0002872", "gnorm": "73.193", "loss_scale": "512", "train_wall": "69", "gb_free": "8", "wall": "1554"}
[2024-11-11 11:46:25,755][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 11:47:23,861][train_inner][INFO] - {"epoch": 2, "update": 1.502, "loss": "148.378", "nll_loss": "5.439", "total": "1324.55", "n_correct": "341.905", "ppl": "43.4", "accuracy": "25.813", "wps": "3750.1", "ups": "2.83", "wpb": "1324.5", "bsz": "54.9", "num_updates": "4400", "lr": "0.0003004", "gnorm": "72.429", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1624"}
[2024-11-11 11:48:34,601][train_inner][INFO] - {"epoch": 2, "update": 1.57, "loss": "142.55", "nll_loss": "5.33", "total": "1337.1", "n_correct": "359.515", "ppl": "40.23", "accuracy": "26.888", "wps": "3780.5", "ups": "2.83", "wpb": "1337.1", "bsz": "56.9", "num_updates": "4600", "lr": "0.0003136", "gnorm": "67.983", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1695"}
[2024-11-11 11:49:44,963][train_inner][INFO] - {"epoch": 2, "update": 1.638, "loss": "147.684", "nll_loss": "5.276", "total": "1326.21", "n_correct": "364.065", "ppl": "38.74", "accuracy": "27.451", "wps": "3769.9", "ups": "2.84", "wpb": "1326.2", "bsz": "54", "num_updates": "4800", "lr": "0.0003268", "gnorm": "67.591", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1765"}
[2024-11-11 11:50:55,558][train_inner][INFO] - {"epoch": 2, "update": 1.706, "loss": "142.77", "nll_loss": "5.18", "total": "1336.82", "n_correct": "379.125", "ppl": "36.25", "accuracy": "28.36", "wps": "3787.4", "ups": "2.83", "wpb": "1336.8", "bsz": "55.5", "num_updates": "5000", "lr": "0.00034", "gnorm": "68.854", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1836"}
[2024-11-11 11:52:05,551][train_inner][INFO] - {"epoch": 2, "update": 1.774, "loss": "140.681", "nll_loss": "5.169", "total": "1326.6", "n_correct": "379.385", "ppl": "35.97", "accuracy": "28.598", "wps": "3790.9", "ups": "2.86", "wpb": "1326.6", "bsz": "55.8", "num_updates": "5200", "lr": "0.0003532", "gnorm": "70.018", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1906"}
[2024-11-11 11:53:15,777][train_inner][INFO] - {"epoch": 2, "update": 1.843, "loss": "142.587", "nll_loss": "5.089", "total": "1336.12", "n_correct": "396.07", "ppl": "34.04", "accuracy": "29.643", "wps": "3805.4", "ups": "2.85", "wpb": "1336.1", "bsz": "54.8", "num_updates": "5400", "lr": "0.0003664", "gnorm": "59.706", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "1976"}
[2024-11-11 11:54:26,081][train_inner][INFO] - {"epoch": 2, "update": 1.911, "loss": "135.193", "nll_loss": "4.986", "total": "1332.17", "n_correct": "407.65", "ppl": "31.69", "accuracy": "30.6", "wps": "3790", "ups": "2.85", "wpb": "1332.2", "bsz": "56.8", "num_updates": "5600", "lr": "0.0003796", "gnorm": "57.985", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "2047"}
[2024-11-11 11:55:36,698][train_inner][INFO] - {"epoch": 2, "update": 1.979, "loss": "133.106", "nll_loss": "4.929", "total": "1324.53", "n_correct": "413.735", "ppl": "30.47", "accuracy": "31.236", "wps": "3751.5", "ups": "2.83", "wpb": "1324.5", "bsz": "56.9", "num_updates": "5800", "lr": "0.0003928", "gnorm": "59.528", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "2117"}
[2024-11-11 11:55:56,772][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 11:56:22,730][valid][INFO] - {"epoch": 2, "valid_loss": "58.434", "valid_nll_loss": "3.66", "valid_total": "1356.8", "valid_n_correct": "621.1", "valid_ppl": "12.64", "valid_accuracy": "45.777", "valid_wps": "4601.9", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "5861"}
[2024-11-11 11:56:22,733][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 5861 updates
[2024-11-11 11:56:22,734][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 11:56:28,631][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 11:56:30,571][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 5861 updates, score 45.777) (writing took 7.83749384758994 seconds)
[2024-11-11 11:56:30,572][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-11-11 11:56:30,579][train][INFO] - {"epoch": 2, "train_loss": "145.873", "train_nll_loss": "5.402", "train_total": "1331.62", "train_n_correct": "349.733", "train_ppl": "42.29", "train_accuracy": "26.264", "train_wps": "3562.1", "train_ups": "2.68", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "5861", "train_lr": "0.000396826", "train_gnorm": "68.774", "train_loss_scale": "256", "train_train_wall": "1018", "train_gb_free": "8", "train_wall": "2171"}
[2024-11-11 11:56:31,096][fairseq.trainer][INFO] - begin training epoch 3
[2024-11-11 11:56:31,097][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 11:57:47,807][train_inner][INFO] - {"epoch": 3, "update": 2.047, "loss": "136.385", "nll_loss": "4.852", "total": "1325.39", "n_correct": "424.985", "ppl": "28.88", "accuracy": "32.065", "wps": "2021.9", "ups": "1.53", "wpb": "1325.4", "bsz": "54.9", "num_updates": "6000", "lr": "0.000406", "gnorm": "56.594", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "2248"}
[2024-11-11 11:58:59,177][train_inner][INFO] - {"epoch": 3, "update": 2.116, "loss": "131.127", "nll_loss": "4.75", "total": "1322.83", "n_correct": "439.805", "ppl": "26.92", "accuracy": "33.247", "wps": "3707.2", "ups": "2.8", "wpb": "1322.8", "bsz": "56.1", "num_updates": "6200", "lr": "0.0004192", "gnorm": "57.439", "loss_scale": "256", "train_wall": "70", "gb_free": "8", "wall": "2320"}
[2024-11-11 12:00:10,307][train_inner][INFO] - {"epoch": 3, "update": 2.184, "loss": "133.829", "nll_loss": "4.714", "total": "1327.96", "n_correct": "447.775", "ppl": "26.25", "accuracy": "33.719", "wps": "3734.1", "ups": "2.81", "wpb": "1328", "bsz": "54.9", "num_updates": "6400", "lr": "0.0004324", "gnorm": "55.328", "loss_scale": "512", "train_wall": "70", "gb_free": "8", "wall": "2391"}
[2024-11-11 12:01:22,453][train_inner][INFO] - {"epoch": 3, "update": 2.252, "loss": "127.196", "nll_loss": "4.652", "total": "1343.51", "n_correct": "461.48", "ppl": "25.15", "accuracy": "34.349", "wps": "3724.7", "ups": "2.77", "wpb": "1343.5", "bsz": "57.8", "num_updates": "6600", "lr": "0.0004456", "gnorm": "48.177", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2463"}
[2024-11-11 12:02:34,959][train_inner][INFO] - {"epoch": 3, "update": 2.32, "loss": "128.66", "nll_loss": "4.633", "total": "1334.38", "n_correct": "461.67", "ppl": "24.81", "accuracy": "34.598", "wps": "3681", "ups": "2.76", "wpb": "1334.4", "bsz": "56.6", "num_updates": "6800", "lr": "0.0004588", "gnorm": "53.707", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2535"}
[2024-11-11 12:03:46,918][train_inner][INFO] - {"epoch": 3, "update": 2.389, "loss": "129.732", "nll_loss": "4.548", "total": "1326.76", "n_correct": "473.735", "ppl": "23.39", "accuracy": "35.706", "wps": "3687.6", "ups": "2.78", "wpb": "1326.8", "bsz": "55.1", "num_updates": "7000", "lr": "0.000472", "gnorm": "45.819", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2607"}
[2024-11-11 12:04:59,146][train_inner][INFO] - {"epoch": 3, "update": 2.457, "loss": "125.911", "nll_loss": "4.512", "total": "1324.91", "n_correct": "477.295", "ppl": "22.82", "accuracy": "36.025", "wps": "3668.9", "ups": "2.77", "wpb": "1324.9", "bsz": "56.3", "num_updates": "7200", "lr": "0.0004852", "gnorm": "47.136", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2680"}
[2024-11-11 12:06:10,579][train_inner][INFO] - {"epoch": 3, "update": 2.525, "loss": "129.606", "nll_loss": "4.468", "total": "1337.43", "n_correct": "490.17", "ppl": "22.13", "accuracy": "36.65", "wps": "3744.8", "ups": "2.8", "wpb": "1337.4", "bsz": "54.9", "num_updates": "7400", "lr": "0.0004984", "gnorm": "41.6", "loss_scale": "512", "train_wall": "70", "gb_free": "8", "wall": "2751"}
[2024-11-11 12:07:22,905][train_inner][INFO] - {"epoch": 3, "update": 2.593, "loss": "125.903", "nll_loss": "4.398", "total": "1329.65", "n_correct": "498.375", "ppl": "21.08", "accuracy": "37.482", "wps": "3677", "ups": "2.77", "wpb": "1329.7", "bsz": "55.5", "num_updates": "7600", "lr": "0.0005116", "gnorm": "42.219", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2823"}
[2024-11-11 12:08:34,754][train_inner][INFO] - {"epoch": 3, "update": 2.662, "loss": "124.339", "nll_loss": "4.331", "total": "1340.61", "n_correct": "512.98", "ppl": "20.12", "accuracy": "38.265", "wps": "3731.9", "ups": "2.78", "wpb": "1340.6", "bsz": "56", "num_updates": "7800", "lr": "0.0005248", "gnorm": "38.402", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2895"}
[2024-11-11 12:09:46,666][train_inner][INFO] - {"epoch": 3, "update": 2.73, "loss": "116.009", "nll_loss": "4.222", "total": "1334.61", "n_correct": "526.16", "ppl": "18.66", "accuracy": "39.424", "wps": "3712", "ups": "2.78", "wpb": "1334.6", "bsz": "58.7", "num_updates": "8000", "lr": "0.000538", "gnorm": "36.584", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "2967"}
[2024-11-11 12:10:59,227][train_inner][INFO] - {"epoch": 3, "update": 2.798, "loss": "120.73", "nll_loss": "4.232", "total": "1325.08", "n_correct": "522.4", "ppl": "18.79", "accuracy": "39.424", "wps": "3652.5", "ups": "2.76", "wpb": "1325.1", "bsz": "56.1", "num_updates": "8200", "lr": "0.0005512", "gnorm": "33.481", "loss_scale": "512", "train_wall": "71", "gb_free": "8", "wall": "3040"}
[2024-11-11 12:11:47,166][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
[2024-11-11 12:12:04,237][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 12:12:12,248][train_inner][INFO] - {"epoch": 3, "update": 2.867, "loss": "124.023", "nll_loss": "4.161", "total": "1335.18", "n_correct": "538.65", "ppl": "17.89", "accuracy": "40.343", "wps": "3657.2", "ups": "2.74", "wpb": "1335.2", "bsz": "54.4", "num_updates": "8400", "lr": "0.0005644", "gnorm": "34.168", "loss_scale": "256", "train_wall": "72", "gb_free": "8", "wall": "3113"}
[2024-11-11 12:13:25,385][train_inner][INFO] - {"epoch": 3, "update": 2.935, "loss": "123.539", "nll_loss": "4.136", "total": "1337.73", "n_correct": "543.98", "ppl": "17.59", "accuracy": "40.664", "wps": "3658.4", "ups": "2.73", "wpb": "1337.7", "bsz": "54.5", "num_updates": "8600", "lr": "0.0005776", "gnorm": "32.776", "loss_scale": "256", "train_wall": "72", "gb_free": "8", "wall": "3186"}
[2024-11-11 12:14:35,449][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-11-11 12:14:35,453][train][INFO] - {"epoch": 3, "train_loss": "126.028", "train_nll_loss": "4.436", "train_total": "1331.66", "train_n_correct": "492.819", "train_ppl": "21.65", "train_accuracy": "37.008", "train_wps": "3595.3", "train_ups": "2.7", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "8790", "train_lr": "0.00059014", "train_gnorm": "43.42", "train_loss_scale": "256", "train_train_wall": "1038", "train_gb_free": "8", "train_wall": "3256"}
[2024-11-11 12:14:36,204][fairseq.trainer][INFO] - begin training epoch 4
[2024-11-11 12:14:36,213][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 12:15:13,263][train_inner][INFO] - {"epoch": 4, "update": 3.003, "loss": "115.935", "nll_loss": "4.031", "total": "1325.39", "n_correct": "556.575", "ppl": "16.35", "accuracy": "41.993", "wps": "2457.4", "ups": "1.85", "wpb": "1325.4", "bsz": "56.5", "num_updates": "8800", "lr": "0.0005908", "gnorm": "29.064", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "3294"}
[2024-11-11 12:16:27,748][train_inner][INFO] - {"epoch": 4, "update": 3.072, "loss": "113.95", "nll_loss": "3.942", "total": "1336.41", "n_correct": "571.84", "ppl": "15.37", "accuracy": "42.789", "wps": "3588.7", "ups": "2.69", "wpb": "1336.4", "bsz": "57.1", "num_updates": "9000", "lr": "0.000604", "gnorm": "27.457", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "3368"}
[2024-11-11 12:17:44,364][train_inner][INFO] - {"epoch": 4, "update": 3.14, "loss": "113.959", "nll_loss": "3.899", "total": "1325.89", "n_correct": "576.405", "ppl": "14.92", "accuracy": "43.473", "wps": "3461.3", "ups": "2.61", "wpb": "1325.9", "bsz": "56.2", "num_updates": "9200", "lr": "0.0006172", "gnorm": "28.222", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "3445"}
[2024-11-11 12:19:01,888][train_inner][INFO] - {"epoch": 4, "update": 3.208, "loss": "115.902", "nll_loss": "3.865", "total": "1332.22", "n_correct": "583.285", "ppl": "14.57", "accuracy": "43.783", "wps": "3437.1", "ups": "2.58", "wpb": "1332.2", "bsz": "55.1", "num_updates": "9400", "lr": "0.0006304", "gnorm": "27.283", "loss_scale": "256", "train_wall": "76", "gb_free": "8", "wall": "3522"}
[2024-11-11 12:20:19,221][train_inner][INFO] - {"epoch": 4, "update": 3.276, "loss": "112.144", "nll_loss": "3.802", "total": "1334.08", "n_correct": "594.445", "ppl": "13.95", "accuracy": "44.559", "wps": "3450.4", "ups": "2.59", "wpb": "1334.1", "bsz": "56.4", "num_updates": "9600", "lr": "0.0006436", "gnorm": "26.652", "loss_scale": "256", "train_wall": "76", "gb_free": "8", "wall": "3600"}
[2024-11-11 12:21:35,316][train_inner][INFO] - {"epoch": 4, "update": 3.345, "loss": "111.33", "nll_loss": "3.796", "total": "1329.69", "n_correct": "593.38", "ppl": "13.89", "accuracy": "44.625", "wps": "3495", "ups": "2.63", "wpb": "1329.7", "bsz": "56.6", "num_updates": "9800", "lr": "0.0006568", "gnorm": "25.036", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "3676"}
[2024-11-11 12:22:51,175][train_inner][INFO] - {"epoch": 4, "update": 3.413, "loss": "109.538", "nll_loss": "3.709", "total": "1333.17", "n_correct": "608.345", "ppl": "13.08", "accuracy": "45.631", "wps": "3515.1", "ups": "2.64", "wpb": "1333.2", "bsz": "56.8", "num_updates": "10000", "lr": "0.00067", "gnorm": "24.066", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "3752"}
[2024-11-11 12:24:07,221][train_inner][INFO] - {"epoch": 4, "update": 3.481, "loss": "114.131", "nll_loss": "3.742", "total": "1332.42", "n_correct": "602.575", "ppl": "13.38", "accuracy": "45.224", "wps": "3504.4", "ups": "2.63", "wpb": "1332.4", "bsz": "54.8", "num_updates": "10200", "lr": "0.0006832", "gnorm": "24.565", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "3828"}
[2024-11-11 12:25:23,573][train_inner][INFO] - {"epoch": 4, "update": 3.549, "loss": "109.07", "nll_loss": "3.668", "total": "1323.14", "n_correct": "611.56", "ppl": "12.71", "accuracy": "46.22", "wps": "3466.1", "ups": "2.62", "wpb": "1323.1", "bsz": "56.1", "num_updates": "10400", "lr": "0.0006964", "gnorm": "21.963", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "3904"}
[2024-11-11 12:26:40,876][train_inner][INFO] - {"epoch": 4, "update": 3.618, "loss": "111.983", "nll_loss": "3.651", "total": "1335.4", "n_correct": "622.78", "ppl": "12.56", "accuracy": "46.636", "wps": "3455.2", "ups": "2.59", "wpb": "1335.4", "bsz": "55", "num_updates": "10600", "lr": "0.0007096", "gnorm": "22.996", "loss_scale": "512", "train_wall": "76", "gb_free": "8", "wall": "3981"}
[2024-11-11 12:27:27,554][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 12:27:57,879][train_inner][INFO] - {"epoch": 4, "update": 3.686, "loss": "108.106", "nll_loss": "3.587", "total": "1324.32", "n_correct": "626.64", "ppl": "12.02", "accuracy": "47.318", "wps": "3439.9", "ups": "2.6", "wpb": "1324.3", "bsz": "55.8", "num_updates": "10800", "lr": "0.0007228", "gnorm": "21.104", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "4058"}
[2024-11-11 12:29:16,679][train_inner][INFO] - {"epoch": 4, "update": 3.754, "loss": "107.982", "nll_loss": "3.569", "total": "1338.63", "n_correct": "635.78", "ppl": "11.87", "accuracy": "47.495", "wps": "3397.7", "ups": "2.54", "wpb": "1338.6", "bsz": "56.3", "num_updates": "11000", "lr": "0.000736", "gnorm": "21.35", "loss_scale": "256", "train_wall": "77", "gb_free": "8", "wall": "4137"}
[2024-11-11 12:30:32,732][train_inner][INFO] - {"epoch": 4, "update": 3.823, "loss": "110.835", "nll_loss": "3.581", "total": "1335.28", "n_correct": "631.945", "ppl": "11.97", "accuracy": "47.327", "wps": "3511.7", "ups": "2.63", "wpb": "1335.3", "bsz": "54.8", "num_updates": "11200", "lr": "0.0007492", "gnorm": "21.056", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "4213"}
[2024-11-11 12:31:49,366][train_inner][INFO] - {"epoch": 4, "update": 3.891, "loss": "106.263", "nll_loss": "3.519", "total": "1327.2", "n_correct": "640.645", "ppl": "11.47", "accuracy": "48.27", "wps": "3463.9", "ups": "2.61", "wpb": "1327.2", "bsz": "56.2", "num_updates": "11400", "lr": "0.0007624", "gnorm": "20.445", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "4290"}
[2024-11-11 12:33:06,006][train_inner][INFO] - {"epoch": 4, "update": 3.959, "loss": "106.903", "nll_loss": "3.496", "total": "1331.47", "n_correct": "647.155", "ppl": "11.28", "accuracy": "48.605", "wps": "3474.8", "ups": "2.61", "wpb": "1331.5", "bsz": "55.8", "num_updates": "11600", "lr": "0.0007756", "gnorm": "19.469", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "4367"}
[2024-11-11 12:33:51,087][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 12:34:22,475][valid][INFO] - {"epoch": 4, "valid_loss": "44.499", "valid_nll_loss": "2.382", "valid_total": "1356.8", "valid_n_correct": "849.7", "valid_ppl": "5.21", "valid_accuracy": "62.625", "valid_wps": "5852.3", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "11720", "valid_best_accuracy": "62.625"}
[2024-11-11 12:34:22,478][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 11720 updates
[2024-11-11 12:34:22,479][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 12:34:32,266][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 12:34:39,210][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 11720 updates, score 62.625) (writing took 16.732071293052286 seconds)
[2024-11-11 12:34:39,212][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-11-11 12:34:39,218][train][INFO] - {"epoch": 4, "train_loss": "110.792", "train_nll_loss": "3.695", "train_total": "1331.62", "train_n_correct": "611.656", "train_ppl": "12.95", "train_accuracy": "45.933", "train_wps": "3241.2", "train_ups": "2.43", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "11720", "train_lr": "0.00078352", "train_gnorm": "23.52", "train_loss_scale": "256", "train_train_wall": "1101", "train_gb_free": "8", "train_wall": "4460"}
[2024-11-11 12:34:39,820][fairseq.trainer][INFO] - begin training epoch 5
[2024-11-11 12:34:39,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 12:35:39,542][train_inner][INFO] - {"epoch": 5, "update": 4.027, "loss": "109.592", "nll_loss": "3.463", "total": "1340.88", "n_correct": "652.175", "ppl": "11.03", "accuracy": "48.638", "wps": "1746.7", "ups": "1.3", "wpb": "1340.9", "bsz": "54.4", "num_updates": "11800", "lr": "0.0007888", "gnorm": "19.557", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "4520"}
[2024-11-11 12:36:54,309][train_inner][INFO] - {"epoch": 5, "update": 4.096, "loss": "102.021", "nll_loss": "3.359", "total": "1331.73", "n_correct": "665.035", "ppl": "10.26", "accuracy": "49.937", "wps": "3562.8", "ups": "2.68", "wpb": "1331.7", "bsz": "56.9", "num_updates": "12000", "lr": "0.000802", "gnorm": "17.982", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "4595"}
[2024-11-11 12:38:09,132][train_inner][INFO] - {"epoch": 5, "update": 4.164, "loss": "107.396", "nll_loss": "3.374", "total": "1329.35", "n_correct": "664.19", "ppl": "10.37", "accuracy": "49.964", "wps": "3553.5", "ups": "2.67", "wpb": "1329.4", "bsz": "54.1", "num_updates": "12200", "lr": "0.0008152", "gnorm": "18.653", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "4670"}
[2024-11-11 12:39:23,190][train_inner][INFO] - {"epoch": 5, "update": 4.232, "loss": "103.865", "nll_loss": "3.371", "total": "1334.86", "n_correct": "667.145", "ppl": "10.35", "accuracy": "49.979", "wps": "3605.1", "ups": "2.7", "wpb": "1334.9", "bsz": "56.2", "num_updates": "12400", "lr": "0.0008284", "gnorm": "17.812", "loss_scale": "256", "train_wall": "72", "gb_free": "8", "wall": "4744"}
[2024-11-11 12:40:37,492][train_inner][INFO] - {"epoch": 5, "update": 4.3, "loss": "103.783", "nll_loss": "3.335", "total": "1323.58", "n_correct": "666.87", "ppl": "10.09", "accuracy": "50.384", "wps": "3562.9", "ups": "2.69", "wpb": "1323.6", "bsz": "55.3", "num_updates": "12600", "lr": "0.0008416", "gnorm": "17.178", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "4818"}
[2024-11-11 12:41:50,706][train_inner][INFO] - {"epoch": 5, "update": 4.368, "loss": "105.858", "nll_loss": "3.33", "total": "1329.77", "n_correct": "672.195", "ppl": "10.06", "accuracy": "50.55", "wps": "3632.7", "ups": "2.73", "wpb": "1329.8", "bsz": "54.5", "num_updates": "12800", "lr": "0.0008548", "gnorm": "16.984", "loss_scale": "512", "train_wall": "72", "gb_free": "8", "wall": "4891"}
[2024-11-11 12:43:07,630][train_inner][INFO] - {"epoch": 5, "update": 4.437, "loss": "102.208", "nll_loss": "3.31", "total": "1336.77", "n_correct": "678.21", "ppl": "9.92", "accuracy": "50.735", "wps": "3475.9", "ups": "2.6", "wpb": "1336.8", "bsz": "56.5", "num_updates": "13000", "lr": "0.000868", "gnorm": "16.049", "loss_scale": "512", "train_wall": "75", "gb_free": "8", "wall": "4968"}
[2024-11-11 12:44:22,092][train_inner][INFO] - {"epoch": 5, "update": 4.505, "loss": "98.979", "nll_loss": "3.278", "total": "1328.33", "n_correct": "679.525", "ppl": "9.7", "accuracy": "51.156", "wps": "3568", "ups": "2.69", "wpb": "1328.3", "bsz": "57.6", "num_updates": "13200", "lr": "0.0008812", "gnorm": "15.67", "loss_scale": "512", "train_wall": "73", "gb_free": "8", "wall": "5043"}
[2024-11-11 12:45:48,491][train_inner][INFO] - {"epoch": 5, "update": 4.573, "loss": "102.394", "nll_loss": "3.273", "total": "1327", "n_correct": "679.78", "ppl": "9.67", "accuracy": "51.227", "wps": "3072", "ups": "2.31", "wpb": "1327", "bsz": "55.5", "num_updates": "13400", "lr": "0.0008944", "gnorm": "15.522", "loss_scale": "512", "train_wall": "84", "gb_free": "8", "wall": "5129"}
[2024-11-11 12:47:17,476][train_inner][INFO] - {"epoch": 5, "update": 4.641, "loss": "99.924", "nll_loss": "3.277", "total": "1319.78", "n_correct": "676.97", "ppl": "9.7", "accuracy": "51.294", "wps": "2966.4", "ups": "2.25", "wpb": "1319.8", "bsz": "56.6", "num_updates": "13600", "lr": "0.0009076", "gnorm": "15.149", "loss_scale": "512", "train_wall": "87", "gb_free": "8", "wall": "5218"}
[2024-11-11 12:48:45,389][train_inner][INFO] - {"epoch": 5, "update": 4.71, "loss": "102.038", "nll_loss": "3.266", "total": "1331.51", "n_correct": "683.845", "ppl": "9.62", "accuracy": "51.359", "wps": "3029.3", "ups": "2.28", "wpb": "1331.5", "bsz": "55.8", "num_updates": "13800", "lr": "0.0009208", "gnorm": "15.051", "loss_scale": "512", "train_wall": "86", "gb_free": "8", "wall": "5306"}
[2024-11-11 12:50:19,055][train_inner][INFO] - {"epoch": 5, "update": 4.778, "loss": "98.641", "nll_loss": "3.226", "total": "1345.84", "n_correct": "699.41", "ppl": "9.36", "accuracy": "51.968", "wps": "2874", "ups": "2.14", "wpb": "1345.8", "bsz": "57.9", "num_updates": "14000", "lr": "0.000934", "gnorm": "14.169", "loss_scale": "512", "train_wall": "91", "gb_free": "8", "wall": "5400"}
[2024-11-11 12:51:56,908][train_inner][INFO] - {"epoch": 5, "update": 4.846, "loss": "104.683", "nll_loss": "3.261", "total": "1336.02", "n_correct": "686.285", "ppl": "9.58", "accuracy": "51.368", "wps": "2730.8", "ups": "2.04", "wpb": "1336", "bsz": "54.5", "num_updates": "14200", "lr": "0.0009472", "gnorm": "15.163", "loss_scale": "512", "train_wall": "96", "gb_free": "8", "wall": "5497"}
[2024-11-11 12:53:30,261][train_inner][INFO] - {"epoch": 5, "update": 4.914, "loss": "100.525", "nll_loss": "3.232", "total": "1333.97", "n_correct": "691.13", "ppl": "9.39", "accuracy": "51.81", "wps": "2858.3", "ups": "2.14", "wpb": "1334", "bsz": "56.4", "num_updates": "14400", "lr": "0.0009604", "gnorm": "14.27", "loss_scale": "512", "train_wall": "91", "gb_free": "8", "wall": "5591"}
[2024-11-11 12:54:48,513][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 12:55:02,376][train_inner][INFO] - {"epoch": 5, "update": 4.983, "loss": "104.163", "nll_loss": "3.249", "total": "1333.5", "n_correct": "688.165", "ppl": "9.51", "accuracy": "51.606", "wps": "2895.4", "ups": "2.17", "wpb": "1333.5", "bsz": "54.6", "num_updates": "14600", "lr": "0.0009736", "gnorm": "14.599", "loss_scale": "256", "train_wall": "90", "gb_free": "8", "wall": "5683"}
[2024-11-11 12:55:22,151][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-11-11 12:55:22,155][train][INFO] - {"epoch": 5, "train_loss": "102.585", "train_nll_loss": "3.296", "train_total": "1331.61", "train_n_correct": "678.354", "train_ppl": "9.82", "train_accuracy": "50.942", "train_wps": "3139", "train_ups": "2.36", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "14650", "train_lr": "0.0009769", "train_gnorm": "16.07", "train_loss_scale": "256", "train_train_wall": "1186", "train_gb_free": "8", "train_wall": "5703"}
[2024-11-11 12:55:23,257][fairseq.trainer][INFO] - begin training epoch 6
[2024-11-11 12:55:23,258][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 12:57:16,974][train_inner][INFO] - {"epoch": 6, "update": 5.051, "loss": "99.244", "nll_loss": "3.127", "total": "1329.34", "n_correct": "703.48", "ppl": "8.73", "accuracy": "52.92", "wps": "1975.3", "ups": "1.49", "wpb": "1329.3", "bsz": "55.7", "num_updates": "14800", "lr": "0.0009868", "gnorm": "13.778", "loss_scale": "256", "train_wall": "95", "gb_free": "8", "wall": "5818"}
[2024-11-11 12:58:51,617][train_inner][INFO] - {"epoch": 6, "update": 5.119, "loss": "96.248", "nll_loss": "3.097", "total": "1330.52", "n_correct": "711.555", "ppl": "8.56", "accuracy": "53.479", "wps": "2811.8", "ups": "2.11", "wpb": "1330.5", "bsz": "57.1", "num_updates": "15000", "lr": "0.001", "gnorm": "13.501", "loss_scale": "256", "train_wall": "92", "gb_free": "8", "wall": "5912"}
[2024-11-11 13:00:32,202][train_inner][INFO] - {"epoch": 6, "update": 5.188, "loss": "98.711", "nll_loss": "3.091", "total": "1336.54", "n_correct": "714.44", "ppl": "8.52", "accuracy": "53.454", "wps": "2657.6", "ups": "1.99", "wpb": "1336.5", "bsz": "55.9", "num_updates": "15200", "lr": "0.000980227", "gnorm": "13.01", "loss_scale": "256", "train_wall": "98", "gb_free": "8", "wall": "6013"}
[2024-11-11 13:02:07,665][train_inner][INFO] - {"epoch": 6, "update": 5.256, "loss": "97.996", "nll_loss": "3.082", "total": "1326.98", "n_correct": "712.31", "ppl": "8.47", "accuracy": "53.679", "wps": "2780.3", "ups": "2.1", "wpb": "1327", "bsz": "55.8", "num_updates": "15400", "lr": "0.000960844", "gnorm": "12.924", "loss_scale": "256", "train_wall": "93", "gb_free": "8", "wall": "6108"}
[2024-11-11 13:03:42,766][train_inner][INFO] - {"epoch": 6, "update": 5.324, "loss": "98.212", "nll_loss": "3.05", "total": "1330.37", "n_correct": "719.365", "ppl": "8.28", "accuracy": "54.073", "wps": "2798.5", "ups": "2.1", "wpb": "1330.4", "bsz": "55.4", "num_updates": "15600", "lr": "0.000941845", "gnorm": "12.887", "loss_scale": "256", "train_wall": "93", "gb_free": "8", "wall": "6203"}
[2024-11-11 13:04:57,949][train_inner][INFO] - {"epoch": 6, "update": 5.392, "loss": "95.634", "nll_loss": "3.035", "total": "1335.92", "n_correct": "726.24", "ppl": "8.2", "accuracy": "54.363", "wps": "3554", "ups": "2.66", "wpb": "1335.9", "bsz": "57", "num_updates": "15800", "lr": "0.000923221", "gnorm": "12.243", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "6278"}
[2024-11-11 13:06:11,976][train_inner][INFO] - {"epoch": 6, "update": 5.461, "loss": "98.272", "nll_loss": "3.062", "total": "1325.44", "n_correct": "715.055", "ppl": "8.35", "accuracy": "53.948", "wps": "3581.1", "ups": "2.7", "wpb": "1325.4", "bsz": "55.3", "num_updates": "16000", "lr": "0.000904966", "gnorm": "12.405", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "6353"}
[2024-11-11 13:07:24,943][train_inner][INFO] - {"epoch": 6, "update": 5.529, "loss": "100.814", "nll_loss": "3.057", "total": "1329.31", "n_correct": "718.115", "ppl": "8.32", "accuracy": "54.022", "wps": "3643.8", "ups": "2.74", "wpb": "1329.3", "bsz": "54", "num_updates": "16200", "lr": "0.000887072", "gnorm": "12.82", "loss_scale": "256", "train_wall": "72", "gb_free": "8", "wall": "6425"}
[2024-11-11 13:08:35,664][train_inner][INFO] - {"epoch": 6, "update": 5.597, "loss": "94.03", "nll_loss": "2.992", "total": "1332.18", "n_correct": "731.35", "ppl": "7.96", "accuracy": "54.899", "wps": "3767.7", "ups": "2.83", "wpb": "1332.2", "bsz": "57.2", "num_updates": "16400", "lr": "0.000869531", "gnorm": "11.717", "loss_scale": "256", "train_wall": "70", "gb_free": "8", "wall": "6496"}
[2024-11-11 13:09:47,742][train_inner][INFO] - {"epoch": 6, "update": 5.665, "loss": "98.034", "nll_loss": "3.002", "total": "1334.48", "n_correct": "730.345", "ppl": "8.01", "accuracy": "54.729", "wps": "3703.2", "ups": "2.78", "wpb": "1334.5", "bsz": "55.1", "num_updates": "16600", "lr": "0.000852338", "gnorm": "12.147", "loss_scale": "256", "train_wall": "71", "gb_free": "8", "wall": "6568"}
[2024-11-11 13:10:58,560][train_inner][INFO] - {"epoch": 6, "update": 5.734, "loss": "93.967", "nll_loss": "2.961", "total": "1329.24", "n_correct": "735.27", "ppl": "7.79", "accuracy": "55.315", "wps": "3754.3", "ups": "2.82", "wpb": "1329.2", "bsz": "56.8", "num_updates": "16800", "lr": "0.000835484", "gnorm": "11.446", "loss_scale": "512", "train_wall": "70", "gb_free": "8", "wall": "6639"}
[2024-11-11 13:12:09,194][train_inner][INFO] - {"epoch": 6, "update": 5.802, "loss": "93.786", "nll_loss": "2.945", "total": "1333.61", "n_correct": "740.91", "ppl": "7.7", "accuracy": "55.557", "wps": "3776.2", "ups": "2.83", "wpb": "1333.6", "bsz": "56.9", "num_updates": "17000", "lr": "0.000818964", "gnorm": "11.321", "loss_scale": "512", "train_wall": "69", "gb_free": "8", "wall": "6710"}
[2024-11-11 13:13:19,723][train_inner][INFO] - {"epoch": 6, "update": 5.87, "loss": "96.122", "nll_loss": "2.95", "total": "1329.91", "n_correct": "737.08", "ppl": "7.73", "accuracy": "55.423", "wps": "3771.5", "ups": "2.84", "wpb": "1329.9", "bsz": "55.4", "num_updates": "17200", "lr": "0.00080277", "gnorm": "11.272", "loss_scale": "512", "train_wall": "69", "gb_free": "8", "wall": "6780"}
[2024-11-11 13:14:33,348][train_inner][INFO] - {"epoch": 6, "update": 5.938, "loss": "97.152", "nll_loss": "2.954", "total": "1331.4", "n_correct": "739.27", "ppl": "7.75", "accuracy": "55.526", "wps": "3616.9", "ups": "2.72", "wpb": "1331.4", "bsz": "54.9", "num_updates": "17400", "lr": "0.000786896", "gnorm": "11.729", "loss_scale": "512", "train_wall": "72", "gb_free": "8", "wall": "6854"}
[2024-11-11 13:15:28,511][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 13:15:35,676][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 13:16:02,809][valid][INFO] - {"epoch": 6, "valid_loss": "40.287", "valid_nll_loss": "2.001", "valid_total": "1356.8", "valid_n_correct": "922.7", "valid_ppl": "4", "valid_accuracy": "68.006", "valid_wps": "5966.2", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "17580", "valid_best_accuracy": "68.006"}
[2024-11-11 13:16:02,811][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 17580 updates
[2024-11-11 13:16:02,811][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 13:16:11,541][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 13:16:17,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 17580 updates, score 68.006) (writing took 14.733776212204248 seconds)
[2024-11-11 13:16:17,545][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-11-11 13:16:17,548][train][INFO] - {"epoch": 6, "train_loss": "96.841", "train_nll_loss": "3.019", "train_total": "1331.67", "train_n_correct": "725.959", "train_ppl": "8.11", "train_accuracy": "54.515", "train_wps": "3108", "train_ups": "2.33", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "17580", "train_lr": "0.000772879", "train_gnorm": "12.287", "train_loss_scale": "256", "train_train_wall": "1153", "train_gb_free": "8", "train_wall": "6958"}
[2024-11-11 13:16:17,943][fairseq.trainer][INFO] - begin training epoch 7
[2024-11-11 13:16:17,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 13:16:49,910][train_inner][INFO] - {"epoch": 7, "update": 6.007, "loss": "92.717", "nll_loss": "2.9", "total": "1336.36", "n_correct": "750.625", "ppl": "7.46", "accuracy": "56.169", "wps": "1957.2", "ups": "1.46", "wpb": "1336.4", "bsz": "57.1", "num_updates": "17600", "lr": "0.000771337", "gnorm": "11.068", "loss_scale": "256", "train_wall": "69", "gb_free": "8", "wall": "6990"}
[2024-11-11 13:18:01,646][train_inner][INFO] - {"epoch": 7, "update": 6.075, "loss": "91.677", "nll_loss": "2.782", "total": "1318.97", "n_correct": "757.58", "ppl": "6.88", "accuracy": "57.437", "wps": "3677.5", "ups": "2.79", "wpb": "1319", "bsz": "55.6", "num_updates": "17800", "lr": "0.000756085", "gnorm": "11.438", "loss_scale": "256", "train_wall": "70", "gb_free": "8", "wall": "7062"}
[2024-11-11 13:19:13,600][train_inner][INFO] - {"epoch": 7, "update": 6.143, "loss": "94.777", "nll_loss": "2.785", "total": "1334.2", "n_correct": "768.02", "ppl": "6.89", "accuracy": "57.564", "wps": "3709", "ups": "2.78", "wpb": "1334.2", "bsz": "54.4", "num_updates": "18000", "lr": "0.000741134", "gnorm": "11.533", "loss_scale": "256", "train_wall": "71", "gb_free": "8", "wall": "7134"}
[2024-11-11 13:20:25,548][train_inner][INFO] - {"epoch": 7, "update": 6.212, "loss": "92.046", "nll_loss": "2.784", "total": "1326.91", "n_correct": "761.56", "ppl": "6.89", "accuracy": "57.393", "wps": "3688.8", "ups": "2.78", "wpb": "1326.9", "bsz": "55.7", "num_updates": "18200", "lr": "0.00072648", "gnorm": "11.174", "loss_scale": "256", "train_wall": "71", "gb_free": "8", "wall": "7206"}
[2024-11-11 13:21:44,647][train_inner][INFO] - {"epoch": 7, "update": 6.28, "loss": "92.376", "nll_loss": "2.766", "total": "1337.49", "n_correct": "772.33", "ppl": "6.8", "accuracy": "57.745", "wps": "3381.9", "ups": "2.53", "wpb": "1337.5", "bsz": "55.7", "num_updates": "18400", "lr": "0.000712115", "gnorm": "11.182", "loss_scale": "256", "train_wall": "77", "gb_free": "8", "wall": "7285"}
[2024-11-11 13:23:39,242][train_inner][INFO] - {"epoch": 7, "update": 6.348, "loss": "90.911", "nll_loss": "2.771", "total": "1335.31", "n_correct": "772.245", "ppl": "6.82", "accuracy": "57.833", "wps": "2330.9", "ups": "1.75", "wpb": "1335.3", "bsz": "56.5", "num_updates": "18600", "lr": "0.000698034", "gnorm": "11.132", "loss_scale": "256", "train_wall": "111", "gb_free": "8", "wall": "7400"}
[2024-11-11 13:25:41,282][train_inner][INFO] - {"epoch": 7, "update": 6.416, "loss": "91.375", "nll_loss": "2.747", "total": "1335.72", "n_correct": "775.455", "ppl": "6.71", "accuracy": "58.055", "wps": "2189.6", "ups": "1.64", "wpb": "1335.7", "bsz": "56", "num_updates": "18800", "lr": "0.000684231", "gnorm": "10.974", "loss_scale": "256", "train_wall": "118", "gb_free": "8", "wall": "7522"}
[2024-11-11 13:27:43,241][train_inner][INFO] - {"epoch": 7, "update": 6.484, "loss": "91.04", "nll_loss": "2.766", "total": "1327.24", "n_correct": "767.59", "ppl": "6.8", "accuracy": "57.834", "wps": "2176.7", "ups": "1.64", "wpb": "1327.2", "bsz": "56.1", "num_updates": "19000", "lr": "0.000670702", "gnorm": "11.016", "loss_scale": "256", "train_wall": "118", "gb_free": "8", "wall": "7644"}
[2024-11-11 13:29:41,175][train_inner][INFO] - {"epoch": 7, "update": 6.553, "loss": "95.379", "nll_loss": "2.752", "total": "1331.73", "n_correct": "772.84", "ppl": "6.74", "accuracy": "58.033", "wps": "2258.5", "ups": "1.7", "wpb": "1331.7", "bsz": "53.5", "num_updates": "19200", "lr": "0.00065744", "gnorm": "11.423", "loss_scale": "256", "train_wall": "115", "gb_free": "8", "wall": "7762"}
[2024-11-11 13:31:31,181][train_inner][INFO] - {"epoch": 7, "update": 6.621, "loss": "93.649", "nll_loss": "2.744", "total": "1330.41", "n_correct": "773.65", "ppl": "6.7", "accuracy": "58.151", "wps": "2418.9", "ups": "1.82", "wpb": "1330.4", "bsz": "54.3", "num_updates": "19400", "lr": "0.00064444", "gnorm": "11.161", "loss_scale": "256", "train_wall": "107", "gb_free": "8", "wall": "7872"}
[2024-11-11 13:33:22,059][train_inner][INFO] - {"epoch": 7, "update": 6.689, "loss": "90.584", "nll_loss": "2.718", "total": "1335.51", "n_correct": "779.985", "ppl": "6.58", "accuracy": "58.404", "wps": "2409.1", "ups": "1.8", "wpb": "1335.5", "bsz": "56.1", "num_updates": "19600", "lr": "0.000631697", "gnorm": "10.936", "loss_scale": "256", "train_wall": "108", "gb_free": "8", "wall": "7983"}
[2024-11-11 13:35:06,712][train_inner][INFO] - {"epoch": 7, "update": 6.757, "loss": "86.979", "nll_loss": "2.717", "total": "1326.56", "n_correct": "775.555", "ppl": "6.58", "accuracy": "58.464", "wps": "2535.3", "ups": "1.91", "wpb": "1326.6", "bsz": "58", "num_updates": "19800", "lr": "0.000619206", "gnorm": "10.546", "loss_scale": "512", "train_wall": "102", "gb_free": "8", "wall": "8087"}
[2024-11-11 13:36:49,742][train_inner][INFO] - {"epoch": 7, "update": 6.826, "loss": "91.892", "nll_loss": "2.694", "total": "1326.53", "n_correct": "779.8", "ppl": "6.47", "accuracy": "58.785", "wps": "2575.3", "ups": "1.94", "wpb": "1326.5", "bsz": "54.6", "num_updates": "20000", "lr": "0.000606962", "gnorm": "11.123", "loss_scale": "512", "train_wall": "100", "gb_free": "8", "wall": "8190"}
[2024-11-11 13:38:20,869][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 13:38:27,823][train_inner][INFO] - {"epoch": 7, "update": 6.894, "loss": "85.463", "nll_loss": "2.685", "total": "1338.74", "n_correct": "788.9", "ppl": "6.43", "accuracy": "58.929", "wps": "2730", "ups": "2.04", "wpb": "1338.7", "bsz": "59.1", "num_updates": "20200", "lr": "0.000594961", "gnorm": "10.045", "loss_scale": "256", "train_wall": "95", "gb_free": "8", "wall": "8288"}
[2024-11-11 13:39:57,607][train_inner][INFO] - {"epoch": 7, "update": 6.962, "loss": "89.521", "nll_loss": "2.703", "total": "1334.81", "n_correct": "784.375", "ppl": "6.51", "accuracy": "58.763", "wps": "2973.5", "ups": "2.23", "wpb": "1334.8", "bsz": "56.5", "num_updates": "20400", "lr": "0.000583196", "gnorm": "10.617", "loss_scale": "256", "train_wall": "88", "gb_free": "8", "wall": "8378"}
[2024-11-11 13:40:39,931][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-11-11 13:40:39,936][train][INFO] - {"epoch": 7, "train_loss": "91.106", "train_nll_loss": "2.742", "train_total": "1331.64", "train_n_correct": "774.133", "train_ppl": "6.69", "train_accuracy": "58.134", "train_wps": "2668", "train_ups": "2", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "20510", "train_lr": "0.000576825", "train_gnorm": "10.996", "train_loss_scale": "256", "train_train_wall": "1400", "train_gb_free": "8", "train_wall": "8420"}
[2024-11-11 13:40:40,594][fairseq.trainer][INFO] - begin training epoch 8
[2024-11-11 13:40:40,595][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 13:41:44,722][train_inner][INFO] - {"epoch": 8, "update": 7.031, "loss": "88.901", "nll_loss": "2.618", "total": "1329.84", "n_correct": "795.91", "ppl": "6.14", "accuracy": "59.85", "wps": "2483.1", "ups": "1.87", "wpb": "1329.8", "bsz": "55.6", "num_updates": "20600", "lr": "0.000571664", "gnorm": "10.497", "loss_scale": "256", "train_wall": "81", "gb_free": "8", "wall": "8485"}
[2024-11-11 13:42:59,531][train_inner][INFO] - {"epoch": 8, "update": 7.099, "loss": "85.869", "nll_loss": "2.552", "total": "1329.55", "n_correct": "805.49", "ppl": "5.86", "accuracy": "60.584", "wps": "3554.8", "ups": "2.67", "wpb": "1329.5", "bsz": "56.7", "num_updates": "20800", "lr": "0.000560361", "gnorm": "10.485", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "8560"}
[2024-11-11 13:44:14,809][train_inner][INFO] - {"epoch": 8, "update": 7.167, "loss": "86.87", "nll_loss": "2.541", "total": "1337.92", "n_correct": "812.785", "ppl": "5.82", "accuracy": "60.75", "wps": "3554.8", "ups": "2.66", "wpb": "1337.9", "bsz": "56.3", "num_updates": "21000", "lr": "0.00054928", "gnorm": "10.571", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "8635"}
[2024-11-11 13:45:29,404][train_inner][INFO] - {"epoch": 8, "update": 7.235, "loss": "87.343", "nll_loss": "2.563", "total": "1323.09", "n_correct": "800.15", "ppl": "5.91", "accuracy": "60.476", "wps": "3547.6", "ups": "2.68", "wpb": "1323.1", "bsz": "55.6", "num_updates": "21200", "lr": "0.000538419", "gnorm": "10.477", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "8710"}
[2024-11-11 13:46:44,052][train_inner][INFO] - {"epoch": 8, "update": 7.304, "loss": "87.998", "nll_loss": "2.552", "total": "1333.21", "n_correct": "807.965", "ppl": "5.86", "accuracy": "60.603", "wps": "3572.2", "ups": "2.68", "wpb": "1333.2", "bsz": "55.5", "num_updates": "21400", "lr": "0.000527773", "gnorm": "10.695", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "8785"}
[2024-11-11 13:47:59,246][train_inner][INFO] - {"epoch": 8, "update": 7.372, "loss": "88.317", "nll_loss": "2.574", "total": "1340.05", "n_correct": "808.41", "ppl": "5.96", "accuracy": "60.327", "wps": "3564.4", "ups": "2.66", "wpb": "1340", "bsz": "55.8", "num_updates": "21600", "lr": "0.000517337", "gnorm": "10.762", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "8860"}
[2024-11-11 13:49:13,313][train_inner][INFO] - {"epoch": 8, "update": 7.44, "loss": "85.659", "nll_loss": "2.561", "total": "1327.82", "n_correct": "802.365", "ppl": "5.9", "accuracy": "60.427", "wps": "3585.7", "ups": "2.7", "wpb": "1327.8", "bsz": "56.9", "num_updates": "21800", "lr": "0.000507107", "gnorm": "10.621", "loss_scale": "256", "train_wall": "73", "gb_free": "8", "wall": "8934"}
[2024-11-11 13:50:28,040][train_inner][INFO] - {"epoch": 8, "update": 7.508, "loss": "89.696", "nll_loss": "2.565", "total": "1327.47", "n_correct": "801.355", "ppl": "5.92", "accuracy": "60.367", "wps": "3553", "ups": "2.68", "wpb": "1327.5", "bsz": "54.3", "num_updates": "22000", "lr": "0.00049708", "gnorm": "10.82", "loss_scale": "256", "train_wall": "74", "gb_free": "8", "wall": "9009"}
[2024-11-11 13:51:44,211][train_inner][INFO] - {"epoch": 8, "update": 7.577, "loss": "86.993", "nll_loss": "2.547", "total": "1330.38", "n_correct": "809.4", "ppl": "5.84", "accuracy": "60.84", "wps": "3493.4", "ups": "2.63", "wpb": "1330.4", "bsz": "55.9", "num_updates": "22200", "lr": "0.000487251", "gnorm": "10.566", "loss_scale": "256", "train_wall": "75", "gb_free": "8", "wall": "9085"}
[2024-11-11 13:53:00,515][train_inner][INFO] - {"epoch": 8, "update": 7.645, "loss": "87.649", "nll_loss": "2.531", "total": "1329.07", "n_correct": "811.4", "ppl": "5.78", "accuracy": "61.05", "wps": "3483.8", "ups": "2.62", "wpb": "1329.1", "bsz": "55.2", "num_updates": "22400", "lr": "0.000477616", "gnorm": "10.807", "loss_scale": "512", "train_wall": "75", "gb_free": "8", "wall": "9161"}
[2024-11-11 13:53:39,156][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
[2024-11-11 13:53:39,598][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2024-11-11 13:53:39,963][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-11-11 13:54:25,913][train_inner][INFO] - {"epoch": 8, "update": 7.714, "loss": "85.167", "nll_loss": "2.496", "total": "1327.89", "n_correct": "815.11", "ppl": "5.64", "accuracy": "61.384", "wps": "3110", "ups": "2.34", "wpb": "1327.9", "bsz": "56.3", "num_updates": "22600", "lr": "0.000468172", "gnorm": "18.43", "loss_scale": "64", "train_wall": "84", "gb_free": "6.1", "wall": "9246"}
[2024-11-11 13:55:53,848][train_inner][INFO] - {"epoch": 8, "update": 7.782, "loss": "82.008", "nll_loss": "2.386", "total": "1331.05", "n_correct": "839.135", "ppl": "5.23", "accuracy": "63.043", "wps": "3027.5", "ups": "2.27", "wpb": "1331", "bsz": "57.1", "num_updates": "22800", "lr": "0.000458915", "gnorm": "23.069", "loss_scale": "64", "train_wall": "87", "gb_free": "6.2", "wall": "9334"}
[2024-11-11 13:57:22,514][train_inner][INFO] - {"epoch": 8, "update": 7.851, "loss": "82.877", "nll_loss": "2.349", "total": "1332.93", "n_correct": "846.705", "ppl": "5.09", "accuracy": "63.522", "wps": "3006.8", "ups": "2.26", "wpb": "1332.9", "bsz": "56", "num_updates": "23000", "lr": "0.000449841", "gnorm": "22.494", "loss_scale": "64", "train_wall": "87", "gb_free": "6.1", "wall": "9423"}
[2024-11-11 13:57:44,188][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-11-11 13:58:49,354][train_inner][INFO] - {"epoch": 8, "update": 7.919, "loss": "84.328", "nll_loss": "2.363", "total": "1329.72", "n_correct": "842.885", "ppl": "5.15", "accuracy": "63.388", "wps": "3063.3", "ups": "2.3", "wpb": "1329.7", "bsz": "55.1", "num_updates": "23200", "lr": "0.000440946", "gnorm": "22.406", "loss_scale": "32", "train_wall": "85", "gb_free": "6", "wall": "9510"}
[2024-11-11 14:00:15,430][train_inner][INFO] - {"epoch": 8, "update": 7.987, "loss": "82.724", "nll_loss": "2.303", "total": "1341.61", "n_correct": "861.48", "ppl": "4.94", "accuracy": "64.212", "wps": "3117.5", "ups": "2.32", "wpb": "1341.6", "bsz": "55.8", "num_updates": "23400", "lr": "0.000432227", "gnorm": "21.357", "loss_scale": "32", "train_wall": "85", "gb_free": "5.8", "wall": "9596"}
[2024-11-11 14:00:31,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/root/miniconda3/envs/avhubert/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [64, 1, 5, 7, 7], strides() = [245, 1, 49, 7, 1]
bucket_view.sizes() = [64, 1, 5, 7, 7], strides() = [245, 245, 49, 7, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2024-11-11 14:00:57,297][valid][INFO] - {"epoch": 8, "valid_loss": "36.666", "valid_nll_loss": "1.675", "valid_total": "1356.8", "valid_n_correct": "986.3", "valid_ppl": "3.19", "valid_accuracy": "72.693", "valid_wps": "6327.8", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "23437", "valid_best_accuracy": "72.693"}
[2024-11-11 14:00:57,300][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 23437 updates
[2024-11-11 14:00:57,301][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 14:01:07,049][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 14:01:13,326][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 23437 updates, score 72.693) (writing took 16.02613591356203 seconds)
[2024-11-11 14:01:13,327][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-11-11 14:01:13,330][train][INFO] - {"epoch": 8, "train_loss": "85.972", "train_nll_loss": "2.49", "train_total": "1331.62", "train_n_correct": "819.273", "train_ppl": "5.62", "train_accuracy": "61.524", "train_wps": "3160.1", "train_ups": "2.37", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "23437", "train_lr": "0.000430633", "train_gnorm": "14.5", "train_loss_scale": "32", "train_train_wall": "1148", "train_gb_free": "5.9", "train_wall": "9654"}
[2024-11-11 14:01:13,836][fairseq.trainer][INFO] - begin training epoch 9
[2024-11-11 14:01:13,836][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 14:03:17,423][train_inner][INFO] - {"epoch": 9, "update": 8.056, "loss": "78.795", "nll_loss": "2.177", "total": "1336.83", "n_correct": "882.705", "ppl": "4.52", "accuracy": "66.03", "wps": "1469.1", "ups": "1.1", "wpb": "1336.8", "bsz": "56.6", "num_updates": "23600", "lr": "0.00042368", "gnorm": "20.998", "loss_scale": "32", "train_wall": "105", "gb_free": "6.1", "wall": "9778"}
[2024-11-11 14:05:02,807][train_inner][INFO] - {"epoch": 9, "update": 8.124, "loss": "80.01", "nll_loss": "2.15", "total": "1335.19", "n_correct": "884.98", "ppl": "4.44", "accuracy": "66.281", "wps": "2534.2", "ups": "1.9", "wpb": "1335.2", "bsz": "55.3", "num_updates": "23800", "lr": "0.000415302", "gnorm": "21.521", "loss_scale": "32", "train_wall": "104", "gb_free": "6.3", "wall": "9883"}
[2024-11-11 14:06:38,727][train_inner][INFO] - {"epoch": 9, "update": 8.192, "loss": "76.264", "nll_loss": "2.105", "total": "1338.86", "n_correct": "896.79", "ppl": "4.3", "accuracy": "66.982", "wps": "2791.9", "ups": "2.09", "wpb": "1338.9", "bsz": "57.5", "num_updates": "24000", "lr": "0.000407091", "gnorm": "20.723", "loss_scale": "32", "train_wall": "94", "gb_free": "6.1", "wall": "9979"}
[2024-11-11 14:08:19,688][train_inner][INFO] - {"epoch": 9, "update": 8.26, "loss": "78.152", "nll_loss": "2.124", "total": "1335.95", "n_correct": "891.37", "ppl": "4.36", "accuracy": "66.722", "wps": "2646.6", "ups": "1.98", "wpb": "1336", "bsz": "56.2", "num_updates": "24200", "lr": "0.000399041", "gnorm": "20.944", "loss_scale": "32", "train_wall": "99", "gb_free": "6.5", "wall": "10080"}
[2024-11-11 14:10:04,538][train_inner][INFO] - {"epoch": 9, "update": 8.329, "loss": "81.685", "nll_loss": "2.136", "total": "1328.17", "n_correct": "885.17", "ppl": "4.4", "accuracy": "66.646", "wps": "2533.6", "ups": "1.91", "wpb": "1328.2", "bsz": "53.7", "num_updates": "24400", "lr": "0.000391151", "gnorm": "21.671", "loss_scale": "32", "train_wall": "103", "gb_free": "6.2", "wall": "10185"}
[2024-11-11 14:11:28,389][train_inner][INFO] - {"epoch": 9, "update": 8.397, "loss": "76.766", "nll_loss": "2.092", "total": "1328.27", "n_correct": "894.335", "ppl": "4.26", "accuracy": "67.331", "wps": "3168.4", "ups": "2.39", "wpb": "1328.3", "bsz": "56.4", "num_updates": "24600", "lr": "0.000383416", "gnorm": "20.13", "loss_scale": "32", "train_wall": "83", "gb_free": "6.1", "wall": "10269"}
[2024-11-11 14:12:52,310][train_inner][INFO] - {"epoch": 9, "update": 8.465, "loss": "79.725", "nll_loss": "2.105", "total": "1322.72", "n_correct": "888.13", "ppl": "4.3", "accuracy": "67.144", "wps": "3152.5", "ups": "2.38", "wpb": "1322.7", "bsz": "54.3", "num_updates": "24800", "lr": "0.000375835", "gnorm": "20.991", "loss_scale": "32", "train_wall": "83", "gb_free": "6.2", "wall": "10353"}
[2024-11-11 14:14:16,431][train_inner][INFO] - {"epoch": 9, "update": 8.533, "loss": "76.109", "nll_loss": "2.083", "total": "1339.08", "n_correct": "903.17", "ppl": "4.24", "accuracy": "67.447", "wps": "3183.8", "ups": "2.38", "wpb": "1339.1", "bsz": "57.2", "num_updates": "25000", "lr": "0.000368403", "gnorm": "20.23", "loss_scale": "32", "train_wall": "83", "gb_free": "6.5", "wall": "10437"}
[2024-11-11 14:15:40,022][train_inner][INFO] - {"epoch": 9, "update": 8.602, "loss": "77.411", "nll_loss": "2.076", "total": "1327.56", "n_correct": "897.005", "ppl": "4.22", "accuracy": "67.568", "wps": "3176.6", "ups": "2.39", "wpb": "1327.6", "bsz": "55.7", "num_updates": "25200", "lr": "0.000361119", "gnorm": "19.801", "loss_scale": "64", "train_wall": "82", "gb_free": "5.8", "wall": "10521"}
[2024-11-11 14:17:04,146][train_inner][INFO] - {"epoch": 9, "update": 8.67, "loss": "77.189", "nll_loss": "2.08", "total": "1342.45", "n_correct": "905.69", "ppl": "4.23", "accuracy": "67.465", "wps": "3191.8", "ups": "2.38", "wpb": "1342.5", "bsz": "56.5", "num_updates": "25400", "lr": "0.000353978", "gnorm": "20.355", "loss_scale": "64", "train_wall": "83", "gb_free": "6.6", "wall": "10605"}
[2024-11-11 14:18:30,113][train_inner][INFO] - {"epoch": 9, "update": 8.738, "loss": "76.259", "nll_loss": "2.069", "total": "1338.89", "n_correct": "906.03", "ppl": "4.2", "accuracy": "67.67", "wps": "3115.1", "ups": "2.33", "wpb": "1338.9", "bsz": "56.9", "num_updates": "25600", "lr": "0.000346979", "gnorm": "19.741", "loss_scale": "64", "train_wall": "85", "gb_free": "6.4", "wall": "10691"}
[2024-11-11 14:19:55,290][train_inner][INFO] - {"epoch": 9, "update": 8.806, "loss": "76.328", "nll_loss": "2.078", "total": "1322.54", "n_correct": "892.77", "ppl": "4.22", "accuracy": "67.504", "wps": "3105.5", "ups": "2.35", "wpb": "1322.5", "bsz": "56.2", "num_updates": "25800", "lr": "0.000340118", "gnorm": "19.878", "loss_scale": "64", "train_wall": "84", "gb_free": "6.2", "wall": "10776"}
[2024-11-11 14:21:20,090][train_inner][INFO] - {"epoch": 9, "update": 8.874, "loss": "77.831", "nll_loss": "2.037", "total": "1332.84", "n_correct": "909.465", "ppl": "4.1", "accuracy": "68.235", "wps": "3143.6", "ups": "2.36", "wpb": "1332.8", "bsz": "55", "num_updates": "26000", "lr": "0.000333392", "gnorm": "20.19", "loss_scale": "64", "train_wall": "83", "gb_free": "6.2", "wall": "10861"}
[2024-11-11 14:22:45,687][train_inner][INFO] - {"epoch": 9, "update": 8.943, "loss": "77.696", "nll_loss": "2.071", "total": "1321.84", "n_correct": "894.19", "ppl": "4.2", "accuracy": "67.648", "wps": "3088.7", "ups": "2.34", "wpb": "1321.8", "bsz": "55.1", "num_updates": "26200", "lr": "0.0003268", "gnorm": "20.383", "loss_scale": "64", "train_wall": "84", "gb_free": "5.9", "wall": "10946"}
[2024-11-11 14:23:57,423][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-11-11 14:23:57,427][train][INFO] - {"epoch": 9, "train_loss": "77.696", "train_nll_loss": "2.093", "train_total": "1331.66", "train_n_correct": "895.957", "train_ppl": "4.27", "train_accuracy": "67.281", "train_wps": "2861.3", "train_ups": "2.15", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "26368", "train_lr": "0.000321363", "train_gnorm": "20.5", "train_loss_scale": "64", "train_train_wall": "1309", "train_gb_free": "6", "train_wall": "11018"}
[2024-11-11 14:23:58,085][fairseq.trainer][INFO] - begin training epoch 10
[2024-11-11 14:23:58,085][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 14:24:40,553][train_inner][INFO] - {"epoch": 10, "update": 9.011, "loss": "76.303", "nll_loss": "1.997", "total": "1326.55", "n_correct": "911.92", "ppl": "3.99", "accuracy": "68.744", "wps": "2309.8", "ups": "1.74", "wpb": "1326.5", "bsz": "55.2", "num_updates": "26400", "lr": "0.000320338", "gnorm": "20.005", "loss_scale": "64", "train_wall": "89", "gb_free": "6.2", "wall": "11061"}
[2024-11-11 14:26:05,688][train_inner][INFO] - {"epoch": 10, "update": 9.079, "loss": "70.052", "nll_loss": "1.798", "total": "1319.42", "n_correct": "947.095", "ppl": "3.48", "accuracy": "71.781", "wps": "3099.7", "ups": "2.35", "wpb": "1319.4", "bsz": "56.7", "num_updates": "26600", "lr": "0.000314004", "gnorm": "19.205", "loss_scale": "64", "train_wall": "84", "gb_free": "6.1", "wall": "11146"}
[2024-11-11 14:27:29,385][train_inner][INFO] - {"epoch": 10, "update": 9.147, "loss": "73.451", "nll_loss": "1.814", "total": "1317.07", "n_correct": "941.91", "ppl": "3.52", "accuracy": "71.516", "wps": "3147.4", "ups": "2.39", "wpb": "1317.1", "bsz": "54.2", "num_updates": "26800", "lr": "0.000307795", "gnorm": "19.776", "loss_scale": "64", "train_wall": "82", "gb_free": "6.4", "wall": "11230"}
[2024-11-11 14:28:53,838][train_inner][INFO] - {"epoch": 10, "update": 9.216, "loss": "73.062", "nll_loss": "1.816", "total": "1339.81", "n_correct": "958.25", "ppl": "3.52", "accuracy": "71.521", "wps": "3173", "ups": "2.37", "wpb": "1339.8", "bsz": "55.4", "num_updates": "27000", "lr": "0.000301709", "gnorm": "19.927", "loss_scale": "64", "train_wall": "83", "gb_free": "6", "wall": "11314"}
[2024-11-11 14:30:18,534][train_inner][INFO] - {"epoch": 10, "update": 9.284, "loss": "70.513", "nll_loss": "1.819", "total": "1327.87", "n_correct": "949.755", "ppl": "3.53", "accuracy": "71.525", "wps": "3135.7", "ups": "2.36", "wpb": "1327.9", "bsz": "56.9", "num_updates": "27200", "lr": "0.000295743", "gnorm": "18.956", "loss_scale": "128", "train_wall": "83", "gb_free": "6.2", "wall": "11399"}
[2024-11-11 14:30:54,281][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-11-11 14:31:43,836][train_inner][INFO] - {"epoch": 10, "update": 9.352, "loss": "73.98", "nll_loss": "1.841", "total": "1339.04", "n_correct": "951.305", "ppl": "3.58", "accuracy": "71.044", "wps": "3139.7", "ups": "2.34", "wpb": "1339", "bsz": "55.1", "num_updates": "27400", "lr": "0.000289895", "gnorm": "20.375", "loss_scale": "64", "train_wall": "84", "gb_free": "5.8", "wall": "11484"}
[2024-11-11 14:33:08,976][train_inner][INFO] - {"epoch": 10, "update": 9.421, "loss": "71.137", "nll_loss": "1.822", "total": "1326.97", "n_correct": "949.05", "ppl": "3.54", "accuracy": "71.52", "wps": "3117.3", "ups": "2.35", "wpb": "1327", "bsz": "56.4", "num_updates": "27600", "lr": "0.000284163", "gnorm": "19.044", "loss_scale": "64", "train_wall": "84", "gb_free": "6", "wall": "11570"}
[2024-11-11 14:34:40,136][train_inner][INFO] - {"epoch": 10, "update": 9.489, "loss": "72.995", "nll_loss": "1.832", "total": "1326.1", "n_correct": "944.765", "ppl": "3.56", "accuracy": "71.244", "wps": "2909.5", "ups": "2.19", "wpb": "1326.1", "bsz": "55.1", "num_updates": "27800", "lr": "0.000278544", "gnorm": "19.892", "loss_scale": "64", "train_wall": "90", "gb_free": "5.9", "wall": "11661"}
[2024-11-11 14:36:02,177][train_inner][INFO] - {"epoch": 10, "update": 9.557, "loss": "71.428", "nll_loss": "1.813", "total": "1334.85", "n_correct": "956.32", "ppl": "3.51", "accuracy": "71.643", "wps": "3254.2", "ups": "2.44", "wpb": "1334.9", "bsz": "56.4", "num_updates": "28000", "lr": "0.000273036", "gnorm": "19.255", "loss_scale": "64", "train_wall": "81", "gb_free": "6.2", "wall": "11743"}
[2024-11-11 14:37:24,392][train_inner][INFO] - {"epoch": 10, "update": 9.625, "loss": "71.117", "nll_loss": "1.8", "total": "1339.47", "n_correct": "961.38", "ppl": "3.48", "accuracy": "71.773", "wps": "3258.6", "ups": "2.43", "wpb": "1339.5", "bsz": "56.6", "num_updates": "28200", "lr": "0.000267637", "gnorm": "19.184", "loss_scale": "64", "train_wall": "81", "gb_free": "6.5", "wall": "11825"}
[2024-11-11 14:38:46,634][train_inner][INFO] - {"epoch": 10, "update": 9.694, "loss": "72.881", "nll_loss": "1.832", "total": "1338.77", "n_correct": "955.97", "ppl": "3.56", "accuracy": "71.407", "wps": "3255.9", "ups": "2.43", "wpb": "1338.8", "bsz": "55.7", "num_updates": "28400", "lr": "0.000262345", "gnorm": "19.475", "loss_scale": "64", "train_wall": "81", "gb_free": "6.1", "wall": "11907"}
[2024-11-11 14:40:08,679][train_inner][INFO] - {"epoch": 10, "update": 9.762, "loss": "71.446", "nll_loss": "1.796", "total": "1330.41", "n_correct": "956.035", "ppl": "3.47", "accuracy": "71.86", "wps": "3243.2", "ups": "2.44", "wpb": "1330.4", "bsz": "55.9", "num_updates": "28600", "lr": "0.000257158", "gnorm": "19.318", "loss_scale": "64", "train_wall": "81", "gb_free": "6.1", "wall": "11989"}
[2024-11-11 14:41:30,929][train_inner][INFO] - {"epoch": 10, "update": 9.83, "loss": "70.089", "nll_loss": "1.801", "total": "1333.27", "n_correct": "956.705", "ppl": "3.48", "accuracy": "71.756", "wps": "3242.2", "ups": "2.43", "wpb": "1333.3", "bsz": "57.2", "num_updates": "28800", "lr": "0.000252073", "gnorm": "18.735", "loss_scale": "64", "train_wall": "81", "gb_free": "6.1", "wall": "12071"}
[2024-11-11 14:42:53,064][train_inner][INFO] - {"epoch": 10, "update": 9.898, "loss": "71.025", "nll_loss": "1.817", "total": "1337.65", "n_correct": "958.28", "ppl": "3.52", "accuracy": "71.639", "wps": "3257.4", "ups": "2.44", "wpb": "1337.7", "bsz": "56.8", "num_updates": "29000", "lr": "0.000247089", "gnorm": "19.081", "loss_scale": "64", "train_wall": "81", "gb_free": "6.7", "wall": "12154"}
[2024-11-11 14:44:15,121][train_inner][INFO] - {"epoch": 10, "update": 9.967, "loss": "72.35", "nll_loss": "1.789", "total": "1335.88", "n_correct": "963.58", "ppl": "3.46", "accuracy": "72.13", "wps": "3256.1", "ups": "2.44", "wpb": "1335.9", "bsz": "55.3", "num_updates": "29200", "lr": "0.000242203", "gnorm": "19.575", "loss_scale": "64", "train_wall": "81", "gb_free": "6.2", "wall": "12236"}
[2024-11-11 14:44:54,768][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 14:45:20,272][valid][INFO] - {"epoch": 10, "valid_loss": "34.073", "valid_nll_loss": "1.426", "valid_total": "1356.8", "valid_n_correct": "1043.5", "valid_ppl": "2.69", "valid_accuracy": "76.909", "valid_wps": "8707.5", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "29298", "valid_best_accuracy": "76.909"}
[2024-11-11 14:45:20,274][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 29298 updates
[2024-11-11 14:45:20,275][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 14:45:28,845][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 14:45:35,177][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 29298 updates, score 76.909) (writing took 14.90289161587134 seconds)
[2024-11-11 14:45:35,177][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-11-11 14:45:35,181][train][INFO] - {"epoch": 10, "train_loss": "71.915", "train_nll_loss": "1.813", "train_total": "1331.66", "train_n_correct": "953.426", "train_ppl": "3.51", "train_accuracy": "71.597", "train_wps": "3006.6", "train_ups": "2.26", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "29298", "train_lr": "0.000239844", "train_gnorm": "19.446", "train_loss_scale": "64", "train_train_wall": "1213", "train_gb_free": "6.6", "train_wall": "12316"}
[2024-11-11 14:45:35,605][fairseq.trainer][INFO] - begin training epoch 11
[2024-11-11 14:45:35,606][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 14:46:42,057][train_inner][INFO] - {"epoch": 11, "update": 10.035, "loss": "71.422", "nll_loss": "1.709", "total": "1324.97", "n_correct": "969.995", "ppl": "3.27", "accuracy": "73.209", "wps": "1803.5", "ups": "1.36", "wpb": "1325", "bsz": "54.3", "num_updates": "29400", "lr": "0.000237414", "gnorm": "19.934", "loss_scale": "128", "train_wall": "80", "gb_free": "6", "wall": "12383"}
[2024-11-11 14:48:04,856][train_inner][INFO] - {"epoch": 11, "update": 10.103, "loss": "66.216", "nll_loss": "1.581", "total": "1331.44", "n_correct": "1002.06", "ppl": "2.99", "accuracy": "75.261", "wps": "3216.2", "ups": "2.42", "wpb": "1331.4", "bsz": "56.7", "num_updates": "29600", "lr": "0.000232719", "gnorm": "18.35", "loss_scale": "128", "train_wall": "81", "gb_free": "6", "wall": "12465"}
[2024-11-11 14:49:27,576][train_inner][INFO] - {"epoch": 11, "update": 10.171, "loss": "65.265", "nll_loss": "1.613", "total": "1340.3", "n_correct": "1001.35", "ppl": "3.06", "accuracy": "74.711", "wps": "3240.7", "ups": "2.42", "wpb": "1340.3", "bsz": "58.5", "num_updates": "29800", "lr": "0.000228117", "gnorm": "18.286", "loss_scale": "128", "train_wall": "81", "gb_free": "6", "wall": "12548"}
[2024-11-11 14:50:50,065][train_inner][INFO] - {"epoch": 11, "update": 10.24, "loss": "67.489", "nll_loss": "1.603", "total": "1325.57", "n_correct": "993.6", "ppl": "3.04", "accuracy": "74.957", "wps": "3214.1", "ups": "2.42", "wpb": "1325.6", "bsz": "55.7", "num_updates": "30000", "lr": "0.000223607", "gnorm": "19.016", "loss_scale": "128", "train_wall": "81", "gb_free": "6", "wall": "12631"}
[2024-11-11 14:50:55,374][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-11-11 14:52:13,130][train_inner][INFO] - {"epoch": 11, "update": 10.308, "loss": "68.427", "nll_loss": "1.619", "total": "1339.25", "n_correct": "999.175", "ppl": "3.07", "accuracy": "74.607", "wps": "3224.7", "ups": "2.41", "wpb": "1339.2", "bsz": "55.8", "num_updates": "30200", "lr": "0.000219185", "gnorm": "19.352", "loss_scale": "64", "train_wall": "82", "gb_free": "6", "wall": "12714"}
[2024-11-11 14:53:35,471][train_inner][INFO] - {"epoch": 11, "update": 10.376, "loss": "67.4", "nll_loss": "1.621", "total": "1326.83", "n_correct": "991.35", "ppl": "3.07", "accuracy": "74.716", "wps": "3222.9", "ups": "2.43", "wpb": "1326.8", "bsz": "56.1", "num_updates": "30400", "lr": "0.000214851", "gnorm": "19.304", "loss_scale": "64", "train_wall": "81", "gb_free": "6.4", "wall": "12796"}
[2024-11-11 14:54:59,240][train_inner][INFO] - {"epoch": 11, "update": 10.445, "loss": "68.311", "nll_loss": "1.606", "total": "1332.31", "n_correct": "997.695", "ppl": "3.04", "accuracy": "74.885", "wps": "3181.1", "ups": "2.39", "wpb": "1332.3", "bsz": "55.4", "num_updates": "30600", "lr": "0.000210603", "gnorm": "19.415", "loss_scale": "64", "train_wall": "82", "gb_free": "6", "wall": "12880"}
[2024-11-11 14:56:23,412][train_inner][INFO] - {"epoch": 11, "update": 10.513, "loss": "67.668", "nll_loss": "1.617", "total": "1331.9", "n_correct": "995.58", "ppl": "3.07", "accuracy": "74.749", "wps": "3164.9", "ups": "2.38", "wpb": "1331.9", "bsz": "56", "num_updates": "30800", "lr": "0.000206439", "gnorm": "19.086", "loss_scale": "64", "train_wall": "83", "gb_free": "6.6", "wall": "12964"}
[2024-11-11 14:57:45,887][train_inner][INFO] - {"epoch": 11, "update": 10.581, "loss": "67.518", "nll_loss": "1.616", "total": "1332.68", "n_correct": "996.375", "ppl": "3.07", "accuracy": "74.764", "wps": "3231.9", "ups": "2.43", "wpb": "1332.7", "bsz": "56.2", "num_updates": "31000", "lr": "0.000202357", "gnorm": "19.377", "loss_scale": "64", "train_wall": "81", "gb_free": "6.2", "wall": "13046"}
[2024-11-11 14:59:08,336][train_inner][INFO] - {"epoch": 11, "update": 10.649, "loss": "72.174", "nll_loss": "1.64", "total": "1327.55", "n_correct": "987.265", "ppl": "3.12", "accuracy": "74.368", "wps": "3220.4", "ups": "2.43", "wpb": "1327.5", "bsz": "52.7", "num_updates": "31200", "lr": "0.000198355", "gnorm": "20.433", "loss_scale": "64", "train_wall": "81", "gb_free": "6.1", "wall": "13129"}
[2024-11-11 15:00:30,948][train_inner][INFO] - {"epoch": 11, "update": 10.718, "loss": "67.996", "nll_loss": "1.621", "total": "1342.71", "n_correct": "1002.11", "ppl": "3.08", "accuracy": "74.633", "wps": "3250.8", "ups": "2.42", "wpb": "1342.7", "bsz": "56.3", "num_updates": "31400", "lr": "0.000194433", "gnorm": "18.95", "loss_scale": "64", "train_wall": "81", "gb_free": "5.8", "wall": "13211"}
[2024-11-11 15:01:53,580][train_inner][INFO] - {"epoch": 11, "update": 10.786, "loss": "68.491", "nll_loss": "1.628", "total": "1326.97", "n_correct": "989.075", "ppl": "3.09", "accuracy": "74.536", "wps": "3211.9", "ups": "2.42", "wpb": "1327", "bsz": "55.3", "num_updates": "31600", "lr": "0.000190589", "gnorm": "19.448", "loss_scale": "64", "train_wall": "81", "gb_free": "7", "wall": "13294"}
[2024-11-11 15:03:16,251][train_inner][INFO] - {"epoch": 11, "update": 10.854, "loss": "67.021", "nll_loss": "1.604", "total": "1335.3", "n_correct": "1001.98", "ppl": "3.04", "accuracy": "75.038", "wps": "3230.6", "ups": "2.42", "wpb": "1335.3", "bsz": "56.5", "num_updates": "31800", "lr": "0.00018682", "gnorm": "19.279", "loss_scale": "64", "train_wall": "81", "gb_free": "6", "wall": "13377"}
[2024-11-11 15:04:38,676][train_inner][INFO] - {"epoch": 11, "update": 10.922, "loss": "67.002", "nll_loss": "1.621", "total": "1325.4", "n_correct": "988.88", "ppl": "3.08", "accuracy": "74.61", "wps": "3216.2", "ups": "2.43", "wpb": "1325.4", "bsz": "56.4", "num_updates": "32000", "lr": "0.000183126", "gnorm": "18.852", "loss_scale": "64", "train_wall": "81", "gb_free": "6.1", "wall": "13459"}
[2024-11-11 15:06:01,113][train_inner][INFO] - {"epoch": 11, "update": 10.99, "loss": "67.427", "nll_loss": "1.619", "total": "1334.09", "n_correct": "997.785", "ppl": "3.07", "accuracy": "74.791", "wps": "3236.8", "ups": "2.43", "wpb": "1334.1", "bsz": "56.3", "num_updates": "32200", "lr": "0.000179505", "gnorm": "18.902", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "13542"}
[2024-11-11 15:06:11,923][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-11-11 15:06:11,925][train][INFO] - {"epoch": 11, "train_loss": "67.796", "train_nll_loss": "1.615", "train_total": "1331.66", "train_n_correct": "995.474", "train_ppl": "3.06", "train_accuracy": "74.754", "train_wps": "3154.9", "train_ups": "2.37", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "32228", "train_lr": "0.000179004", "train_gnorm": "19.18", "train_loss_scale": "128", "train_train_wall": "1193", "train_gb_free": "5.9", "train_wall": "13552"}
[2024-11-11 15:06:12,496][fairseq.trainer][INFO] - begin training epoch 12
[2024-11-11 15:06:12,497][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 15:07:40,709][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-11-11 15:07:52,302][train_inner][INFO] - {"epoch": 12, "update": 11.059, "loss": "66.276", "nll_loss": "1.461", "total": "1332.87", "n_correct": "1028.97", "ppl": "2.75", "accuracy": "77.2", "wps": "2397.6", "ups": "1.8", "wpb": "1332.9", "bsz": "54.6", "num_updates": "32400", "lr": "0.000175955", "gnorm": "18.928", "loss_scale": "64", "train_wall": "84", "gb_free": "6.1", "wall": "13653"}
[2024-11-11 15:09:15,142][train_inner][INFO] - {"epoch": 12, "update": 11.127, "loss": "67.263", "nll_loss": "1.469", "total": "1320.9", "n_correct": "1019.73", "ppl": "2.77", "accuracy": "77.2", "wps": "3189.2", "ups": "2.41", "wpb": "1320.9", "bsz": "53.4", "num_updates": "32600", "lr": "0.000172476", "gnorm": "19.387", "loss_scale": "64", "train_wall": "82", "gb_free": "5.9", "wall": "13736"}
[2024-11-11 15:10:08,290][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-11-11 15:10:38,432][train_inner][INFO] - {"epoch": 12, "update": 11.196, "loss": "61.527", "nll_loss": "1.429", "total": "1343.84", "n_correct": "1046.21", "ppl": "2.69", "accuracy": "77.853", "wps": "3227", "ups": "2.4", "wpb": "1343.8", "bsz": "58.7", "num_updates": "32800", "lr": "0.000169066", "gnorm": "18.114", "loss_scale": "32", "train_wall": "82", "gb_free": "6.2", "wall": "13819"}
[2024-11-11 15:12:01,058][train_inner][INFO] - {"epoch": 12, "update": 11.264, "loss": "64.336", "nll_loss": "1.445", "total": "1328.22", "n_correct": "1030.59", "ppl": "2.72", "accuracy": "77.592", "wps": "3215.2", "ups": "2.42", "wpb": "1328.2", "bsz": "55.7", "num_updates": "33000", "lr": "0.000165723", "gnorm": "18.769", "loss_scale": "32", "train_wall": "81", "gb_free": "5.9", "wall": "13902"}
[2024-11-11 15:13:23,743][train_inner][INFO] - {"epoch": 12, "update": 11.332, "loss": "67.182", "nll_loss": "1.487", "total": "1329.2", "n_correct": "1021.28", "ppl": "2.8", "accuracy": "76.834", "wps": "3215.3", "ups": "2.42", "wpb": "1329.2", "bsz": "54.1", "num_updates": "33200", "lr": "0.000162446", "gnorm": "19.805", "loss_scale": "32", "train_wall": "81", "gb_free": "6.5", "wall": "13984"}
[2024-11-11 15:14:46,881][train_inner][INFO] - {"epoch": 12, "update": 11.401, "loss": "64.969", "nll_loss": "1.475", "total": "1334.09", "n_correct": "1027.84", "ppl": "2.78", "accuracy": "77.044", "wps": "3209.4", "ups": "2.41", "wpb": "1334.1", "bsz": "56", "num_updates": "33400", "lr": "0.000159234", "gnorm": "18.813", "loss_scale": "32", "train_wall": "82", "gb_free": "6.1", "wall": "14067"}
[2024-11-11 15:16:09,884][train_inner][INFO] - {"epoch": 12, "update": 11.469, "loss": "65.549", "nll_loss": "1.475", "total": "1344.89", "n_correct": "1036.53", "ppl": "2.78", "accuracy": "77.071", "wps": "3240.8", "ups": "2.41", "wpb": "1344.9", "bsz": "55.9", "num_updates": "33600", "lr": "0.000156085", "gnorm": "19.301", "loss_scale": "32", "train_wall": "82", "gb_free": "5.9", "wall": "14150"}
[2024-11-11 15:17:32,782][train_inner][INFO] - {"epoch": 12, "update": 11.537, "loss": "62.346", "nll_loss": "1.459", "total": "1330.41", "n_correct": "1029.29", "ppl": "2.75", "accuracy": "77.366", "wps": "3209.9", "ups": "2.41", "wpb": "1330.4", "bsz": "57.8", "num_updates": "33800", "lr": "0.000152999", "gnorm": "18.463", "loss_scale": "32", "train_wall": "82", "gb_free": "6.3", "wall": "14233"}
[2024-11-11 15:18:55,819][train_inner][INFO] - {"epoch": 12, "update": 11.605, "loss": "65.353", "nll_loss": "1.476", "total": "1328.7", "n_correct": "1023.39", "ppl": "2.78", "accuracy": "77.022", "wps": "3200.4", "ups": "2.41", "wpb": "1328.7", "bsz": "55.4", "num_updates": "34000", "lr": "0.000149973", "gnorm": "19.065", "loss_scale": "32", "train_wall": "82", "gb_free": "6", "wall": "14316"}
[2024-11-11 15:20:18,750][train_inner][INFO] - {"epoch": 12, "update": 11.673, "loss": "62.803", "nll_loss": "1.458", "total": "1334.86", "n_correct": "1032.52", "ppl": "2.75", "accuracy": "77.35", "wps": "3219.4", "ups": "2.41", "wpb": "1334.9", "bsz": "57.6", "num_updates": "34200", "lr": "0.000147008", "gnorm": "18.402", "loss_scale": "32", "train_wall": "82", "gb_free": "5.9", "wall": "14399"}
[2024-11-11 15:21:41,849][train_inner][INFO] - {"epoch": 12, "update": 11.742, "loss": "64.664", "nll_loss": "1.447", "total": "1328.05", "n_correct": "1029.54", "ppl": "2.73", "accuracy": "77.522", "wps": "3196.4", "ups": "2.41", "wpb": "1328", "bsz": "55.4", "num_updates": "34400", "lr": "0.000144101", "gnorm": "18.876", "loss_scale": "32", "train_wall": "82", "gb_free": "6", "wall": "14482"}
[2024-11-11 15:23:04,654][train_inner][INFO] - {"epoch": 12, "update": 11.81, "loss": "65.215", "nll_loss": "1.464", "total": "1324.97", "n_correct": "1023.88", "ppl": "2.76", "accuracy": "77.276", "wps": "3200.4", "ups": "2.42", "wpb": "1325", "bsz": "55.1", "num_updates": "34600", "lr": "0.000141252", "gnorm": "19.209", "loss_scale": "32", "train_wall": "82", "gb_free": "6.3", "wall": "14565"}
[2024-11-11 15:24:28,119][train_inner][INFO] - {"epoch": 12, "update": 11.878, "loss": "65.144", "nll_loss": "1.46", "total": "1331.53", "n_correct": "1029.7", "ppl": "2.75", "accuracy": "77.332", "wps": "3190.8", "ups": "2.4", "wpb": "1331.5", "bsz": "55.4", "num_updates": "34800", "lr": "0.000138459", "gnorm": "19.221", "loss_scale": "64", "train_wall": "82", "gb_free": "6.4", "wall": "14649"}
[2024-11-11 15:25:51,321][train_inner][INFO] - {"epoch": 12, "update": 11.946, "loss": "62.857", "nll_loss": "1.478", "total": "1331.78", "n_correct": "1025.97", "ppl": "2.78", "accuracy": "77.038", "wps": "3201.5", "ups": "2.4", "wpb": "1331.8", "bsz": "57.7", "num_updates": "35000", "lr": "0.000135721", "gnorm": "18.505", "loss_scale": "64", "train_wall": "82", "gb_free": "6", "wall": "14732"}
[2024-11-11 15:26:55,228][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 15:27:21,108][valid][INFO] - {"epoch": 12, "valid_loss": "33.277", "valid_nll_loss": "1.357", "valid_total": "1356.8", "valid_n_correct": "1057.9", "valid_ppl": "2.56", "valid_accuracy": "77.97", "valid_wps": "11582", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "35157", "valid_best_accuracy": "77.97"}
[2024-11-11 15:27:21,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 35157 updates
[2024-11-11 15:27:21,111][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 15:27:29,974][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 15:27:36,335][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 12 @ 35157 updates, score 77.97) (writing took 15.22376337600872 seconds)
[2024-11-11 15:27:36,337][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-11-11 15:27:36,343][train][INFO] - {"epoch": 12, "train_loss": "64.608", "train_nll_loss": "1.461", "train_total": "1331.7", "train_n_correct": "1029.28", "train_ppl": "2.75", "train_accuracy": "77.291", "train_wps": "3036.8", "train_ups": "2.28", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "35157", "train_lr": "0.00013361", "train_gnorm": "18.925", "train_loss_scale": "64", "train_train_wall": "1199", "train_gb_free": "6", "train_wall": "14837"}
[2024-11-11 15:27:36,863][fairseq.trainer][INFO] - begin training epoch 13
[2024-11-11 15:27:36,864][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 15:28:18,722][train_inner][INFO] - {"epoch": 13, "update": 12.015, "loss": "64.899", "nll_loss": "1.438", "total": "1327.38", "n_correct": "1031.03", "ppl": "2.71", "accuracy": "77.674", "wps": "1801.1", "ups": "1.36", "wpb": "1327.4", "bsz": "55", "num_updates": "35200", "lr": "0.000133037", "gnorm": "19.158", "loss_scale": "64", "train_wall": "81", "gb_free": "6.2", "wall": "14879"}
[2024-11-11 15:29:41,025][train_inner][INFO] - {"epoch": 13, "update": 12.083, "loss": "62.5", "nll_loss": "1.325", "total": "1330.04", "n_correct": "1058.23", "ppl": "2.5", "accuracy": "79.564", "wps": "3232.2", "ups": "2.43", "wpb": "1330", "bsz": "55.2", "num_updates": "35400", "lr": "0.000130407", "gnorm": "19.077", "loss_scale": "64", "train_wall": "81", "gb_free": "5.9", "wall": "14962"}
[2024-11-11 15:31:03,275][train_inner][INFO] - {"epoch": 13, "update": 12.151, "loss": "61.239", "nll_loss": "1.348", "total": "1332.33", "n_correct": "1055.29", "ppl": "2.55", "accuracy": "79.206", "wps": "3239.9", "ups": "2.43", "wpb": "1332.3", "bsz": "56.9", "num_updates": "35600", "lr": "0.000127828", "gnorm": "18.49", "loss_scale": "64", "train_wall": "81", "gb_free": "6.5", "wall": "15044"}
[2024-11-11 15:32:25,661][train_inner][INFO] - {"epoch": 13, "update": 12.219, "loss": "62.848", "nll_loss": "1.348", "total": "1332.54", "n_correct": "1054.2", "ppl": "2.55", "accuracy": "79.112", "wps": "3235", "ups": "2.43", "wpb": "1332.5", "bsz": "55.4", "num_updates": "35800", "lr": "0.0001253", "gnorm": "19.169", "loss_scale": "64", "train_wall": "81", "gb_free": "6.8", "wall": "15126"}
[2024-11-11 15:33:48,447][train_inner][INFO] - {"epoch": 13, "update": 12.288, "loss": "65.146", "nll_loss": "1.352", "total": "1337.1", "n_correct": "1057.29", "ppl": "2.55", "accuracy": "79.073", "wps": "3230.4", "ups": "2.42", "wpb": "1337.1", "bsz": "53.7", "num_updates": "36000", "lr": "0.000122823", "gnorm": "19.428", "loss_scale": "64", "train_wall": "81", "gb_free": "6.5", "wall": "15209"}
[2024-11-11 15:35:11,007][train_inner][INFO] - {"epoch": 13, "update": 12.356, "loss": "63.004", "nll_loss": "1.349", "total": "1332.14", "n_correct": "1054.74", "ppl": "2.55", "accuracy": "79.176", "wps": "3227.2", "ups": "2.42", "wpb": "1332.1", "bsz": "55.3", "num_updates": "36200", "lr": "0.000120394", "gnorm": "19.037", "loss_scale": "64", "train_wall": "81", "gb_free": "7.1", "wall": "15292"}
[2024-11-11 15:36:33,117][train_inner][INFO] - {"epoch": 13, "update": 12.424, "loss": "62.757", "nll_loss": "1.352", "total": "1331.72", "n_correct": "1054.99", "ppl": "2.55", "accuracy": "79.22", "wps": "3244", "ups": "2.44", "wpb": "1331.7", "bsz": "55.5", "num_updates": "36400", "lr": "0.000118014", "gnorm": "19.099", "loss_scale": "64", "train_wall": "81", "gb_free": "6.3", "wall": "15374"}
[2024-11-11 15:37:55,559][train_inner][INFO] - {"epoch": 13, "update": 12.492, "loss": "61.974", "nll_loss": "1.33", "total": "1340.35", "n_correct": "1064.85", "ppl": "2.51", "accuracy": "79.446", "wps": "3251.7", "ups": "2.43", "wpb": "1340.4", "bsz": "56.2", "num_updates": "36600", "lr": "0.00011568", "gnorm": "18.776", "loss_scale": "64", "train_wall": "81", "gb_free": "6", "wall": "15456"}
[2024-11-11 15:39:18,125][train_inner][INFO] - {"epoch": 13, "update": 12.561, "loss": "60.241", "nll_loss": "1.337", "total": "1332.35", "n_correct": "1055.81", "ppl": "2.53", "accuracy": "79.244", "wps": "3227.5", "ups": "2.42", "wpb": "1332.3", "bsz": "57.6", "num_updates": "36800", "lr": "0.000113393", "gnorm": "18.676", "loss_scale": "64", "train_wall": "81", "gb_free": "6", "wall": "15539"}
[2024-11-11 15:40:40,805][train_inner][INFO] - {"epoch": 13, "update": 12.629, "loss": "62.974", "nll_loss": "1.391", "total": "1327.65", "n_correct": "1041.27", "ppl": "2.62", "accuracy": "78.429", "wps": "3211.7", "ups": "2.42", "wpb": "1327.7", "bsz": "55.9", "num_updates": "37000", "lr": "0.00011115", "gnorm": "19.214", "loss_scale": "128", "train_wall": "81", "gb_free": "6.2", "wall": "15621"}
[2024-11-11 15:42:03,126][train_inner][INFO] - {"epoch": 13, "update": 12.697, "loss": "61.365", "nll_loss": "1.348", "total": "1329.36", "n_correct": "1052.19", "ppl": "2.55", "accuracy": "79.15", "wps": "3229.9", "ups": "2.43", "wpb": "1329.4", "bsz": "56.6", "num_updates": "37200", "lr": "0.000108953", "gnorm": "18.65", "loss_scale": "128", "train_wall": "81", "gb_free": "6.1", "wall": "15704"}
[2024-11-11 15:43:25,617][train_inner][INFO] - {"epoch": 13, "update": 12.765, "loss": "62.109", "nll_loss": "1.35", "total": "1331.57", "n_correct": "1055.03", "ppl": "2.55", "accuracy": "79.232", "wps": "3228.6", "ups": "2.42", "wpb": "1331.6", "bsz": "56.1", "num_updates": "37400", "lr": "0.000106798", "gnorm": "18.735", "loss_scale": "128", "train_wall": "81", "gb_free": "6.1", "wall": "15786"}
[2024-11-11 15:44:48,117][train_inner][INFO] - {"epoch": 13, "update": 12.834, "loss": "60.523", "nll_loss": "1.36", "total": "1326.36", "n_correct": "1047.86", "ppl": "2.57", "accuracy": "79.003", "wps": "3215.6", "ups": "2.42", "wpb": "1326.4", "bsz": "57.5", "num_updates": "37600", "lr": "0.000104687", "gnorm": "18.337", "loss_scale": "128", "train_wall": "81", "gb_free": "6.7", "wall": "15869"}
[2024-11-11 15:46:10,494][train_inner][INFO] - {"epoch": 13, "update": 12.902, "loss": "63.843", "nll_loss": "1.361", "total": "1334.81", "n_correct": "1053.32", "ppl": "2.57", "accuracy": "78.912", "wps": "3240.9", "ups": "2.43", "wpb": "1334.8", "bsz": "54.9", "num_updates": "37800", "lr": "0.000102617", "gnorm": "19.437", "loss_scale": "128", "train_wall": "81", "gb_free": "6", "wall": "15951"}
[2024-11-11 15:47:32,883][train_inner][INFO] - {"epoch": 13, "update": 12.97, "loss": "62.025", "nll_loss": "1.338", "total": "1325.66", "n_correct": "1052.43", "ppl": "2.53", "accuracy": "79.39", "wps": "3218.2", "ups": "2.43", "wpb": "1325.7", "bsz": "55.7", "num_updates": "38000", "lr": "0.000100587", "gnorm": "18.816", "loss_scale": "128", "train_wall": "81", "gb_free": "5.9", "wall": "16033"}
[2024-11-11 15:48:08,573][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-11-11 15:48:08,576][train][INFO] - {"epoch": 13, "train_loss": "62.309", "train_nll_loss": "1.35", "train_total": "1331.66", "train_n_correct": "1053.99", "train_ppl": "2.55", "train_accuracy": "79.148", "train_wps": "3167.5", "train_ups": "2.38", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "38088", "train_lr": "9.97074e-05", "train_gnorm": "18.924", "train_loss_scale": "128", "train_train_wall": "1189", "train_gb_free": "5.9", "train_wall": "16069"}
[2024-11-11 15:48:09,115][fairseq.trainer][INFO] - begin training epoch 14
[2024-11-11 15:48:09,116][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 15:49:23,976][train_inner][INFO] - {"epoch": 14, "update": 13.038, "loss": "60.708", "nll_loss": "1.296", "total": "1338.3", "n_correct": "1072.21", "ppl": "2.45", "accuracy": "80.118", "wps": "2409.4", "ups": "1.8", "wpb": "1338.3", "bsz": "56.6", "num_updates": "38200", "lr": "9.85985e-05", "gnorm": "18.432", "loss_scale": "128", "train_wall": "83", "gb_free": "6.1", "wall": "16145"}
[2024-11-11 15:50:46,879][train_inner][INFO] - {"epoch": 14, "update": 13.106, "loss": "62.205", "nll_loss": "1.251", "total": "1334.36", "n_correct": "1079.82", "ppl": "2.38", "accuracy": "80.924", "wps": "3219.2", "ups": "2.41", "wpb": "1334.4", "bsz": "54.3", "num_updates": "38400", "lr": "9.66488e-05", "gnorm": "19.12", "loss_scale": "128", "train_wall": "82", "gb_free": "5.9", "wall": "16227"}
[2024-11-11 15:52:09,872][train_inner][INFO] - {"epoch": 14, "update": 13.175, "loss": "60.734", "nll_loss": "1.248", "total": "1327.01", "n_correct": "1074.12", "ppl": "2.37", "accuracy": "80.943", "wps": "3198", "ups": "2.41", "wpb": "1327", "bsz": "55.2", "num_updates": "38600", "lr": "9.47378e-05", "gnorm": "18.878", "loss_scale": "128", "train_wall": "82", "gb_free": "6.5", "wall": "16310"}
[2024-11-11 15:53:33,250][train_inner][INFO] - {"epoch": 14, "update": 13.243, "loss": "60.304", "nll_loss": "1.263", "total": "1328.86", "n_correct": "1071.95", "ppl": "2.4", "accuracy": "80.667", "wps": "3187.7", "ups": "2.4", "wpb": "1328.9", "bsz": "56", "num_updates": "38800", "lr": "9.28645e-05", "gnorm": "18.73", "loss_scale": "128", "train_wall": "82", "gb_free": "5.9", "wall": "16394"}
[2024-11-11 15:54:56,149][train_inner][INFO] - {"epoch": 14, "update": 13.311, "loss": "59.953", "nll_loss": "1.246", "total": "1337.29", "n_correct": "1081.37", "ppl": "2.37", "accuracy": "80.863", "wps": "3226.4", "ups": "2.41", "wpb": "1337.3", "bsz": "56.3", "num_updates": "39000", "lr": "9.10282e-05", "gnorm": "18.601", "loss_scale": "256", "train_wall": "82", "gb_free": "6.1", "wall": "16477"}
[2024-11-11 15:55:25,759][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2024-11-11 15:56:19,178][train_inner][INFO] - {"epoch": 14, "update": 13.38, "loss": "61.251", "nll_loss": "1.259", "total": "1320.05", "n_correct": "1065.15", "ppl": "2.39", "accuracy": "80.69", "wps": "3179.9", "ups": "2.41", "wpb": "1320", "bsz": "54.7", "num_updates": "39200", "lr": "8.92283e-05", "gnorm": "19.395", "loss_scale": "128", "train_wall": "82", "gb_free": "5.9", "wall": "16560"}
[2024-11-11 15:57:42,256][train_inner][INFO] - {"epoch": 14, "update": 13.448, "loss": "61.985", "nll_loss": "1.259", "total": "1322.67", "n_correct": "1066.46", "ppl": "2.39", "accuracy": "80.629", "wps": "3184.3", "ups": "2.41", "wpb": "1322.7", "bsz": "54.1", "num_updates": "39400", "lr": "8.74639e-05", "gnorm": "19.566", "loss_scale": "128", "train_wall": "82", "gb_free": "7.2", "wall": "16643"}
[2024-11-11 15:59:04,996][train_inner][INFO] - {"epoch": 14, "update": 13.516, "loss": "60.446", "nll_loss": "1.264", "total": "1328.73", "n_correct": "1070.4", "ppl": "2.4", "accuracy": "80.558", "wps": "3212", "ups": "2.42", "wpb": "1328.7", "bsz": "55.9", "num_updates": "39600", "lr": "8.57345e-05", "gnorm": "19.173", "loss_scale": "128", "train_wall": "81", "gb_free": "6.4", "wall": "16726"}
[2024-11-11 16:00:27,939][train_inner][INFO] - {"epoch": 14, "update": 13.584, "loss": "60.079", "nll_loss": "1.271", "total": "1331.34", "n_correct": "1071.69", "ppl": "2.41", "accuracy": "80.498", "wps": "3210.4", "ups": "2.41", "wpb": "1331.3", "bsz": "56.4", "num_updates": "39800", "lr": "8.40392e-05", "gnorm": "18.656", "loss_scale": "128", "train_wall": "82", "gb_free": "6", "wall": "16808"}
[2024-11-11 16:01:50,722][train_inner][INFO] - {"epoch": 14, "update": 13.653, "loss": "59.009", "nll_loss": "1.269", "total": "1337.4", "n_correct": "1077.07", "ppl": "2.41", "accuracy": "80.534", "wps": "3231.3", "ups": "2.42", "wpb": "1337.4", "bsz": "57.7", "num_updates": "40000", "lr": "8.23774e-05", "gnorm": "18.735", "loss_scale": "128", "train_wall": "81", "gb_free": "5.7", "wall": "16891"}
[2024-11-11 16:03:13,632][train_inner][INFO] - {"epoch": 14, "update": 13.721, "loss": "59.251", "nll_loss": "1.27", "total": "1330.71", "n_correct": "1072.36", "ppl": "2.41", "accuracy": "80.586", "wps": "3210.2", "ups": "2.41", "wpb": "1330.7", "bsz": "57.2", "num_updates": "40200", "lr": "8.07486e-05", "gnorm": "18.861", "loss_scale": "128", "train_wall": "82", "gb_free": "5.9", "wall": "16974"}
[2024-11-11 16:04:36,685][train_inner][INFO] - {"epoch": 14, "update": 13.789, "loss": "62.686", "nll_loss": "1.262", "total": "1337.21", "n_correct": "1078.13", "ppl": "2.4", "accuracy": "80.625", "wps": "3220.3", "ups": "2.41", "wpb": "1337.2", "bsz": "54.1", "num_updates": "40400", "lr": "7.91519e-05", "gnorm": "19.672", "loss_scale": "128", "train_wall": "82", "gb_free": "6.9", "wall": "17057"}
[2024-11-11 16:05:59,502][train_inner][INFO] - {"epoch": 14, "update": 13.857, "loss": "58.926", "nll_loss": "1.262", "total": "1330.09", "n_correct": "1071.93", "ppl": "2.4", "accuracy": "80.591", "wps": "3212.3", "ups": "2.42", "wpb": "1330.1", "bsz": "57.3", "num_updates": "40600", "lr": "7.75868e-05", "gnorm": "18.416", "loss_scale": "128", "train_wall": "82", "gb_free": "6.7", "wall": "17140"}
[2024-11-11 16:07:22,472][train_inner][INFO] - {"epoch": 14, "update": 13.926, "loss": "61.592", "nll_loss": "1.281", "total": "1335.01", "n_correct": "1073.07", "ppl": "2.43", "accuracy": "80.379", "wps": "3218.2", "ups": "2.41", "wpb": "1335", "bsz": "55.4", "num_updates": "40800", "lr": "7.60526e-05", "gnorm": "19.535", "loss_scale": "128", "train_wall": "82", "gb_free": "6", "wall": "17223"}
[2024-11-11 16:08:45,464][train_inner][INFO] - {"epoch": 14, "update": 13.994, "loss": "59.188", "nll_loss": "1.259", "total": "1335.37", "n_correct": "1077.6", "ppl": "2.39", "accuracy": "80.697", "wps": "3218.2", "ups": "2.41", "wpb": "1335.4", "bsz": "57.2", "num_updates": "41000", "lr": "7.45488e-05", "gnorm": "18.255", "loss_scale": "128", "train_wall": "82", "gb_free": "6.1", "wall": "17306"}
[2024-11-11 16:08:52,447][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 16:09:17,991][valid][INFO] - {"epoch": 14, "valid_loss": "33.153", "valid_nll_loss": "1.345", "valid_total": "1356.8", "valid_n_correct": "1068.7", "valid_ppl": "2.54", "valid_accuracy": "78.766", "valid_wps": "9341.2", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "41018", "valid_best_accuracy": "78.766"}
[2024-11-11 16:09:17,993][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 41018 updates
[2024-11-11 16:09:17,994][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 16:09:26,760][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 16:09:33,540][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 14 @ 41018 updates, score 78.766) (writing took 15.5467633982189 seconds)
[2024-11-11 16:09:33,541][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-11-11 16:09:33,550][train][INFO] - {"epoch": 14, "train_loss": "60.486", "train_nll_loss": "1.261", "train_total": "1331.68", "train_n_correct": "1074.23", "train_ppl": "2.4", "train_accuracy": "80.667", "train_wps": "3036.5", "train_ups": "2.28", "train_wpb": "1331.7", "train_bsz": "55.9", "train_num_updates": "41018", "train_lr": "7.44149e-05", "train_gnorm": "18.933", "train_loss_scale": "128", "train_train_wall": "1199", "train_gb_free": "6", "train_wall": "17354"}
[2024-11-11 16:09:34,319][fairseq.trainer][INFO] - begin training epoch 15
[2024-11-11 16:09:34,320][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 16:10:52,016][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2024-11-11 16:11:13,510][train_inner][INFO] - {"epoch": 15, "update": 14.062, "loss": "59.747", "nll_loss": "1.183", "total": "1331.47", "n_correct": "1091.3", "ppl": "2.27", "accuracy": "81.962", "wps": "1798.8", "ups": "1.35", "wpb": "1331.5", "bsz": "55.1", "num_updates": "41200", "lr": "7.30747e-05", "gnorm": "18.59", "loss_scale": "128", "train_wall": "81", "gb_free": "6.5", "wall": "17454"}
[2024-11-11 16:12:35,486][train_inner][INFO] - {"epoch": 15, "update": 14.131, "loss": "59.021", "nll_loss": "1.184", "total": "1328.64", "n_correct": "1090.08", "ppl": "2.27", "accuracy": "82.045", "wps": "3241.6", "ups": "2.44", "wpb": "1328.6", "bsz": "55.7", "num_updates": "41400", "lr": "7.16298e-05", "gnorm": "18.628", "loss_scale": "128", "train_wall": "81", "gb_free": "6.2", "wall": "17536"}
[2024-11-11 16:13:58,044][train_inner][INFO] - {"epoch": 15, "update": 14.199, "loss": "61.571", "nll_loss": "1.186", "total": "1335.1", "n_correct": "1094.89", "ppl": "2.27", "accuracy": "82.008", "wps": "3234.6", "ups": "2.42", "wpb": "1335.1", "bsz": "53.7", "num_updates": "41600", "lr": "7.02134e-05", "gnorm": "19.43", "loss_scale": "128", "train_wall": "81", "gb_free": "7.1", "wall": "17619"}
[2024-11-11 16:15:20,455][train_inner][INFO] - {"epoch": 15, "update": 14.267, "loss": "59.043", "nll_loss": "1.193", "total": "1335.27", "n_correct": "1092.16", "ppl": "2.29", "accuracy": "81.793", "wps": "3240.7", "ups": "2.43", "wpb": "1335.3", "bsz": "56.1", "num_updates": "41800", "lr": "6.88251e-05", "gnorm": "18.708", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "17701"}
[2024-11-11 16:16:42,801][train_inner][INFO] - {"epoch": 15, "update": 14.335, "loss": "58.895", "nll_loss": "1.187", "total": "1323.4", "n_correct": "1083.39", "ppl": "2.28", "accuracy": "81.864", "wps": "3214.4", "ups": "2.43", "wpb": "1323.4", "bsz": "55.6", "num_updates": "42000", "lr": "6.74641e-05", "gnorm": "18.909", "loss_scale": "128", "train_wall": "81", "gb_free": "6.1", "wall": "17783"}
[2024-11-11 16:18:05,378][train_inner][INFO] - {"epoch": 15, "update": 14.404, "loss": "59.287", "nll_loss": "1.203", "total": "1334.38", "n_correct": "1089.42", "ppl": "2.3", "accuracy": "81.642", "wps": "3232", "ups": "2.42", "wpb": "1334.4", "bsz": "56", "num_updates": "42200", "lr": "6.61301e-05", "gnorm": "18.637", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "17866"}
[2024-11-11 16:19:28,044][train_inner][INFO] - {"epoch": 15, "update": 14.472, "loss": "57.449", "nll_loss": "1.184", "total": "1338.79", "n_correct": "1097.62", "ppl": "2.27", "accuracy": "81.986", "wps": "3239.1", "ups": "2.42", "wpb": "1338.8", "bsz": "57.6", "num_updates": "42400", "lr": "6.48225e-05", "gnorm": "18.292", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "17949"}
[2024-11-11 16:20:50,564][train_inner][INFO] - {"epoch": 15, "update": 14.54, "loss": "57.837", "nll_loss": "1.193", "total": "1335.52", "n_correct": "1092.7", "ppl": "2.29", "accuracy": "81.819", "wps": "3237", "ups": "2.42", "wpb": "1335.5", "bsz": "57.3", "num_updates": "42600", "lr": "6.35408e-05", "gnorm": "18.732", "loss_scale": "128", "train_wall": "81", "gb_free": "6.1", "wall": "18031"}
[2024-11-11 16:22:13,266][train_inner][INFO] - {"epoch": 15, "update": 14.608, "loss": "59.629", "nll_loss": "1.213", "total": "1323.1", "n_correct": "1077.59", "ppl": "2.32", "accuracy": "81.444", "wps": "3199.8", "ups": "2.42", "wpb": "1323.1", "bsz": "55.4", "num_updates": "42800", "lr": "6.22843e-05", "gnorm": "19.408", "loss_scale": "128", "train_wall": "81", "gb_free": "5.9", "wall": "18114"}
[2024-11-11 16:23:35,821][train_inner][INFO] - {"epoch": 15, "update": 14.677, "loss": "60.051", "nll_loss": "1.225", "total": "1328.99", "n_correct": "1081.51", "ppl": "2.34", "accuracy": "81.378", "wps": "3219.8", "ups": "2.42", "wpb": "1329", "bsz": "55.5", "num_updates": "43000", "lr": "6.10528e-05", "gnorm": "19.056", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "18196"}
[2024-11-11 16:24:58,641][train_inner][INFO] - {"epoch": 15, "update": 14.745, "loss": "59.075", "nll_loss": "1.206", "total": "1338.2", "n_correct": "1092.91", "ppl": "2.31", "accuracy": "81.671", "wps": "3231.7", "ups": "2.41", "wpb": "1338.2", "bsz": "56.4", "num_updates": "43200", "lr": "5.98455e-05", "gnorm": "18.679", "loss_scale": "256", "train_wall": "82", "gb_free": "6.1", "wall": "18279"}
[2024-11-11 16:25:48,929][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
[2024-11-11 16:26:21,473][train_inner][INFO] - {"epoch": 15, "update": 14.813, "loss": "57.559", "nll_loss": "1.184", "total": "1331.92", "n_correct": "1091.74", "ppl": "2.27", "accuracy": "81.967", "wps": "3216.1", "ups": "2.41", "wpb": "1331.9", "bsz": "57.2", "num_updates": "43400", "lr": "5.86622e-05", "gnorm": "18.816", "loss_scale": "128", "train_wall": "82", "gb_free": "5.9", "wall": "18362"}
[2024-11-11 16:27:44,611][train_inner][INFO] - {"epoch": 15, "update": 14.882, "loss": "59.043", "nll_loss": "1.196", "total": "1338.06", "n_correct": "1094.36", "ppl": "2.29", "accuracy": "81.787", "wps": "3219", "ups": "2.41", "wpb": "1338.1", "bsz": "56.3", "num_updates": "43600", "lr": "5.75022e-05", "gnorm": "18.934", "loss_scale": "128", "train_wall": "82", "gb_free": "6.1", "wall": "18445"}
[2024-11-11 16:29:07,368][train_inner][INFO] - {"epoch": 15, "update": 14.95, "loss": "59.092", "nll_loss": "1.189", "total": "1325.9", "n_correct": "1086.58", "ppl": "2.28", "accuracy": "81.95", "wps": "3204.5", "ups": "2.42", "wpb": "1325.9", "bsz": "55.5", "num_updates": "43800", "lr": "5.63652e-05", "gnorm": "18.743", "loss_scale": "128", "train_wall": "81", "gb_free": "7", "wall": "18528"}
[2024-11-11 16:30:07,136][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-11-11 16:30:07,138][train][INFO] - {"epoch": 15, "train_loss": "59.092", "train_nll_loss": "1.194", "train_total": "1331.65", "train_n_correct": "1089.47", "train_ppl": "2.29", "train_accuracy": "81.814", "train_wps": "3161.8", "train_ups": "2.37", "train_wpb": "1331.6", "train_bsz": "55.9", "train_num_updates": "43947", "train_lr": "5.55439e-05", "train_gnorm": "18.852", "train_loss_scale": "128", "train_train_wall": "1190", "train_gb_free": "6", "train_wall": "18588"}
[2024-11-11 16:30:07,707][fairseq.trainer][INFO] - begin training epoch 16
[2024-11-11 16:30:07,708][fairseq_cli.train][INFO] - Start iterating over samples
[2024-11-11 16:30:57,252][train_inner][INFO] - {"epoch": 16, "update": 15.018, "loss": "59.406", "nll_loss": "1.187", "total": "1332.15", "n_correct": "1091.69", "ppl": "2.28", "accuracy": "81.949", "wps": "2424.7", "ups": "1.82", "wpb": "1332.2", "bsz": "55.5", "num_updates": "44000", "lr": "5.52507e-05", "gnorm": "19.194", "loss_scale": "128", "train_wall": "83", "gb_free": "6.2", "wall": "18638"}
[2024-11-11 16:32:19,883][train_inner][INFO] - {"epoch": 16, "update": 15.086, "loss": "56.776", "nll_loss": "1.156", "total": "1335.02", "n_correct": "1098.92", "ppl": "2.23", "accuracy": "82.315", "wps": "3231.4", "ups": "2.42", "wpb": "1335", "bsz": "57.6", "num_updates": "44200", "lr": "5.41582e-05", "gnorm": "18.608", "loss_scale": "128", "train_wall": "81", "gb_free": "5.9", "wall": "18720"}
[2024-11-11 16:33:42,542][train_inner][INFO] - {"epoch": 16, "update": 15.155, "loss": "58.575", "nll_loss": "1.144", "total": "1324.18", "n_correct": "1093.82", "ppl": "2.21", "accuracy": "82.603", "wps": "3204.1", "ups": "2.42", "wpb": "1324.2", "bsz": "55.1", "num_updates": "44400", "lr": "5.30873e-05", "gnorm": "18.947", "loss_scale": "128", "train_wall": "81", "gb_free": "6.6", "wall": "18803"}
[2024-11-11 16:35:05,522][train_inner][INFO] - {"epoch": 16, "update": 15.223, "loss": "56.881", "nll_loss": "1.126", "total": "1327.93", "n_correct": "1102.71", "ppl": "2.18", "accuracy": "83.039", "wps": "3200.8", "ups": "2.41", "wpb": "1327.9", "bsz": "56.6", "num_updates": "44600", "lr": "5.20376e-05", "gnorm": "18.103", "loss_scale": "128", "train_wall": "82", "gb_free": "6.2", "wall": "18886"}
[2024-11-11 16:36:28,102][train_inner][INFO] - {"epoch": 16, "update": 15.291, "loss": "58.738", "nll_loss": "1.144", "total": "1327.41", "n_correct": "1098.29", "ppl": "2.21", "accuracy": "82.739", "wps": "3215", "ups": "2.42", "wpb": "1327.4", "bsz": "55.1", "num_updates": "44800", "lr": "5.10086e-05", "gnorm": "18.922", "loss_scale": "128", "train_wall": "81", "gb_free": "6.1", "wall": "18969"}
[2024-11-11 16:37:51,231][train_inner][INFO] - {"epoch": 16, "update": 15.359, "loss": "56.743", "nll_loss": "1.131", "total": "1341.9", "n_correct": "1112.43", "ppl": "2.19", "accuracy": "82.899", "wps": "3228.6", "ups": "2.41", "wpb": "1341.9", "bsz": "57.4", "num_updates": "45000", "lr": "5e-05", "gnorm": "18.25", "loss_scale": "128", "train_wall": "82", "gb_free": "6.9", "wall": "19052"}
[2024-11-11 16:37:51,232][fairseq_cli.train][INFO] - Stopping training due to num_updates: 45000 >= max_update: 45000
[2024-11-11 16:37:51,233][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-11-11 16:38:17,340][valid][INFO] - {"epoch": 16, "valid_loss": "33.252", "valid_nll_loss": "1.351", "valid_total": "1356.8", "valid_n_correct": "1069.6", "valid_ppl": "2.55", "valid_accuracy": "78.833", "valid_wps": "3795", "valid_wpb": "1356.8", "valid_bsz": "108.2", "valid_num_updates": "45000", "valid_best_accuracy": "78.833"}
[2024-11-11 16:38:17,342][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 45000 updates
[2024-11-11 16:38:17,343][fairseq.trainer][INFO] - Saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 16:38:25,661][fairseq.trainer][INFO] - Finished saving checkpoint to checkpoints/checkpoint_best.pt
[2024-11-11 16:38:31,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 16 @ 45000 updates, score 78.833) (writing took 14.210070707835257 seconds)
[2024-11-11 16:38:31,554][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-11-11 16:38:31,561][train][INFO] - {"epoch": 16, "train_loss": "57.59", "train_nll_loss": "1.141", "train_total": "1332.32", "train_n_correct": "1101.96", "train_ppl": "2.21", "train_accuracy": "82.71", "train_wps": "2781.3", "train_ups": "2.09", "train_wpb": "1332.3", "train_bsz": "56.3", "train_num_updates": "45000", "train_lr": "5e-05", "train_gnorm": "18.57", "train_loss_scale": "128", "train_train_wall": "432", "train_gb_free": "6.9", "train_wall": "19092"}
[2024-11-11 16:38:31,562][fairseq_cli.train][INFO] - done training in 19090.0 seconds
/root/miniconda3/envs/avhubert/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1152 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
